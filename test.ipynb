{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "from data.scraping import googleScraping\n",
    "import urllib.request, urllib.error\n",
    "from urllib.error import HTTPError\n",
    "from cabocha.analyzer import CaboChaAnalyzer\n",
    "from cabocha.analyzer import EndOfLinkException \n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from enum import Enum\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import uuid\n",
    "import collections\n",
    "import asyncio\n",
    "import tornado.ioloop\n",
    "from tornado.iostream import IOStream\n",
    "\n",
    "class Crawler:\n",
    "    def __init__(self):\n",
    "        self.uid = str(uuid.uuid4())\n",
    "        self.keyword = \"\"\n",
    "        self.url = \"\"\n",
    "        self.article = \"\"\n",
    "        self.causals = []\n",
    "        self.createdAt = datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "        self.updatedAt = datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "class Relation(Enum):\n",
    "    cause = 0\n",
    "    goal = 1\n",
    "    equal = 2\n",
    "    specific = 3\n",
    "    abstract = 4\n",
    "\n",
    "    def toJson(self):\n",
    "        if self == Relation.cause:\n",
    "            return \"cause\"\n",
    "        elif self == Relation.goal:\n",
    "            return \"goal\"\n",
    "        elif self == Relation.equal:\n",
    "            return \"equal\"\n",
    "        elif self == Relation.specific:\n",
    "            return \"specific\"\n",
    "        elif self == Relation.abstract:\n",
    "            return \"abstract\"\n",
    "        \n",
    "    def toJaKeyword(self):\n",
    "        if self == Relation.cause:\n",
    "            return \"なぜ\"\n",
    "        elif self == Relation.goal:\n",
    "            return \"どうやって\"\n",
    "        elif self == Relation.equal:\n",
    "            return \"とは\"\n",
    "        elif self == Relation.specific:\n",
    "            return \"\"\n",
    "        elif self == Relation.abstract:\n",
    "            return \"\"\n",
    "\n",
    "\n",
    "class Pattern(Enum):\n",
    "    A = 0\n",
    "    B = 1\n",
    "    C = 2\n",
    "    D = 3\n",
    "    E = 4\n",
    "\n",
    "    def toJson(self):\n",
    "        if self == Pattern.A:\n",
    "            return \"A\"\n",
    "        elif self == Pattern.B:\n",
    "            return \"B\"\n",
    "        elif self == Pattern.C:\n",
    "            return \"C\"\n",
    "        elif self == Pattern.D:\n",
    "            return \"D\"\n",
    "        elif self == Pattern.E:\n",
    "            return \"E\"\n",
    "\n",
    "    def toOneHot(self):\n",
    "        zeros = np.zeros(5)\n",
    "        if self == Pattern.A:\n",
    "            zeros[0] = 1\n",
    "            return zeros\n",
    "        elif self == Pattern.B:\n",
    "            zeros[1] = 1\n",
    "            return zeros\n",
    "        elif self == Pattern.C:\n",
    "            zeros[2] = 1\n",
    "            return zeros\n",
    "        elif self == Pattern.D:\n",
    "            zeros[3] = 1\n",
    "            return zeros\n",
    "        elif self == Pattern.E:\n",
    "            zeros[4] = 1\n",
    "            return zeros\n",
    "\n",
    "class Causal:\n",
    "    def __init__(self):\n",
    "        self.uid = str(uuid.uuid4())\n",
    "        self.basis = \"\"\n",
    "        self.result = \"\"\n",
    "        self.subj = \"\"\n",
    "        self.pattern = \"\"\n",
    "        self.clue = \"\"\n",
    "        self.filePath = \"\"\n",
    "        self.line = 0\n",
    "        self.causalId = 0\n",
    "        self.sentence = \"\"\n",
    "        self.relation = Relation.cause\n",
    "        self.createdAt = datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "        self.updatedAt = datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "\n",
    "    # def __init__(self):\n",
    "\n",
    "    # def __init__(self,basis,result,subj,pattern):\n",
    "    #     self.basis = basis\n",
    "    #     self.result = result\n",
    "    #     self.subj = subj\n",
    "    #     self.pattern = pattern\n",
    "\n",
    "    def toJson(self):\n",
    "        json = \"{\"\n",
    "        json += \"\\\"clue\\\": \" + \"\\\"\" + self.clue + \"\\\", \"\n",
    "        json += \"\\\"basis\\\": \" + \"\\\"\" + self.basis + \"\\\", \"\n",
    "        json += \"\\\"result\\\": \" + \"\\\"\" + self.result + \"\\\", \"\n",
    "        json += \"\\\"subj\\\": \" + \"\\\"\" + self.subj + \"\\\", \"\n",
    "        json += \"\\\"pattern\\\": \" + \"\\\"\" + self.pattern + \"\\\", \"\n",
    "        json += \"\\\"filePath\\\": \" + \"\\\"\" + self.filePath + \"\\\", \"\n",
    "        json += \"\\\"line\\\": \" + self.line\n",
    "        json += \"}\"\n",
    "        return json\n",
    "\n",
    "    def noneCheck(self):\n",
    "        return all([self.basis != \"\", self.result != \"\", self.clue != \"\", self.sentence != \"\", self.basis != None,\n",
    "                    self.result != None, self.clue != None, self.sentence != None])\n",
    "\n",
    "class ResultExpression:\n",
    "    def __init__(self):\n",
    "        self.uid = str(uuid.uuid4())\n",
    "        self.result = \"\"\n",
    "        self.pos = \"\"\n",
    "        self.pos1 = \"\"\n",
    "        self.causal = Causal()\n",
    "        self.relation = Relation.cause\n",
    "        self.createdAt = datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "        self.updatedAt = datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "\n",
    "class ClueExpression:\n",
    "    def __init__(self):\n",
    "        self.uid = str(uuid.uuid4())\n",
    "        self.clue = \"\"\n",
    "        self.pos = \"\"\n",
    "        self.pos1 = \"\"\n",
    "        self.basis_pos = \"\"\n",
    "        self.basis_pos1 = \"\"\n",
    "        self.causal = Causal()\n",
    "        self.relation = Relation.cause\n",
    "        self.createdAt = datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "        self.updatedAt = datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "\n",
    "class Goal:\n",
    "    def __init__(self):\n",
    "        self.uid = str(uuid.uuid4())\n",
    "        self.text                    = \"\"\n",
    "        self.credit                  = 0\n",
    "        self.smart                   = Smart()\n",
    "        self.steps                   = []\n",
    "        self.owner                   = PrunedUser()\n",
    "        self.private                 = False\n",
    "        self.createdAt               = \"\"\n",
    "        self.updatedAt               = \"\"\n",
    "\n",
    "class Step:\n",
    "    def __init__(self):\n",
    "        self.uid = str(uuid.uuid4())\n",
    "        self.text                    = \"\"\n",
    "        self.credit                  = 0\n",
    "        self.smart                   = Smart()\n",
    "        # self.tasks                   = []\n",
    "        self.owner                   = PrunedUser()\n",
    "        self.private                 = False\n",
    "        self.createdAt               = \"\"\n",
    "        self.updatedAt               = \"\"\n",
    "\n",
    "class Smart:\n",
    "    def __init__(self):\n",
    "        self.uid = str(uuid.uuid4())\n",
    "        self.specificSubject         = \"\"\n",
    "        self.specificVerb            = \"\"\n",
    "        self.timeBound               = \"\"\n",
    "        self.measurable              = \"\"\n",
    "        self.credit                  = 0\n",
    "        self.owner                   = PrunedUser()\n",
    "        self.private                 = False\n",
    "        self.createdAt               = \"\"\n",
    "        self.updatedAt               = \"\"\n",
    "\n",
    "    def getJaText(self):\n",
    "        return self.specificSubject + self.timeBound + self.measurable + self.specificVerb\n",
    "\n",
    "class PrunedUser:\n",
    "    def __init__(self):\n",
    "        self.uid = str(uuid.uuid4())\n",
    "        self.credit                  = 0\n",
    "        self.sumCredit               = 0\n",
    "        self.displayName             = \"\"\n",
    "        self.profileImage            = \"\"\n",
    "        self.backgroundImage         = \"\"\n",
    "        self.registrationConfirmed   = \"\"\n",
    "        self.permissions             = False\n",
    "        self.private                 = False\n",
    "        self.createdAt               = \"\"\n",
    "        self.updatedAt               = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy\n",
    "import collections\n",
    "\n",
    "class causal_rank:\n",
    "    def lex_rank(self, sentences, n=0, t=0.1):\n",
    "        if sentences == None or sentences == []:\n",
    "            return []\n",
    "        n =  len(sentences) if n==0 else n\n",
    "        \"\"\"\n",
    "        LexRankで文章を要約する．\n",
    "        @param  sentences: list\n",
    "            文章([[w1,w2,w3],[w1,w3,w4,w5],..]のような文リスト)\n",
    "        @param  n: int\n",
    "            文章に含まれる文の数\n",
    "        @param  t: float\n",
    "            コサイン類似度の閾値(default 0.1)\n",
    "        @return : list\n",
    "            LexRank\n",
    "        \"\"\"\n",
    "        cosine_matrix = numpy.zeros((n, n))\n",
    "        degrees = numpy.zeros((n,))\n",
    "        l = []\n",
    "\n",
    "         # 1. 隣接行列の作成\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                cosine_matrix[i][j] = self.idf_modified_cosine(sentences, sentences[i], sentences[j])\n",
    "                if cosine_matrix[i][j] > t:\n",
    "                    cosine_matrix[i][j] = 1\n",
    "                    degrees[i] += 1\n",
    "                else:\n",
    "                    cosine_matrix[i][j] = 0\n",
    "\n",
    "        # 2.LexRank計算\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                cosine_matrix[i][j] = cosine_matrix[i][j] / degrees[i]\n",
    "\n",
    "        ratings = self.power_method(cosine_matrix, n)\n",
    "        print(sentences, ratings)\n",
    "        return zip(sentences, ratings)\n",
    "    \n",
    "    def idf_modified_cosine(self, sentences, sentence1, sentence2):\n",
    "        \"\"\"\n",
    "        2文間のコサイン類似度を計算\n",
    "        @param  sentence1: list\n",
    "            文1([w1,w2,w3]のような単語リスト)\n",
    "        @param  sentence2: list\n",
    "            文2([w1,w2,w3]のような単語リスト)\n",
    "        @param  sentences: list\n",
    "            文章([[w1,w2,w3],[w1,w3,w4,w5],..]のような単語リスト)\n",
    "        @return : float\n",
    "            コサイン類似度\n",
    "        \"\"\"\n",
    "        tf1 = self.compute_tf(sentence1)\n",
    "        tf2 = self.compute_tf(sentence2)\n",
    "        idf_metrics = self.compute_idf(sentences)\n",
    "        return self.cosine_similarity(sentence1, sentence2, tf1, tf2, idf_metrics)\n",
    "\n",
    "\n",
    "    def compute_tf(self, sentence):\n",
    "        \"\"\"\n",
    "        TFを計算\n",
    "        @param  sentence: list\n",
    "            文([w1,w2,w3]のような単語リスト)\n",
    "        @return : list\n",
    "            TFリスト\n",
    "        \"\"\"\n",
    "        tf_values = collections.Counter(sentence)\n",
    "        tf_metrics = {}\n",
    "\n",
    "        max_tf = self.find_tf_max(tf_values)\n",
    "\n",
    "        for term, tf in tf_values.items():\n",
    "            tf_metrics[term] = tf / max_tf\n",
    "\n",
    "        return tf_metrics\n",
    "\n",
    "\n",
    "    def find_tf_max(self, terms):\n",
    "        \"\"\"\n",
    "        単語の最大出現頻度を探索\n",
    "        @param  terms: list\n",
    "            単語の出現頻度\n",
    "        @return : int\n",
    "            単語の最大出現頻度\n",
    "        \"\"\"\n",
    "        return max(terms.values()) if terms else 1\n",
    "\n",
    "\n",
    "    def compute_idf(self, sentences):\n",
    "        \"\"\"\n",
    "        文章中の単語のIDF値を計算\n",
    "        @param sentences: list\n",
    "            文章([[w1,w2,w3],[w1,w3,w4,w5],..]のような単語リスト)\n",
    "        @return: list\n",
    "            IDFリスト\n",
    "        \"\"\"\n",
    "        idf_metrics = {}\n",
    "        sentences_count = len(sentences)\n",
    "\n",
    "        for sentence in sentences:\n",
    "            for term in sentence:\n",
    "                if term not in idf_metrics:\n",
    "                    n_j = sum(1 for s in sentences if term in s)\n",
    "                    idf_metrics[term] = math.log(sentences_count / (1 + n_j))\n",
    "\n",
    "        return idf_metrics\n",
    "\n",
    "\n",
    "    def cosine_similarity(self, sentence1, sentence2, tf1, tf2, idf_metrics):\n",
    "        \"\"\"\n",
    "        コサイン類似度を計算\n",
    "        @param  sentence1: list\n",
    "            文1([w1,w2,w3]のような単語リスト)\n",
    "        @param  sentence2: list\n",
    "            文2([w1,w2,w3]のような単語リスト)\n",
    "        @param  tf1: list\n",
    "            文1のTFリスト\n",
    "        @param  tf2: list\n",
    "            文2のTFリスト\n",
    "        @param  idf_metrics: list\n",
    "            文章のIDFリスト\n",
    "        @return : float\n",
    "            コサイン類似度\n",
    "        \"\"\"\n",
    "        unique_words1 = set(sentence1)\n",
    "        unique_words2 = set(sentence2)\n",
    "        common_words = unique_words1 & unique_words2\n",
    "\n",
    "        numerator = sum((tf1[t] * tf2[t] * idf_metrics[t] ** 2) for t in common_words)\n",
    "        denominator1 = sum((tf1[t] * idf_metrics[t]) ** 2 for t in unique_words1)\n",
    "        denominator2 = sum((tf2[t] * idf_metrics[t]) ** 2 for t in unique_words2)\n",
    "\n",
    "        if denominator1 > 0 and denominator2 > 0:\n",
    "            return numerator / (math.sqrt(denominator1) * math.sqrt(denominator2))\n",
    "        else:\n",
    "            return 0.0    \n",
    "        \n",
    "    def power_method(self, cosine_matrix, n, e=0.1):\n",
    "        \"\"\"\n",
    "        べき乗法を行なう\n",
    "        @param  scosine_matrix: list\n",
    "            確率行列\n",
    "        @param  n: int\n",
    "            文章中の文の数\n",
    "        @param  e: float\n",
    "            許容誤差ε\n",
    "        @return: list\n",
    "            LexRank\n",
    "        \"\"\"\n",
    "        transposed_matrix = cosine_matrix.T\n",
    "        sentences_count = n\n",
    "\n",
    "        p_vector = numpy.array([1.0 / sentences_count] * sentences_count)\n",
    "\n",
    "        lambda_val = 1.0\n",
    "\n",
    "        while lambda_val > e:\n",
    "            next_p = numpy.dot(transposed_matrix, p_vector)\n",
    "            lambda_val = numpy.linalg.norm(numpy.subtract(next_p, p_vector))\n",
    "            p_vector = next_p\n",
    "\n",
    "        return p_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class extractor:\n",
    "\n",
    "    pMeasurableKakujosi = re.compile('から$|より$')\n",
    "\n",
    "    clueList = []\n",
    "\n",
    "    eclueList = []\n",
    "\n",
    "    gclueList = []\n",
    "\n",
    "    geclueList = []\n",
    "\n",
    "    eqclueList = []\n",
    "\n",
    "    eqeclueList = []\n",
    "\n",
    "    demonList = []\n",
    "\n",
    "    skipList = []\n",
    "\n",
    "    clueBFilterList = []\n",
    "\n",
    "    eclueBFilterList = []\n",
    "\n",
    "    gclueBFilterList = []\n",
    "\n",
    "    geclueBFilterList = []\n",
    "\n",
    "    eqclueBFilterList = []\n",
    "\n",
    "    eqeclueBFilterList = []\n",
    "\n",
    "    clueRFilterList = []\n",
    "\n",
    "    eclueRFilterList = []\n",
    "\n",
    "    gclueRFilterList = []\n",
    "\n",
    "    geclueRFilterList = []\n",
    "\n",
    "    eqclueRFilterList = []\n",
    "\n",
    "    eqeclueRFilterList = []\n",
    "\n",
    "    cluePosList = []\n",
    "\n",
    "    gcluePosList = []\n",
    "\n",
    "    eqcluePosList = []\n",
    "\n",
    "    cluePos1List = []\n",
    "\n",
    "    gcluePos1List = []\n",
    "\n",
    "    eqcluePos1List = []\n",
    "    \n",
    "    skipList = []\n",
    "\n",
    "    @staticmethod\n",
    "    def getTextFromChunks(tree):\n",
    "        text = \"\"\n",
    "        for chunk in tree:\n",
    "            text += chunk.surface\n",
    "        return text\n",
    "\n",
    "    @staticmethod\n",
    "    def getTextFromTokens(chunk):\n",
    "        text = \"\"\n",
    "        for token in chunk:\n",
    "            text += token.surface\n",
    "        return text\n",
    "    \n",
    "    @staticmethod\n",
    "    def causalUniqueSentence( causals):\n",
    "        duplicatedIndex = []\n",
    "        df = pd.DataFrame()\n",
    "        df['sentence'] = [causal.sentence for causal in causals if causal.noneCheck()]\n",
    "        df['causal'] = [causal for causal in causals if causal.noneCheck()]\n",
    "        [duplicatedIndex.append(df[df['sentence'] == causal.sentence].index.tolist()) for causal in causals if causal.noneCheck()]\n",
    "        for indexes in duplicatedIndex:\n",
    "            for i, index in enumerate(indexes):\n",
    "                if i > 0:\n",
    "                    try:\n",
    "                        df = df.drop(index, axis=0)\n",
    "                    except:\n",
    "                        break\n",
    "        return [item['causal'] for index, item in df.iterrows()]\n",
    "\n",
    "    def __init__(self):\n",
    "        self.utilSet()\n",
    "\n",
    "    def utilSet(self):\n",
    "        \n",
    "        self.skipList = pd.read_csv(\"Util/ja_skip_list.csv\").dropna(subset=['clue'])['clue']\n",
    "        \n",
    "        self.clueList = pd.read_csv(\"Util/ja_clue_list.csv\").dropna(subset=['clue'])['clue']\n",
    "        self.eclueList = pd.read_csv(\"Util/ja_eclue_list.csv\").dropna(subset=['clue'])['clue']\n",
    "        self.gclueList = pd.read_csv(\"Util/ja_goal_clue_list.csv\").dropna(subset=['clue'])['clue']\n",
    "        self.geclueList = pd.read_csv(\"Util/ja_goal_eclue_list.csv\").dropna(subset=['clue'])['clue']\n",
    "        self.eqclueList = pd.read_csv(\"Util/ja_equal_clue_list.csv\").dropna(subset=['clue'])['clue']\n",
    "        self.eqeclueList = pd.read_csv(\"Util/ja_equal_eclue_list.csv\").dropna(subset=['clue'])['clue']\n",
    "\n",
    "        self.cluePosList = pd.read_csv(\"Util/ja_clue_list.csv\").dropna(subset=['clue'])[\"clue_pos\"]\n",
    "        self.gcluePosList = pd.read_csv(\"Util/ja_goal_clue_list.csv\").dropna(subset=['clue'])[\"clue_pos\"]\n",
    "        self.eqcluePosList = pd.read_csv(\"Util/ja_equal_clue_list.csv\").dropna(subset=['clue'])[\"clue_pos\"]\n",
    "        self.cluePos1List = pd.read_csv(\"Util/ja_clue_list.csv\").dropna(subset=['clue'])[\"clue_pos1\"]\n",
    "        self.gcluePos1List = pd.read_csv(\"Util/ja_goal_clue_list.csv\").dropna(subset=['clue'])[\"clue_pos1\"]\n",
    "        self.eqcluePos1List = pd.read_csv(\"Util/ja_equal_clue_list.csv\").dropna(subset=['clue'])[\"clue_pos1\"]\n",
    "\n",
    "        self.clueBFilterList = pd.read_csv(\"Util/ja_clue_list.csv\").dropna(subset=['clue'])['basis_pos']\n",
    "        #         self.eclueBFilterList = pd.read_csv(\"Util/ja_eclue_list.csv\").dropna(subset=['clue'])['basis_pos']\n",
    "        self.gclueBFilterList = pd.read_csv(\"Util/ja_goal_clue_list.csv\").dropna(subset=['clue'])['basis_pos']\n",
    "        #         self.geclueBFilterList = pd.read_csv(\"Util/ja_goal_eclue_list.csv\").dropna(subset=['clue'])['basis_pos']\n",
    "        self.eqclueBFilterList = pd.read_csv(\"Util/ja_equal_clue_list.csv\").dropna(subset=['clue'])['basis_pos']\n",
    "\n",
    "    #         self.eqeclueBFilterList = pd.read_csv(\"Util/ja_equal_eclue_list.csv\").dropna(subset=['clue'])['basis_pos']\n",
    "\n",
    "    #         self.clueRFilterList = pd.read_csv(\"Util/ja_clue_list.csv\").dropna(subset=['clue'])['result_pos']\n",
    "    # #         self.eclueRFilterList = pd.read_csv(\"Util/ja_eclue_list.csv\").dropna(subset=['clue'])['result_pos']\n",
    "    #         self.gclueRFilterList = pd.read_csv(\"Util/ja_goal_clue_list.csv\").dropna(subset=['clue'])['result_pos']\n",
    "    # #         self.geclueRFilterList = pd.read_csv(\"Util/ja_goal_eclue_list.csv\").dropna(subset=['clue'])['result_pos']\n",
    "    #         self.eqclueRFilterList = pd.read_csv(\"Util/ja_equal_clue_list.csv\").dropna(subset=['clue'])['result_pos']\n",
    "    # #         self.eqeclueRFilterList = pd.read_csv(\"Util/ja_equal_eclue_list.csv\").dropna(subset=['clue'])['result_pos']\n",
    "\n",
    "    def checkSkip(self, causal, skipList):\n",
    "        return any([skip in causal.sentence for skip in skipList])\n",
    "\n",
    "    def checkResult(self, causals):\n",
    "        [causals.remove(causal) for causal in causals if causal == None]\n",
    "        reslutCausals = []\n",
    "        try:\n",
    "            [[reslutCausals.append(causal2) for causal2 in causals if all(\n",
    "                [causal1.sentence == causal2.sentence, causal2.clue.pattern == Pattern.A or causal2.clue.pattern == Pattern.B,\n",
    "                 causal1.clue.pattern == Pattern.C or causal1.clue.pattern == Pattern.D])] for causal1 in causals]\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        return reslutCausals\n",
    "    \n",
    "    #todo:以上以下とかもここでやる\n",
    "    def checkPronoun(self, causal):\n",
    "        analyzer = CaboChaAnalyzer()\n",
    "        basis_tree = analyzer.parse(re.sub(\"、\", \"\",causal.basis))\n",
    "        for chunk in basis_tree:\n",
    "            for token in chunk:\n",
    "                if token.pos == \"名詞\" and token.pos1  == \"代名詞\":\n",
    "                    return True\n",
    "                elif token.pos == \"連体詞\" and re.match(r'こ|そ|あ|ど', token.surface):\n",
    "                    return True\n",
    "                elif token.pos == \"副詞\" and token.pos1  == \"助詞類接続\" and re.match(r'^こ|そ|あ|ど', token.surface):\n",
    "                    return True\n",
    "                elif token.surface == \"これ\" or token.surface == \"それ\" or token.surface == \"あれ\" or token.surface == \"どれ\" or token.surface == \"こう\" or token.surface == \"そう\" or token.surface == \"そちら\" or token.surface == \"こちら\" or token.surface == \"あちら\":\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    def checkCausalSize(self, causal, avarage=14):\n",
    "        analyzer = CaboChaAnalyzer()\n",
    "        return any([analyzer.parse(causal.sentence).chunk_size > avarage, analyzer.parse(causal.basis).chunk_size > avarage / 2, analyzer.parse(causal.result).chunk_size > avarage / 2])\n",
    "\n",
    "    def checkECausalSize(self, causal, avarage=14):\n",
    "        analyzer = CaboChaAnalyzer()\n",
    "        return any([analyzer.parse(causal.basis).chunk_size > avarage / 2, analyzer.parse(causal.result).chunk_size > avarage / 2])\n",
    "    \n",
    "    def causalUnique(self, causals):\n",
    "        causals = list(set(causals))\n",
    "        [causals.remove(causal) for causal in causals if causal == None]\n",
    "        try:\n",
    "            [[causals.remove(causal2) for causal2 in causals if\n",
    "              all([causal1.sentence == causal2.sentence, causal2.clue in causal1.clue, causal2.clue != causal1.clue])]\n",
    "             for causal1 in causals]\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        return causals\n",
    "\n",
    "    def causalFilter(self, causals, basis_list, result_list):\n",
    "        analyzer = CaboChaAnalyzer()\n",
    "        newCausals = []\n",
    "        for causal in causals:\n",
    "            if causal.pattern != Pattern.E:\n",
    "                tree = analyzer.parse(re.sub(\"、\", \"\",causal.basis))\n",
    "                try:\n",
    "                    chunk = tree[tree.chunk_size - 1] if tree.chunk_size > 0 else tree[0]\n",
    "                    if any([chunk[chunk.token_size - 1].pos == str(basis_list[causal.causalId]) and str(basis_list[causal.causalId]) != \"nan\", str(basis_list[causal.causalId]) == \"nan\"]) and not self.checkPronoun(causal) and not self.checkCausalSize(causal) and tree.chunk_size > 2:# and not re.search(r'www|html|http|jpg|png|jpeg|com', causal.sentence) and not re.search(r'www|html|http|jpg|png|jpeg|com', causal.basis):\n",
    "                        newCausals.append(causal)\n",
    "                except IndexError:\n",
    "                    pass\n",
    "            if causal.pattern == Pattern.E and not self.checkPronoun(causal) and not self.checkECausalSize(causal):# and not re.search(r'www|html|http|jpg|png|jpeg|com', causal.sentence) and not re.search(r'www|html|http|jpg|png|jpeg|com', causal.basis):\n",
    "                newCausals.append(causal)\n",
    "        return newCausals\n",
    "\n",
    "    def checkCorePos(self, causal, cluePosList, cluePos1List):\n",
    "        if causal.pattern == Pattern.E:\n",
    "            return True\n",
    "        if str(cluePosList[causal.causalId]) == \"nan\":\n",
    "            return True\n",
    "        if str(cluePos1List[causal.causalId]) == \"nan\":\n",
    "            clue_pos1 = []\n",
    "        clue_pos = str(cluePosList[causal.causalId]).split(\",\")\n",
    "        clue_pos1 = str(cluePos1List[causal.causalId]).split(\",\")\n",
    "        analyzer = CaboChaAnalyzer()\n",
    "        tree = analyzer.parse(causal.sentence)\n",
    "        check_token = []\n",
    "        for chunk in tree:\n",
    "            if causal.clue in chunk.surface:\n",
    "                [check_token.append(token) for token in chunk if token.surface in causal.clue]\n",
    "                if \"\".join(token.surface for token in check_token) == causal.clue:\n",
    "                    break\n",
    "        for index, token in enumerate(check_token):\n",
    "            if token.pos == clue_pos[index]:\n",
    "                if clue_pos1 == []:\n",
    "                    return True\n",
    "                elif clue_pos1[index] == \"\" or clue_pos1[index] == None:\n",
    "                    break\n",
    "                elif token.pos1 == clue_pos1[index]:\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "    def checkKindSentence(self, separateChunks, skipChunk=None):\n",
    "        subj = \"\"\n",
    "        text = \"\"\n",
    "        for chunks in separateChunks:\n",
    "            lastChunk = chunks[len(chunks) - 1]\n",
    "            lastToken = lastChunk[lastChunk.token_size - 1]\n",
    "            if skipChunk != None and skipChunk in chunks:\n",
    "                break\n",
    "            if lastToken.pos == \"記号\":\n",
    "                lastToken = lastChunk[lastChunk.token_size - 2]\n",
    "            # 逆説\n",
    "            if lastToken.pos == \"助詞\" and lastToken.pos1 == \"接続助詞\" and lastToken.surface == \"が\":\n",
    "                separateChunks.remove(chunks)\n",
    "            # 主節\n",
    "            elif lastToken.pos == \"助詞\" and lastToken.pos1 == \"格助詞\":\n",
    "                subj = extractor.getTextFromChunks(chunks)\n",
    "            elif lastToken.pos == \"助詞\" and lastToken.pos1 == \"係助詞\" and lastToken.surface == \"も\":\n",
    "                separateChunks.remove(chunks)\n",
    "        #             elif lastToken.pos == \"助動詞\":\n",
    "        #                 separateChunks.remove(chunks)\n",
    "        for chunks in separateChunks:\n",
    "            text += extractor.getTextFromChunks(chunks)\n",
    "        return text, subj\n",
    "\n",
    "    def getCoreIds(self, tree, clue):\n",
    "        ids = []\n",
    "        [ids.append(chunk.id) for chunk in tree if clue in chunk.surface or clue in chunk.surface + \"。\"]\n",
    "        return ids\n",
    "\n",
    "    def replaceCoreChunk(self, coreChunk, clue):\n",
    "        return coreChunk.surface.strip(clue)\n",
    "\n",
    "    def getSeparateChunk(self, tree):\n",
    "        ids = []\n",
    "        chunks = []\n",
    "        [ids.append(chunk.id) for chunk in tree[tree.chunk_size - 1].prev_links]\n",
    "        ids.sort()\n",
    "        for index, chunkId in enumerate(ids):\n",
    "            if chunkId == min(ids):\n",
    "                chunks.append(tree[:chunkId + 1])\n",
    "            elif chunkId == max(ids):\n",
    "                chunks.append(tree[ids[index - 1] + 1:chunkId + 1])\n",
    "            else:\n",
    "                chunks.append(tree[ids[index - 1] + 1: chunkId + 1])\n",
    "        chunks.append([tree[tree.chunk_size - 1]])\n",
    "        return chunks\n",
    "\n",
    "    def getResult(self, chunks):\n",
    "        text = extractor.getTextFromTokens(chunks)\n",
    "        text = re.sub(r'^といって', \"\", text)\n",
    "        text = re.sub(r'^ため', \"\", text)\n",
    "        text = re.sub(r'^だこそ', \"\", text)\n",
    "        text = re.sub(r'^こそ', \"\", text)\n",
    "        text = re.sub(r'^ですの', \"\", text)\n",
    "        text = re.sub(r'^です', \"\", text)\n",
    "        text = re.sub(r'^だ', \"\", text)\n",
    "        text = re.sub(r'^の', \"\", text)\n",
    "        if not re.match(\"なん\", text):\n",
    "            text = re.sub(r'^な', \"\", text)\n",
    "        text = re.sub(r'^、', \"\", text)\n",
    "        return text\n",
    "\n",
    "    def getBasis(self, chunks, clue_basis=\"\"):\n",
    "        remover = \"\"\n",
    "        try:\n",
    "            for token in chunks[0]:\n",
    "                if token.surface != \"少し\" or token.pos == \"接続詞\" or all([token.pos == \"副詞\", token.pos1 == \"助詞類接続\"]) or all([token.pos == \"名詞\", token.pos1 == \"数\"]):\n",
    "                    remover += token.surface\n",
    "                elif chunks[0].surface == \"逆に\" or chunks[0].surface == \"逆に、\" or chunks[0].surface == \"反対に\" or chunks[0].surface == \"反対に、\" or chunks[0].surface == \"ぜひ、\" or chunks[0].surface == \"ぜひ\" or chunks[0].surface == \"是非、\" or chunks[0].surface == \"是非\"  or chunks[0].surface == \"具体的\" or chunks[0].surface == \"もちろん\":\n",
    "                    remover = chunks[0].surface\n",
    "        except:\n",
    "            pass\n",
    "        text = extractor.getTextFromTokens(chunks) + clue_basis if not clue_basis in extractor.getTextFromTokens(chunks) else extractor.getTextFromTokens(chunks) \n",
    "        text = re.sub(remover, \"\", text)\n",
    "        text = re.sub(r'^、', \"\", text)\n",
    "        text = re.sub(r'、$', \"\", text)\n",
    "        return text\n",
    "    \n",
    "    def getResultFromText(self, text):\n",
    "        text = re.sub(r'^といって', \"\", text)\n",
    "        text = re.sub(r'^だこそ', \"\", text)\n",
    "        text = re.sub(r'^こそ', \"\", text)\n",
    "        text = re.sub(r'^ですの', \"\", text)\n",
    "        text = re.sub(r'^です', \"\", text)\n",
    "        text = re.sub(r'^だ', \"\", text)\n",
    "        text = re.sub(r'^の', \"\", text)\n",
    "        text = re.sub(r'^な', \"\", text)\n",
    "        text = re.sub(r'^、', \"\", text)\n",
    "        return text\n",
    "\n",
    "    def getBasisFromText(self, text, clue_basis=\"\"):\n",
    "        analyzer = CaboChaAnalyzer()\n",
    "        chunks = analyzer.parse(text)\n",
    "        remover = \"\"\n",
    "        try:\n",
    "            for token in chunks[0]:\n",
    "                if token.pos == \"接続詞\" or all([token.pos == \"副詞\", token.pos1 == \"助詞類接続\"]) or all([token.pos == \"名詞\", token.pos1 == \"数\"]):\n",
    "                    remover += token.surface\n",
    "                elif chunks[0].surface == \"逆に\" or chunks[0].surface == \"逆に、\" or chunks[0].surface == \"反対に\" or chunks[0].surface == \"反対に、\" or chunks[0].surface == \"ぜひ、\" or chunks[0].surface == \"ぜひ\" or chunks[0].surface == \"是非、\" or chunks[0].surface == \"是非\"  or chunks[0].surface == \"具体的\" or chunks[0].surface == \"もちろん\":\n",
    "                    remover = chunks[0].surface\n",
    "        except:\n",
    "            pass\n",
    "        text = extractor.getTextFromTokens(chunks) + clue_basis\n",
    "        text = re.sub(remover, \"\", text)\n",
    "        text = re.sub(r'^、', \"\", text)\n",
    "        return text\n",
    "\n",
    "    def getCausalExpression(self, tree, clue, coreId, sentence, beforeSentence, eclueList, causalId, line, relation):\n",
    "        causal = Causal()\n",
    "        coreChunk = tree[coreId]\n",
    "        sentence, subj = self.checkKindSentence(self.getSeparateChunk(tree))\n",
    "        analyzer = CaboChaAnalyzer()\n",
    "        tree = analyzer.parse(sentence)\n",
    "        causal.subj = subj\n",
    "        causal.sentence = sentence\n",
    "        causal.line = line\n",
    "        causal.causalId = causalId\n",
    "        causal.relation = relation\n",
    "        for eclue in eclueList:\n",
    "            if re.match(str(eclue), coreChunk.surface):\n",
    "                causal.pattern = Pattern.E\n",
    "                causal.result = self.getResultFromText(sentence.replace(clue, \"\"))\n",
    "                causal.basis = self.getBasisFromText(beforeSentence)\n",
    "                causal.sentence = beforeSentence + \"。\" + sentence\n",
    "                causal.clue = eclue\n",
    "                return causal if causal.noneCheck else None\n",
    "        if not clue.endswith(\"。\") and not coreChunk.surface.endswith(clue + \"。\"):\n",
    "            causal.basis = self.getBasis(tree[: coreId], clue_basis=self.replaceCoreChunk(coreChunk, clue))\n",
    "            causal.result = self.getResult(tree[coreId + 1: tree.chunk_size])\n",
    "            causal.clue = clue\n",
    "            causal.pattern = Pattern.A if causal.subj == \"\" else Pattern.B\n",
    "            return causal if causal.noneCheck else None\n",
    "        elif (coreChunk.surface + \"。\").endswith(clue) or all(\n",
    "                [coreChunk.surface.endswith(clue), coreChunk.surface.endswith(\"。\")]):\n",
    "            if causal.subj == \"\":\n",
    "                causal.pattern = Pattern.D\n",
    "                causal.result = self.getResult(tree[:coreId])\n",
    "                causal.basis = beforeSentence\n",
    "                causal.sentence = beforeSentence + \"。\" + sentence #todo: is it  need ??\n",
    "                causal.clue = clue\n",
    "            else:\n",
    "                causal.pattern = Pattern.C\n",
    "                chunkId = 0\n",
    "                for chunk in tree:\n",
    "                    if subj in chunk.surface:\n",
    "                        chunkId = chunk.id\n",
    "                causal.result = self.getResult(tree[chunkId + 1:coreId])\n",
    "                causal.basis = subj\n",
    "                causal.clue = clue\n",
    "            return causal if causal.noneCheck else None\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def getInga(self, texts):\n",
    "        causals = []\n",
    "        for line, text in enumerate(texts):\n",
    "            analyzer = CaboChaAnalyzer()\n",
    "            tree = analyzer.parse(text)\n",
    "            if tree.chunk_size == 0:\n",
    "                break\n",
    "            beforeSentence = texts[line - 1] if line > 0 else \"\"\n",
    "            for index, clue in enumerate(self.clueList):\n",
    "                causals.extend([self.getCausalExpression(tree, clue, coreId, text, beforeSentence, self.eclueList, index, line, Relation.cause) for coreId in self.getCoreIds(tree, clue)])\n",
    "        [print(\"Before\", \"subj\", causal.subj, \"basis\", causal.basis, \"reslut\", causal.result, causal.clue, causal.causalId, causal.pattern.toJson()) for causal in causals]\n",
    "        causals = self.causalUnique(causals)\n",
    "        causals = self.causalFilter(causals, self.clueBFilterList, self.clueRFilterList)\n",
    "        causals = [causal for causal in causals if self.checkCorePos(causal, self.cluePosList, self.cluePos1List)]\n",
    "        return causals\n",
    "\n",
    "    def getGoal(self, texts):\n",
    "        causals = []\n",
    "        for line, text in enumerate(texts):\n",
    "            analyzer = CaboChaAnalyzer()\n",
    "            tree = analyzer.parse(text)\n",
    "            if tree.chunk_size == 0:\n",
    "                break\n",
    "            beforeSentence = texts[line - 1] if line > 0 else \"\"\n",
    "            for index, clue in enumerate(self.gclueList):\n",
    "                causals.extend(\n",
    "                    [self.getCausalExpression(tree, clue, coreId, text, beforeSentence, self.geclueList, index, line, Relation.goal)\n",
    "                     for coreId in self.getCoreIds(tree, clue)])\n",
    "        [print(\"Before\", \"subj\", causal.subj, \"basis\", causal.basis, \"reslut\", causal.result, causal.clue, causal.causalId, causal.pattern.toJson()) for causal in causals]\n",
    "        causals = self.causalUnique(causals)\n",
    "        causals = self.causalFilter(causals, self.gclueBFilterList, self.gclueRFilterList)\n",
    "        causals = [causal for causal in causals if self.checkCorePos(causal, self.gcluePosList, self.gcluePos1List)]\n",
    "        return causals\n",
    "\n",
    "    def getEqual(self, texts):\n",
    "        causals = []\n",
    "        for line, text in enumerate(texts):\n",
    "            analyzer = CaboChaAnalyzer()\n",
    "            tree = analyzer.parse(text)\n",
    "            if tree.chunk_size == 0:\n",
    "                break\n",
    "            beforeSentence = texts[line - 1] if line > 0 else \"\"\n",
    "            for index, clue in enumerate(self.eqclueList):\n",
    "                causals.extend(\n",
    "                    [self.getCausalExpression(tree, clue, coreId, text, beforeSentence, self.eqeclueList, index, line, Relation.equal)\n",
    "                     for coreId in self.getCoreIds(tree, clue)])\n",
    "        [print(\"Before\", \"subj\", causal.subj, \"basis\", causal.basis, \"reslut\", causal.result, causal.clue, causal.causalId, causal.pattern.toJson()) for causal in causals]\n",
    "        causals = self.causalUnique(causals)\n",
    "        causals = self.causalFilter(causals, self.eqclueBFilterList, self.eqclueRFilterList)\n",
    "        causals = [causal for causal in causals if self.checkCorePos(causal, self.eqcluePosList, self.eqcluePos1List)]\n",
    "#         causals = self.checkResult(causals)\n",
    "        return causals\n",
    "    \n",
    "    @asyncio.coroutine\n",
    "    async def coroutineGetInga(self, texts):\n",
    "        await asyncio.sleep(1)\n",
    "        try:\n",
    "            causals = []\n",
    "            for line, text in enumerate(texts):\n",
    "                analyzer = CaboChaAnalyzer()\n",
    "                tree = analyzer.parse(text)\n",
    "                if tree.chunk_size == 0:\n",
    "                    break\n",
    "                beforeSentence = texts[line - 1] if line > 0 else \"\"\n",
    "                for index, clue in enumerate(self.clueList):\n",
    "                    causals.extend([self.getCausalExpression(tree, clue, coreId, text, beforeSentence, self.eclueList, index, line, Relation.cause) for coreId in self.getCoreIds(tree, clue)])\n",
    "            [print(\"Before\", \"subj\", causal.subj, \"basis\", causal.basis, \"reslut\", causal.result, causal.clue, causal.causalId, causal.pattern.toJson()) for causal in causals]\n",
    "            causals = self.causalUnique(causals)\n",
    "            causals = self.causalFilter(causals, self.clueBFilterList, self.clueRFilterList)\n",
    "            causals = [causal for causal in causals if self.checkCorePos(causal, self.cluePosList, self.cluePos1List)]\n",
    "            return causals\n",
    "        except:\n",
    "            return []\n",
    "\n",
    "    @asyncio.coroutine\n",
    "    async def coroutineGetGoal(self, texts):\n",
    "        await asyncio.sleep(1)\n",
    "        causals = []\n",
    "        for line, text in enumerate(texts):\n",
    "            analyzer = CaboChaAnalyzer()\n",
    "            tree = analyzer.parse(text)\n",
    "            if tree.chunk_size == 0:\n",
    "                break\n",
    "            beforeSentence = texts[line - 1] if line > 0 else \"\"\n",
    "            for index, clue in enumerate(self.gclueList):\n",
    "                causals.extend(\n",
    "                    [self.getCausalExpression(tree, clue, coreId, text, beforeSentence, self.geclueList, index, line, Relation.goal)\n",
    "                     for coreId in self.getCoreIds(tree, clue)])\n",
    "        [print(\"Before\", \"subj\", causal.subj, \"basis\", causal.basis, \"reslut\", causal.result, causal.clue, causal.causalId, causal.pattern.toJson()) for causal in causals]\n",
    "        causals = self.causalUnique(causals)\n",
    "        causals = self.causalFilter(causals, self.gclueBFilterList, self.gclueRFilterList)\n",
    "        causals = [causal for causal in causals if self.checkCorePos(causal, self.gcluePosList, self.gcluePos1List)]\n",
    "        return causals\n",
    "\n",
    "    @asyncio.coroutine\n",
    "    async def coroutineGetEqual(self, texts):\n",
    "        await asyncio.sleep(1)\n",
    "        causals = []\n",
    "        for line, text in enumerate(texts):\n",
    "            analyzer = CaboChaAnalyzer()\n",
    "            tree = analyzer.parse(text)\n",
    "            if tree.chunk_size == 0:\n",
    "                break\n",
    "            beforeSentence = texts[line - 1] if line > 0 else \"\"\n",
    "            for index, clue in enumerate(self.eqclueList):\n",
    "                causals.extend(\n",
    "                    [self.getCausalExpression(tree, clue, coreId, text, beforeSentence, self.eqeclueList, index, line, Relation.equal)\n",
    "                     for coreId in self.getCoreIds(tree, clue)])\n",
    "        [print(\"Before\", \"subj\", causal.subj, \"basis\", causal.basis, \"reslut\", causal.result, causal.clue, causal.causalId, causal.pattern.toJson()) for causal in causals]\n",
    "        causals = self.causalUnique(causals)\n",
    "        causals = self.causalFilter(causals, self.eqclueBFilterList, self.eqclueRFilterList)\n",
    "        causals = [causal for causal in causals if self.checkCorePos(causal, self.eqcluePosList, self.eqcluePos1List)]\n",
    "#         causals = self.checkResult(causals)\n",
    "        return causals\n",
    "\n",
    "    @asyncio.coroutine\n",
    "    async def coroutine(self, crawlers, relation):\n",
    "        await asyncio.sleep(1)\n",
    "        if relation == Relation.cause:\n",
    "            tasks = [self.coroutineGetInga(crawler.article) for crawler in crawlers]\n",
    "        elif relation == Relation.goal:\n",
    "            tasks = [self.coroutineGetGoal(crawler.article) for crawler in crawlers]\n",
    "        elif relation == Relation.equal:\n",
    "            tasks = [self.coroutineGetEqual(crawler.article) for crawler in crawlers]\n",
    "        return await asyncio.gather(*tasks)\n",
    "    \n",
    "    def extract(self, crawlers, relation):\n",
    "        causals = []\n",
    "        for crawler in crawlers:\n",
    "            if relation == Relation.cause:\n",
    "                ingas = self.getInga(crawler.article)\n",
    "                ingas = extractor.causalUniqueSentence(ingas)\n",
    "                ingas = [inga for inga in ingas if not self.checkSkip(inga, self.skipList)]\n",
    "                crawler.causals = ingas\n",
    "                causals.extend(ingas)\n",
    "            elif relation == Relation.goal:\n",
    "                goals = self.getGoal(crawler.article)\n",
    "                goals = extractor.causalUniqueSentence(goals)\n",
    "                goals = [goal for goal in goals if not self.checkSkip(goal, self.skipList)]\n",
    "                crawler.causals = goals\n",
    "                causals.extend(goals)\n",
    "            elif relation == Relation.equal:\n",
    "                equals = self.getEqual(crawler.article)\n",
    "                equals = extractor.causalUniqueSentence(equals)\n",
    "                equals = [equal for equal in equals if not self.checkSkip(equal, self.skipList)]\n",
    "                crawler.causals = equals\n",
    "                causals.extend(equals)\n",
    "        causals = extractor.causalUniqueSentence(causals)\n",
    "        [print(\"after\", \"subj\", causal.subj, \"basis\", causal.basis, \"reslut\", causal.result, causal.clue,\n",
    "               causal.causalId, causal.pattern.toJson()) for causal in causals]\n",
    "        return causals, crawlers\n",
    "    \n",
    "#     def extract(self, crawlers, relation):\n",
    "#         causals = []\n",
    "#         ex_causals = causals.extend\n",
    "#         loop = asyncio.new_event_loop()\n",
    "#         gcausals = loop.run_until_complete(self.coroutine(crawlers, relation))\n",
    "#         loop.close()\n",
    "#         gcausals = extractor.causalUniqueSentence(gcausals)\n",
    "#         gcausals = [gcausal for gcausal in gcausals if not self.checkSkip(gcausal, self.skipList)]\n",
    "#         crawler.causals = gcausals\n",
    "#         ex_causals(gcausals)\n",
    "#         causals = extractor.causalUniqueSentence(causals)\n",
    "#         [print(\"after\", \"subj\", causal.subj, \"basis\", causal.basis, \"reslut\", causal.result, causal.clue, causal.causalId, causal.pattern.toJson()) for causal in causals]\n",
    "#         return causals, crawlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data.ja.word_vector import WordEmbeddings\n",
    "import MeCab\n",
    "from gensim.models import word2vec\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from data.scraping import googleScraping\n",
    "import termextract.mecab\n",
    "import termextract.core\n",
    "import collections\n",
    "import asyncio\n",
    "import tornado.ioloop\n",
    "from tornado.iostream import IOStream\n",
    "\n",
    "class causalRepository:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.save_path = \"Util/causal.model\"\n",
    "        self.keyword = \"\"\n",
    "        self.searcher = googleScraping.google_search\n",
    "        self.scraper = googleScraping.getMainJAText\n",
    "        \n",
    "    def routineCrawle(self, init_keyword, limit=3, per_limit=20):\n",
    "        keywords = []\n",
    "        for i in range(limit):\n",
    "            print(\"Epoch:\" + str(i + 1))\n",
    "            if i == 0:\n",
    "                print(\"Epoch of search: init\"+ \"\\n\" + \"Keyword: \" + init_keyword)\n",
    "                crawlers = self.syncCrawle(init_keyword, limit=per_limit)\n",
    "            else:\n",
    "                crawlers = []\n",
    "                ex_crawlers = crawlers.extend\n",
    "                for index ,keyword in enumerate(keywords):\n",
    "                    print(\"Epoch of search: \" + str(index + 1) + \" / \" + str(len(keywords)) + \"\\n\" + \"Keyword: \" + keyword)\n",
    "                    gcrawlers = repository.syncCrawle(keyword)\n",
    "                    self.setCrawlerData(gcrawlers)\n",
    "                    ex_crawlers(gcrawlers)\n",
    "            self.setCrawlerData(crawlers)\n",
    "            print(\"Saved \" + str(len(crawlers)) + \" of crawlers\")\n",
    "            loop = asyncio.new_event_loop()\n",
    "            keywords = loop.run_until_complete(repository.generateKeyword(crawlers))\n",
    "            print(\"Generated \"+ str(len(keywords)) + \" of keywords\")\n",
    "            loop.close()\n",
    "    \n",
    "    def causalToVector(self, sentences, causals, keyword):\n",
    "        wordEmbedding = WordEmbeddings()\n",
    "        preTexts = \"\".join(self.wakati(sentence) for sentence in sentences)\n",
    "        preTexts = re.sub(r'\\n', \"\", preTexts)\n",
    "        texts = preTexts.split(\" \")\n",
    "        print(texts)\n",
    "        wordEmbedding.train_word_embeddings(texts, self.save_path, sg=0, size=9999, min_count=1, max_vocab_size=None, trim_rule=None, sample=0)\n",
    "        wordEmbedding.load_word_embeddings(self.save_path)\n",
    "        \n",
    "        causalSubjVecs = [wordEmbedding.get_vector(causal.subj) for causal in causals]\n",
    "        causalBasisVecs = [wordEmbedding.get_vector(causal.basis) for causal in causals]\n",
    "        causalResultVecs = [wordEmbedding.get_vector(causal.result) for causal in causals]\n",
    "        causalClueVecs = [wordEmbedding.get_vector(causal.clue) for causal in causals]\n",
    "        causalSentenceVecs = [wordEmbedding.get_vector(causal.sentence) for causal in causals]\n",
    "\n",
    "        causalPatternVecs = [causal.pattern.toOneHot() for causal in causals]\n",
    "        \n",
    "        try:\n",
    "            keywordVec = wordEmbedding.get_vector(keyword)\n",
    "        except:\n",
    "            keywordVec = np.zeros\n",
    "\n",
    "        causalSubjCosSims = [wordEmbedding.cos_sim(keywordVec, subj) for subj in causalSubjVecs]\n",
    "        causalBasisCosSims = [wordEmbedding.cos_sim(keywordVec, basis) for basis in causalBasisVecs]\n",
    "        causalResultCosSims = [wordEmbedding.cos_sim(keywordVec, result) for result in causalResultVecs]\n",
    "        causalClueCosSims = [wordEmbedding.cos_sim(keywordVec, clue) for clue in causalClueVecs]\n",
    "        causalSentenceCosSims = [wordEmbedding.cos_sim(keywordVec, sentence) for sentence in causalSentenceVecs]\n",
    "        \n",
    "        [print(subj)  for subj in causalSubjVecs]\n",
    "        return causalSubjVecs, causalBasisVecs, causalResultVecs, causalClueVecs, causalSentenceVecs, causalPatternVecs, causalSubjCosSims, causalBasisCosSims, causalResultCosSims, causalClueCosSims, causalSentenceCosSims\n",
    "        \n",
    "    def lexRankCausal(self, causals):\n",
    "        cr = causal_rank()\n",
    "        \n",
    "#         causalSubjRanks = cr.lex_rank([self.wakatiArray(causal.subj) for causal in causals])\n",
    "        causalBasisRanks = cr.lex_rank([self.wakatiArray(causal.basis) for causal in causals if causal.noneCheck()])\n",
    "        causalResultRanks = cr.lex_rank([self.wakatiArray(causal.result) for causal in causals if causal.noneCheck()])\n",
    "        causalClueRanks = cr.lex_rank([self.wakatiArray(causal.clue) for causal in causals if causal.noneCheck()])\n",
    "#         causalSentenceRanks = cr.lex_rank([self.wakatiArray(causal.sentence) for causal in causals if causal.noneCheck()])\n",
    "        \n",
    "#         causalPatternRanks = [causal.pattern.toOneHot() for causal in causals if causal.noneCheck()]\n",
    "        \n",
    "        return  causalBasisRanks, causalResultRanks, causalClueRanks\n",
    "\n",
    "    \n",
    "    def wakati(self, sentence):\n",
    "        mecab = MeCab.Tagger (\"-Owakati\")\n",
    "        return mecab.parse(sentence)\n",
    "    \n",
    "    def wakatiArray(self, sentence):\n",
    "        return [re.sub('\\n', \"\", prune_sentence) for prune_sentence in self.wakati(sentence).split(\" \")]\n",
    "    \n",
    "    def tokenizes(self, sentences):\n",
    "        return [self.wakati(sentence) for sentence in sentences]\n",
    "    \n",
    "    def tokenize(self, sentence):\n",
    "        return self.wakati(sentence)\n",
    "    \n",
    "    def syncCrawle(self, keyword, limit=10):\n",
    "        crawlers = []\n",
    "        ex_crawlers = crawlers.extend\n",
    "        loop = asyncio.new_event_loop()\n",
    "        gcrawlers = loop.run_until_complete(repository.routeCrawle(keyword, limit=limit))\n",
    "        loop.close()\n",
    "        ex_crawlers(gcrawlers)\n",
    "        return crawlers\n",
    "    \n",
    "    @asyncio.coroutine\n",
    "    async def generateCrawlerFromURL(self, url, keyword):\n",
    "        await asyncio.sleep(1)\n",
    "        text = self.scraper(url)\n",
    "        crawler = Crawler()\n",
    "        crawler.keyword = keyword\n",
    "        crawler.url = url\n",
    "        crawler.article = text\n",
    "        print(url, \"\\n\",text)\n",
    "        return crawler\n",
    "\n",
    "    @asyncio.coroutine\n",
    "    async def routeCrawle(self, keyword, limit=10):\n",
    "        try:\n",
    "            await asyncio.sleep(1)\n",
    "            urls = self.searcher(keyword)\n",
    "        except:\n",
    "            pass\n",
    "        tasks = [self.generateCrawlerFromURL(url, keyword) for url in urls if url != \"\"]\n",
    "        return await asyncio.gather(*tasks)\n",
    "    \n",
    "    def scraping(self, keyword):\n",
    "        self.keyword = keyword\n",
    "        crawlers = []\n",
    "        try:\n",
    "            urls = self.searcher(keyword)\n",
    "        except:\n",
    "            pass\n",
    "        for url in urls:\n",
    "            if url == \"\":\n",
    "                break\n",
    "            try:\n",
    "                text = self.scraper(url)\n",
    "                crawler = Crawler()\n",
    "                crawler.keyword = keyword\n",
    "                crawler.url = url\n",
    "                crawler.article = text\n",
    "                print(url, \"\\n\", text)\n",
    "                crawlers.append(crawler)\n",
    "            except:\n",
    "                return crawlers\n",
    "        return crawlers\n",
    "    \n",
    "    def generateTerm(self, crawler, limit=5):\n",
    "        parser = MeCab.Tagger ()\n",
    "        join = \"\".join\n",
    "        sentence = join(article for i ,article in enumerate(crawler.article) if i < 100)\n",
    "        analyzed = parser.parse(sentence)\n",
    "        frequency = termextract.mecab.cmp_noun_dict(analyzed)\n",
    "        LR = termextract.core.score_lr(frequency,\n",
    "                 ignore_words=termextract.mecab.IGNORE_WORDS,\n",
    "                 lr_mode=1, average_rate=1\n",
    "             )\n",
    "        term_imp = termextract.core.term_importance(frequency, LR)\n",
    "        data_collection = collections.Counter(term_imp)\n",
    "#         for cmp_noun, value in data_collection.most_common():\n",
    "#             print(termextract.core.modify_agglutinative_lang(cmp_noun), value, sep=\"\\t\")\n",
    "        return [termextract.core.modify_agglutinative_lang(cmp_noun) for cmp_noun, value in data_collection.most_common()][:limit]\n",
    "\n",
    "    def termExtract(self, crawlers):\n",
    "        values = []\n",
    "        [values.extend(self.generateTerm(crawler)) for crawler in crawlers]\n",
    "        return values\n",
    "    \n",
    "    @asyncio.coroutine\n",
    "    async def generateKeyword(self, crawlers):\n",
    "        save_keywords = pd.read_csv('Util/crawlers_data.csv')['Keyword']\n",
    "        await asyncio.sleep(1)\n",
    "        values = list(set(self.termExtract(crawlers)))\n",
    "        keywords = []\n",
    "        for value in values:\n",
    "            keywords.append(value + \" \" + Relation.cause.toJaKeyword())\n",
    "            keywords.append(value + \" \" + Relation.goal.toJaKeyword())\n",
    "            keywords.append(value + \" \" + Relation.equal.toJaKeyword())\n",
    "        return list( set(keywords) - (set(keywords) & set(save_keywords)))\n",
    "         \n",
    "    def setListUid(self, proparties):\n",
    "        uidList = \"\"\n",
    "        for proparty in proparties:\n",
    "            uidList += proparty.uid + \",\" if proparty != proparties[-1] else proparty.uid\n",
    "        return uidList\n",
    "                \n",
    "    def setCrawlerData(self, crawlers):\n",
    "        df = pd.read_csv('Util/crawlers_data.csv')\n",
    "        for crawler in crawlers:\n",
    "            try:\n",
    "                df = df.drop(df[df['Article'] == \"\".join(article + \"。\" for article in crawler.article)].index.tolist(), axis=0)\n",
    "                df = df.append(pd.Series([crawler.uid ,crawler.keyword, crawler.url, \"\".join(article + \"。\" for article in crawler.article), self.setListUid(crawler.causals), crawler.createdAt, crawler.updatedAt],  index=df.columns), ignore_index=True)\n",
    "            except:\n",
    "                df = df.append(pd.Series([crawler.uid ,crawler.keyword, crawler.url, crawler.article, self.setListUid(crawler.causals), crawler.createdAt, crawler.updatedAt],  index=df.columns), ignore_index=True)\n",
    "        df.to_csv('Util/crawlers_data.csv', index=None) \n",
    "    \n",
    "    def setCausalData(self, causals, crawlers):\n",
    "        df = pd.read_csv('Util/causal_train_data.csv')\n",
    "        self.setCrawlerData(crawlers)\n",
    "        for causal in causals:\n",
    "            if causal.noneCheck():\n",
    "                try:\n",
    "                    df = df.drop(df[df['Uid'] == causal.uid].index.tolist(), axis=0)\n",
    "                    df = df.append(pd.Series([causal.uid ,1,causal.basis, causal.result, causal.subj, causal.pattern.toJson(), causal.clue, causal.filePath, causal.line, causal.causalId, causal.sentence, causal.relation.toJson(), causal.createdAt, causal.updatedAt, self.keyword],  index=df.columns), ignore_index=True)\n",
    "                except:\n",
    "                    df = df.append(pd.Series([causal.uid ,1,causal.basis, causal.result, causal.subj, causal.pattern.toJson(), causal.clue, causal.filePath, causal.line, causal.causalId, causal.sentence, causal.relation.toJson(), causal.createdAt, causal.updatedAt, self.keyword],  index=df.columns), ignore_index=True)\n",
    "        df.to_csv('Util/causal_train_data2.csv', index=None)\n",
    "        \n",
    "    def analyzeCausals(self, causals):\n",
    "        analyzer = CaboChaAnalyzer()\n",
    "        num = np.zeros (len(causals))\n",
    "        numB = np.zeros (len(causals))\n",
    "        numR = np.zeros (len(causals))\n",
    "        for i,causal in enumerate(causals):\n",
    "            num[i] = analyzer.parse(causal.sentence).chunk_size\n",
    "            numB[i] = analyzer.parse(causal.basis).chunk_size\n",
    "            numR[i] = analyzer.parse(causal.result).chunk_size\n",
    "        print(\"sentence_avarage\",np.average(num),\"basis_avarage\",np.average(numB),\"result_avarage\",np.average(numR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://peco-japan.com/52258 \n",
      " ['犬は、いわゆる空気を読むのが得意な動物です', '喧嘩をしている時の不穏な空気を察知し、自分自身の不安な気持ちを抑えるために、喧嘩はやめましょうと割り込んできます', '自分より大きな体格の人間や、大型犬の喧嘩の仲裁に小型犬が割り込んでくることもあります', 'この、犬が喧嘩の仲裁に入るような行動は、カーミングシグナルの一種です', 'このカーミングシグナルとは、犬特有のコミュニケーションで、犬が野生時代に群れで暮らしていた時から備わっていたものです', '群れの中では、リーダーを中心として円滑に暮らしていく必要があったため、ほかの犬に自分の意思を伝えるためのボディランゲージが発達しました', 'ペットとして飼われている犬の場合、カーミングシグナルはあまり親しくない犬に対して使われることが多いようです', 'たとえば、散歩中に初めて出会った犬に対し、私は争うつもりはありませんよという気持ちを伝えるために背中を向けるなどの行動があります', '自ら争う気がないことを示すことで、犬同士の無用な争いを避けているのです', 'この発展した形として、人間同士の口論に割り込んで仲裁するような行動を取るのも、カーミングシグナルの一種だと考えられています', '対象が犬であろうと、人間であろうと、犬はその行動で無用な争いはやめなさいと伝えてくれているのです', 'カーミングシグナルの種類yuttana ockcom  このようにカーミングシグナルは、もともとは犬同士のコミュニケーション手段として発達しましたが、人間に対しても使われることがあるのです', 'カーミングシグナルには様々な種類があり、その数は現在わかっているだけでも30近くに上ります', '以下は、代表的なカーミングシグナルの一例です', '自分の鼻を舐める飼い主やほかの犬が怒っていると感じた時、犬は相手を落ち着かせようとして自分の鼻を舐めます', '犬が活動している時はよく鼻が濡れていますが、あまりにも頻繁に鼻を舐める時は、何かしらのストレスを感じていると考えられるでしょう', 'たとえば頻繁に鼻を舐めていた犬が、飼い主が怒るのをやめた途端鼻を舐めなくなったとしたら、犬は飼い主の怒りに対しストレスを感じていたと思われます', 'このように、犬にストレスを感じている様子がみられた時は、その原因を探りだし、改善してあげる必要があります', '前足を低くして、お尻を高く持ち上げる姿勢を取るこれは、相手に対して構ってほしいという気持ちを伝えるためのカーミングシグナルです', 'この体勢で尻尾を振っていたら、ほぼ間違いありません', '犬が一緒にいる相手とより友好的に過ごしたい時にみせる行動なので、たくさん遊んであげましょう', 'あくびをする鼻を舐めるカーミングシグナル同様、相手が怒っている時によくみられます', '飼い主が怒った時にあくびをする犬は少なくありませんが、これは反省していないのではなく、わかりましたので落ち着いてくださいという意味です', 'カーミングシグナルを理解すると、犬が飼い主に何を伝えようとしているのか、察することができるようになります', '日頃から愛犬の行動をよく観察し、カーミングシグナルに応えてあげることで、より深い信頼関係を築きましょう', '']\n",
      "https://woman.mynavi.jp/article/170219-9/ \n",
      " ['そもそもカップルが喧嘩する一番の原因って何また、喧嘩をしてしまったとき、仲直りするために効果的な謝り方とは働く男女369人のアンケートと男女の仲にくわしい弁護士堀井亜生先生の解説から探っていきましょう', 'そもそもカップルが喧嘩する原因と時期ってカップルが喧嘩をしてしまうのには、それなりの理由や原因があるものです', 'まずはカップルの主な喧嘩の原因について見ていきましょう', 'カップルが喧嘩する原因ランキングちょっとしたことがきっかけで、大喧嘩にまで発展してしまうこともあるでしょう', '実際、カップルたちはどんな原因によって喧嘩をしているのでしょうか男女の意見をランキングにました', 'qあなたが恋人と喧嘩する原因を教えてください', '男性  第1位 生活習慣の違い304  第2位 嫉妬や束縛が激しい276  第3位 お金のトラブル249  1有効回答数181件', '複数回答式、4位以下省略その他除く女性  第1位 生活習慣の違い330  第2位 連絡しない314  第3位 浮気293  2有効回答数188件', '複数回答式、4位以下省略その他除く男女ともに、生活習慣の違いが一番の喧嘩の原因となっているようです', 'また、興味深いのは、連絡しないという答えが女性では2位なのに対して、男性では嫉妬や束縛が激しいという答えが2位にランクインしているということ', '男女の恋愛に対する価値観の違いが浮き彫りになったアンケートでした', 'カップルの喧嘩が増える時期とはアンケートからカップルの喧嘩の原因が判明しましたが、時期によっても喧嘩が起こりやすくなるものなのでしょうかここでは、カップルの喧嘩が増える時期やタイミングについて、働く男女に尋ねてみました', '12 1仕事などで忙しくなったときお互いに忙しく、余裕がないときに苦言を呈されるとつい感情的になりやすいと思う男性35歳商社卸営業職仕事が忙しいなど精神的に余裕がない状態男性30歳機械精密機器技術職お互い仕事が忙しいと、イライラしやすくなる女性26歳ホテル旅行アミューズメント販売職サービス系いろいろと忙しいとき', '余裕がなくなる女性34歳情報it技術職仕事が忙しいときなどは、恋人のことをかまってあげたり、優しくする余裕がなくなってしまったりすることも', '忙しいというだけでもイライラしてしまいがちですが、それを理解してくれず責められたりすると、喧嘩に発展してしまうようです', '2会えない日が多くなったとき会えない期間が長くなると喧嘩しやすくなる男性29歳情報it技術職会えなくなって寂しくなってきたとき男性28歳運輸倉庫その他会えない日が重なっているのに、飲み会の予定とかを入れられたとき女性26歳医療福祉専門職忘年会やクリスマスの飲み会の多い季節', 'お互いの時間が合わなくなるから女性30歳電機技術職遠距離や出張などのせいで会う時間が取れなくなると、寂しさやすれ違いなどから喧嘩になることも増えるようです', '寂しい気持ちを理解してくれないといういらだちがお互いに募るのかもしれませんね', '3マンネリ化したときマンネリ化の時期男性35歳運輸倉庫その他少しマンネリ化したときやすれ違いが増えたとき男性32歳その他販売職サービス系付き合って長くなるとお互いがマンネリ化して恋人だという新鮮味がなくなるとき女性35歳建設土木その他マンネリ化してきたころ', '相手を大切に思う気持ちが薄れてくるから女性23歳学校教育関連専門職ある程度長く付き合っていると、自然と関係がマンネリ化してしまいがちです', '新鮮味がなくなり、お互いに怠惰な態度を見せてしまうのも、相手に対しての不満を抱く原因になりそうです', '4お互いが慣れてきたころ付き合って慣れてきたころのちょっとした言動男性30歳その他その他次第に慣れてきたとき、緊張感がなくなり、相手の嫌な面が見えてきたとき男性35歳商社卸営業職慣れると連絡が来なくなる女性32歳医療福祉その他付き合って慣れてきたころ', 'こっちは会いたいので連絡するが、相手から会おうと言ってこなかったら何で となる付き合い始めは適度に緊張して、言葉や態度にも気を遣うものですが、慣れが出てくるといつしかそうした気遣いを忘れてしまうこともあります', '喧嘩が増えてきたかもと思ったら、お互いの距離感が縮まった証なのかもしれません', '喧嘩が増える時期喧嘩が増えてしまう原因としてありがちなのは、会えなくなってしまった際の寂しさを感じる時期や、お互いに対する思いやりが欠けてきた時期のようです', '不満に思う気持ちが募り、ある日爆発してしまうカップルが多いのでしょう']\n",
      "https://kirari-media.net/posts/935 \n",
      " ['最近、喧嘩ばかりになったカップルや、喧嘩をしたことがないカップルも、なぜ喧嘩が発生してしまうのかを考えていきましょう', 'そもそも喧嘩って何喧嘩とは、言葉や暴力による争いのことを指します', 'その為、冷静に話し合っていても、言い争っているのであれば、それは喧嘩です', 'こういう風に喧嘩の定義が分かると、喧嘩をしたことがないカップルでも、本当は喧嘩をしていたということになりませんか    喧嘩とは、お付き合いしていく上で決して避けては通れない壁なのです', '彼氏と喧嘩喧嘩中に無視する男性の心理と仲直りするコツ彼氏と喧嘩している最中に無視される、彼氏と仲直りしたと思ったのにlineが未読で無視されるな カップルが喧嘩する原因や理由13選では、カップルが喧嘩ばかりする原因や理由を考えていきましょう', 'どのような原因や理由から喧嘩になってしまうのかを考えていくと、自ずと対処法も見つかっていきます', 'ここでは、喧嘩ばかりになってしまう13個の原因と理由をご紹介します', '1自分の感情をぶつけてしまう喧嘩ばかりのカップルに多い原因は、自分の感情を恋人にぶつけてしまうことです', '恋人には関係ないところでイライラしたのに、そのイライラを恋人にぶつけてしまい喧嘩になることが多いのです', 'また、感情に振り回されて恋人に突然甘えたり、素っ気なくしたりと感情によって態度が違えば、恋人だってイライラします', 'そういったところから、喧嘩になる原因を生み出してしまうのです', '2わがままが多い喧嘩ばかりのカップルは、恋人のわがままで喧嘩が始まることがあります', 'たまにわがままを言うのであれば、かわいいものですが、常日頃からわがままを聞かされているとうんざりしてしまいます', 'そういった日頃の積み重ねが原因となって、喧嘩に発展してしまうのです', 'また、恋人自身わがままを、言っているつもりがないこともあります', 'それを上手く伝える術を知らないカップルが、わがままを理由に喧嘩ばかりのカップルになってしまうのです', '3浮気をする浮気が喧嘩の原因になるのは、当たり前です', 'しかし、意外と浮気をしても別れないカップルが多く、恋人が浮気をする度に喧嘩となり、喧嘩ばかりのカップルになってしまうのです', 'また、浮気をして喧嘩をすることによって、恋人の関心を自分に向いているということに快感を覚える人もいます', 'その為、浮気を繰り返し、喧嘩をするよう仕向ける恋人もいるそうです', '4価値観が合わない喧嘩ばかりのカップルは、価値観が合っていないことがあります', '金銭感覚や、食生活など小さな理由から喧嘩の原因となってしまいます', '価値観を合わせようにも、お互いが引かない状態なので、価値観のすり合わせが出来ず喧嘩ばかりになってしまうのです', 'また、価値観が違うとわかっておらず、お互いの価値観をぶつけ合うだけの意味のない喧嘩が多いのも特徴です', '5嫉妬や束縛が激しい嫉妬や束縛が激しく、喧嘩になるパターンも多いです', '恋人への過剰な嫉妬や束縛で、恋人が不自由を感じ、怒って喧嘩になるのです', 'また、友好関係が広く男女ともに友達の多い恋人に対して、愛されているのか不安を抱いているため、過剰な嫉妬や束縛をする人もいます', 'その不安が原因となって、喧嘩ばかりのカップルになってしまうのです', '6連絡を待っていられない恋人からの連絡を待っていられないのも、喧嘩ばかりのカップルの多い原因です', 'なんで連絡してくれないのと、恋人が忙しいのに連絡を催促して、喧嘩になってしまうのです', 'また、恋人への連絡を過剰にしてしまい、恋人の迷惑となり喧嘩の理由になるパターンもあります', 'どちらも連絡を待っていられないので、喧嘩ばかりになってしまうのです', '7約束を破る恋人との約束を破ることが、喧嘩の原因になるのは当たり前です', '特に、喧嘩ばかりのカップルに多いのは、何度も約束を破り、その度に喧嘩をしていることです', '約束を守るよう話し合うなどはせず、ただ喧嘩をするので、何度も約束を破ることを理由に喧嘩になります', 'そういった原因を取り除けないのも、喧嘩ばかりのカップルに多いことです', '8勝手に恋人の大切なものを捨てる意外と多い喧嘩の理由が、恋人の大切なものを勝手に捨てることです', '恋人の大切なものを勝手に捨てる行為は、人間としても最低の行為です', 'しかし、恋人の所有物は自分の所有物だと思っている人もおり、自分に必要のないもの、気持ち悪いものだから捨てるという人もいます', '大切なものを勝手に捨てられれば誰だって怒りますが、そこを理解できない人もおり、喧嘩ばかりのカップルになってしまうのです', '9遅刻が多い遅刻を理由に、喧嘩ばかりのカップルになることも多いです', '待っている側は意外とイライラします', 'そして、繰り返される遅刻に恋人の堪忍袋の緒が切れてしまい、喧嘩になってしまうのです', 'また、意外と多いのが遅刻をする側は遅刻癖を直す気がないことです', 'その為、遅刻が原因の喧嘩ばかりのカップルになってしまいます', '10人の迷惑を考えない恋人の迷惑を考えず会いに行ったり、連絡を頻繁に取ろうとする行為が、喧嘩の原因となることもあります', '恋人も自分の生活があるのですが、そこを気にしないで自分の想いばかりで行動をしている為、恋人の不満が溜まり、喧嘩になるのです', 'また、周囲の迷惑を考えず行動することも、理由となり喧嘩になることもあります', '周囲を気にせず恋人に良いところを見せようと、店員に横暴な態度を取ったりなど、そういった行動でも価値観が合わず喧嘩になるのです', '11すぐに病んでるアピールをするちょっとしたことでsns上で、病んでいるアピールをするのも、恋人からするととても不愉快です', 'それが積み重なり、喧嘩の原因となってしまいます', 'また、sns上だけで病んでいるアピールをするので、恋人からすると何が不満なのと不安な状態が続きます', 'その不安が苛立ちになり、喧嘩になってしまうのです', '12自分の思い通りに行動してくれないと怒る恋人が自分の思い通りにならないと、ヒステリックに怒ったりして、喧嘩になるカップルもいます', '連絡の頻度や、自分への態度など、全てが自分の想い通りに恋人が動いてくれないと、嫌なのです', 'しかし、恋人はそんなこと思ってもいないので、なぜ怒っているのか見当がつきません', 'その為、お互いが不満を溜めて、喧嘩に発展していくのです', '13恋人を自分の物扱いしている12の理由と似ていますが、こちらは完全に恋人を自分の物だと思っているので、恋人の友好関係や趣味から何まで口を出して、恋人を怒らせてしまいます', '恋人は不満がいっぱいなので、感情的になっていますし、自分は恋人が自分の思う通りに動いて当然だと思っているので、話が噛み合いません', 'そういったお互いの価値観のすれ違いから、喧嘩ばかりのカップルになってしまうのです', '喧嘩ばかりの恋人と仲直りする方法とは喧嘩ばかりのカップルになってしまう原因や理由がわかったところで、喧嘩ばかりの恋人と仲直りする方法は、どのようなものがあるのでしょうかここでは、喧嘩ばかりの恋人と仲直りする方法をご紹介します', '直接会って謝る謝ることを決意したのなら、直接謝ったほうがいいです', 'お互いの目を見て、反省している姿を見せることができるので、謝罪の気持ちが伝わります', 'そして、そのまま喧嘩の内容について話し合って解決することができます', '謝罪するときに日頃の感謝の気持ちなどを伝えると、よりぐっとお互いの距離が近くなるので、この方法を取るのが一番といえます', '冷静に話し合うこちらの方法は上の謝罪をした後にするといいでしょう', '冷静に今回の喧嘩の内容を話し合うことで、どこが悪かったのか、次から気を付けることはなんなのか、原因や理由がはっきりとします', 'また、冷静に話し合う状況を作ることで、喧嘩別れを防ぐこともできますので、別れたくないカップルは必ず取ったほうがいい方法です', '手紙や電話で謝る喧嘩の熱をお互いが距離を取ることで、冷ます効果が期待できる方法です', 'しかし、この方法は少しリスキーです', '恋人がそもそも手紙を読んでくれなかったり、電話に出てくれなければ意味がありません', 'ですが、顔を合わせると感情的なことしか言えない状況などでは、お互いに冷静になる時間が必要です', 'そんなときに、手紙や電話であれば顔を見ることはないので、感情を落ち着かせながら謝罪や話し合いができ仲直りできます', '第三者を入れて会う喧嘩ばかりのカップルに多いのは、喧嘩別れや言い争いになってしまうことです', 'その為、二人だけで会うとまた言い争ったりして収拾がつきませんが、友達などの第三者を交えて会うとストッパーになってくれます', 'また、その時にお互いの価値観を擦り合わせることで、第三者が証人となり、あの約束を言った言わないがなくなります', '二人だけで仲直りが難しい喧嘩の場合は、第三者を入れることをおすすめします', '彼女と喧嘩したときの仲直りする方法別れないコツとは付き合っていれば、彼女と喧嘩をしてしまうことだってあると思います', '喧嘩をしてしまうとずっと嫌 喧嘩の多いカップルの喧嘩の内容では、喧嘩の多いカップルの喧嘩の内容はどのようなものでしょうか', 'ここでは、喧嘩の多いカップルの喧嘩の原因や理由ではなく、どのような喧嘩をするのかを考えていきます', '感情むき出しの喧嘩喧嘩の多いカップルの喧嘩は、感情をむき出しで罵り合う内容の喧嘩が多いです', '感情に任せて言葉を発するので、思ってもいないことや恋人を酷く傷つける内容も言ってしまいます', 'また、感情的な状態なので別れるなどと言ってしまうこともあり、感情的な内容の喧嘩が多いカップルは喧嘩別れをしてしまうことも多いです', '暴力や物に当たる喧嘩感情的になる喧嘩に似ていますが、こちらは言葉ではなく手や足が出る喧嘩です', '恋人に暴力を振るったり、物を投げたり、物に当たったりなど、暴れるような喧嘩になります', 'こういう喧嘩が多いカップルは、dvや依存系のカップルになりやすいので、注意が必要です', 'お互い謝らないで終わらせる喧嘩喧嘩が多いカップルは、なあなあな状態で喧嘩を終わらせることが多いです', 'お互い謝りたくない為、時間をかけたり、ちょっとしたきっかけですぐに仲直りしてしまいます', 'しかし、しっかり謝ったりしていない為、喧嘩が再発しやすく、喧嘩の原因を取り除けないことがおおいです', '相手に謝らせるだけの喧嘩話し合いなどをせず、相手に謝らせるだけの喧嘩は、何も解決になっていません', 'その為、喧嘩が再発しやすく、また謝った側はストレスを溜めるだけなので、どんどん重く酷い喧嘩になりやすくなります', 'そういった喧嘩は、自分のほうが立場が上だというプライドが高い人が行うことが多いです', 'そういった喧嘩になった場合は、話し合いに持っていけるように試行錯誤をする必要があります', 'しかし、その試行錯誤が見つからない為に、喧嘩が多いカップルになってしまうのです', '長続きするカップルの喧嘩の内容次に、長続きするカップルの喧嘩の内容は、どんな内容でしょうか喧嘩が多くても長続きする内容を一緒に考えていきましょう', 'カップルが長続きする秘訣や特徴13選恋人と長続きさせたい付き合うのであれば、長続きしたいと思うのは当たり前ですよね', 'この記事では、カップルが長続きす 素直にごめんが言える喧嘩例え激しい喧嘩になっても長続きするカップルは、素直にごめんとあやまることができ、仲直りが早いのです', '素直に謝れるということは、変に拗れず喧嘩が長続きすることはありません', 'どんなに怒っていても、お互いが謝ることができれば、そこで喧嘩は終わりです', '素直に謝ることのできるカップルは、喧嘩を引きずることもありません', 'そういう素直さから、長続きするカップルになれるのです', '冷静に話し合う喧嘩長続きするカップルは、どんな内容の喧嘩になっても冷静に話し合うことができます', 'そして、お互いのどこが悪いのか、喧嘩の原因はなんなのかをはっきりさせて、喧嘩を終わらせることができます', 'その為、同じことで喧嘩が起きることはなく、絆が強くなるような喧嘩をして長続きするのです', 'お互いを想いあっての喧嘩長続きするカップルに多い内容の喧嘩は、お互いを想いあっての喧嘩が多いです', 'その為、乱暴な言葉などを使わないので拗れず、恋人が自分を想ってくれる気持ちも伝わっているので、早く仲直りします', 'そもそも、お互いを常に想い合っているカップルは、喧嘩の内容も比較的に軽く、例え重たい内容であっても、冷静に話し合って解決することができます', '喧嘩した後のカップルがすぐに仲直りするには喧嘩をした後の仲直りの方法が分かった今、すぐに仲直りする方法とはなんでしょうかここでは、どうしたらすぐに仲直りできるのかを考えていきます', '時間を置かない喧嘩の内容に関わらず、喧嘩をしてしまった後、時間を置こうとするのは喧嘩を長引かせるだけです', '喧嘩を早く終わらせたい場合は、時間を置かずに謝ったり、話し合いをするようにしましょう', 'しかし、お互いの頭が冷えていない状態で謝ったり、話し合いをすると喧嘩が泥沼化する危険性があるので、頭を冷やす時間だけは作ったほうがいいでしょう', '会う約束をする早く仲直りがしたい場合は、きちんと会う約束をしましょう', '勝手に会いに行ったり、会わなかったりせず、約束を作ることで仲直りしたいという意思表示ができます', 'そして、直接会って言葉を交わすことで、仲直りできる雰囲気を作れるのです', 'しかし、頑なに会ってくれなかったり、そもそも連絡が出来ない状態の場合は、少し時間を空けて落ち着いてから、会う約束をしましょう', '決して泣かない泣く行為を見ると、人は自分だって悲しいのにずるいと感じてしまうそうです', 'その為、早く仲直りをしたいのであれば、決して泣いてはいけません', '泣くことで恋人を悪い立場にしてしまうからです', 'また、少しずるい手ですが、涙を溜めて堪えている姿を見ると、自分と真剣に向き合っていてくれていると印象付けることができます', 'こういった理由から、喧嘩したときに決して泣いてはいけないのです', 'lineで謝らないlineは気軽にできる分、真剣度が欠けます', 'また、謝るスタンプを送るなどは持っての他です', 'そんなスタンプを送られてきた恋人は、ふざけてんのと更にヒートアップしてしまうからです', '例え長文でlineを送ったところで、読まなければいいですし、そもそもlineで済まそうとしてくる精神が恋人をヒートアップさせてしまいます', 'その為、lineで謝るのは最悪な手段となるので、絶対にしてはいけません', '改善点を伝えるようにする喧嘩をした際、どこかしらに悪いところがあるはずです', 'その改善点を伝えると反省していることも伝わりますし、お付き合いを続けていきたいという意思表示ができます', 'また、喧嘩の再発防止にもなりますので、改善点を伝えるようにすると仲直りしやすく、長続きするカップルになれます', '喧嘩ばかりのカップルが気をつけたい事仲直りの方法もわかったところで、そもそも喧嘩をしないようにするには、どうしたらいいのでしょうかここでは、喧嘩ばかりのカップルが気を付けたい事をご紹介します', '感情的にならない喧嘩にならないようにするには、まず感情的にならないことが大切です', '感情的になって行動することは、恋人のことを考えていない状態になってしまい、喧嘩になってしまうことが多いです', 'その為、感情的になりそうなときは、別の発散方法で落ち着かせるようにしましょう', 'こうすることで、喧嘩別れするような内容の喧嘩が減り、長続きするカップルになれるのです', '汚い言葉を使わない気を許している恋人だからといって、汚い言葉を使って傷つけるのはやめましょう', 'そういった汚い言葉から、喧嘩に発展することもあります', 'そういった喧嘩は感情的で暴力や物に当たる喧嘩になりやすいです', '恋人の気持ちをきちんと考えて、言葉を発するようにすると、長続きしてお互いを想いあうカップルになれるのです', '乱暴な振る舞いをしない物に当たったり、暴力を振るったりなど、乱暴な振る舞いは喧嘩の原因になります', 'その為、もし物に当たる癖などがあるのであれば、早急に直すことをおすすめします', 'ストレスを発散する方法は、いくらでもあります', '物に当たることなどは、恋人に負担がかかる行為なので、恋人を想うのであれば、やめられるはずです', '乱暴な振る舞いをなくすことができれば、より良いカップルになれます', '広い心を持つ恋人の全てのことに気を張っていては、自分が疲れてしまいます', 'ちょっとしたことなどであればまあいいかくらいの気持ちで、スルーできる広い心を持ったほうが、お互いストレスなく過ごせます', '恋人の行動に対してのストレスが多いと、別れる原因にもなってしまいますので、恋人との価値観を合わせられるくらい広い心を持つように心がけるのがいいでしょう', '喧嘩ばかりのカップルを卒業する方法ここまで、喧嘩の内容についてや、対処方法などを考えてきました', 'では、そもそも喧嘩をしないカップルになる為には、どういうことをするといいのでしょうかここでは、その方法を考えていきます', '怒る前に深呼吸する喧嘩ばかりのカップルを卒業する為には、まずは感情的に怒る前に、深呼吸癖をつけましょう', '深呼吸をすることで、頭を冷やし本当に怒ることなのかを考えられるようになります', 'また、一息つくことで気持ちが落ち着き、感情的に怒るようなことにはならず、冷静に話し合いができる良い方法です', '実際に、長続きするカップルの中にも、実践しているカップルがいるそうなので、効果的な方法と言えます', '恋人を別の人間だと認識する恋人はあくまで自分ではなく、別の人間です', '恋人には恋人の考えもあるし、恋人の価値観があります', 'そこを自分と同じだと思ってしまうことが、喧嘩の原因となってしまいます', '恋人のことを好きなあまり、一緒の考え、価値観だと思うことはやめましょう', '恋人を別の人間だと認識して、お互いの価値観などを擦り合わせていくことが、長続きするカップルの秘訣なのです', '喧嘩になる原因を取り除く喧嘩の内容というのは、必ず原因や理由があります', '何度も同じ喧嘩を繰り返すカップルは、原因を取り除けていない為に繰り返すのです', '喧嘩を防ぐ為には、原因を取り除く他ありません', 'お互いがきちんと話し合って、価値観や考えを擦り合わせ、仲良く長続きするカップルになれるように考えていくのです', 'そうすることが、喧嘩を減らし長続きするカップルになれる近道なのです', '喧嘩ばかりのカップルだっていいいかがでしたでしょうかここまで読んで頂いて、私たちはダメなカップルだと思った人もいるでしょう', 'しかし、喧嘩ばかりしているから、ダメなカップルということはありません', '喧嘩ばかりしているからダメなカップルだと思っているのであれば、それは間違った考えです', '喧嘩をする度にお互いの考えや価値観がわかり、絆が深まることがあるからです', '喧嘩をしてもいいんです', '喧嘩をした後に、絆が深まり仲良く長続きするカップルになれていればいいのです', 'そのことを忘れないでください', 'どうか幸せな喧嘩カップルでいてください']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://happylifestyle.com/2084 \n",
      " ['自分が相手に対して十分な理解ができていなかったとき   逆に、相手が自分のことを十分に理解してくれなかったとき   相手の気持ちを考えずに、ぶっきらぼうな言葉を口にしてしまったとき   相手が嫌いだからという、それだけの理由で悪口を吐いてしまったときこのように喧嘩が始まる原因はささいなことかもしれませんが理解不足は喧嘩をする一番の原因なのです', 'そのために人間には不思議なことに喧嘩をまったくしない人と喧嘩をよくする人の2とおりに分かれます', '理解のある人は喧嘩なんてまったくせずにみんなと仲良くでき、逆に理解のない人はいつも誰かとトラブルを起こしています', '喧嘩をしない人は理解がある人ですから、前もって喧嘩を防いだり、避けたり、謝ることができます', '大きな喧嘩に発展することはありません', 'しかし、どういうわけか喧嘩をする人は、決まってよく喧嘩をしています', 'その人だけ特別に災難が集中しているわけではありません', 'その人に理解が不足していたため、行く先々でトラブルということになるのです', '分からないときには教えてくださいと言えず、すぐ分からないから教えろと怒ります', '友達と考え方がぶつかったときも、自分の考えこそが一番正しいと思い込み、相手の話は一切聞かず、自分の話ばかりをします', '理解不足の人は、よく話す人とも言えます', '自分の話ばかりで相手の話は聞かない', 'と言うのも相手を理解するより自分のことを理解させることを優先させてしまっているからです', '理解不足が喧嘩の原因なら理解力を身につけることこそが喧嘩をしないコツなのです', '自分のことばかりを考えるのではなく、相手のことも理解するという理解力を持ちましょう', 'もちろんこうした姿勢は相手にもそうであってほしいですよね', '単純に自分が無知であっただけかもしれませんし、そういうときは相手に教えてもらうという謙虚な姿勢も必要です', '人付き合いが上手な人は、理解力のある人なのです', '喧嘩をしない方法 その2']\n",
      "http://nellco.xyz/1252.html \n",
      " ['お子さんが1人という家庭でも、友だちとの喧嘩に遭遇することもありますよね', 'こんな時、どのように対応すればいいのでしょうかやり方をしっていればむやみに怒ってしまうこともありませんよ', ' 喧嘩の本質 なぜあんなに喧嘩が絶えないのでしょうか理由は意見の不一致という明らかな理由があります', 'ただそれは大人なら簡単に解決してしまえる問題でも子供の世界では全然違います', '保育士は保育の内容を決定する時、相手に思いがあることを知る相手の意見をきこうとするなどの言葉で子供の発達を見据えた計画を立てます', 'それらが目指すところということはつまり、まだ備わっていないということですよね', '子供は自分が世界の中心です', '他人の考えは全く無視です', 'それが段々と友だちにも気持ちがあって、それが違う意見であるということに気づいていくのです', 'そうなるまでには俗にいうジャイアン思考なんです', 'そんな子供同士が遊ぶわけですから、当然ぶつかるわけです', ' ありがちな喧嘩の対応 よく見る喧嘩の対応としては、どちらかをおこりどちらかを慰めるという方法です', '具体的には、例えばa君がb君をたたいたという喧嘩があったとします', 'この方法を使うと大人はa君を怒り、b君を慰めるという形です', '確かに間違ってはないのですが、これだけで本当に解決したといえるのか疑問です', '他には年上だから我慢しなさいという方法です', 'これも理不尽なときがあります', 'これらは大人からすると解決できたと思えるのですが、子供からは全くそうではありません', 'ただ、大人の力で無理やり喧嘩を終了させたことにすぎないのです', 'こんな解決策をとってしまっていませんか  どうやって解決するか 子供に適切な喧嘩の解決方法とはどんなものなのでしょうか', '喧嘩と一口に言っても様々なパターンがあります', 'どんな内容の喧嘩でも解決策を子どもに導きさせることが一番のポイントです', '見守るだけでは、自分中心の世界にいる子供たちに解決策は見出せません', '大人が仲介にはいることは絶対です', 'でもその仲介方法にポイントがあるのです', '具体的に説明しましょう', 'おもちゃをめぐってa君とb君が喧嘩をしていたとします', 'そしてa君がb君をたたいてしまいました', 'こんな時の大人の関わりはまず、a君とb君の間に入りこれ以上手が出ないようにします', 'そしてなにがあったのかどうしたのかを聞きます', 'ここで重要なのが、a君b君別々に聞くことです', '年齢が高ければこれで状況がほぼわかります', 'この行動をすることで新しい状況が見えてきたりします', 'この場合b君がa君のおもちゃを取ったということがわかったとします', 'そこで2人にお互いに話しかけます', 'b君はそのおもちゃがほしかったんだね', 'だから取っちゃったんだね', 'でもa君は取られたくなくてたたいちゃったんだね', 'と状況を言葉にだし、次は気持ちの面です', 'a君はおもちゃを取られたくなかったんだよね', 'でもb君は痛いって言ってるよb君はおもちゃが欲しかったんだよね', 'でも取ったらa君は嫌な気持ちだったらしいよなどですね', 'そのあと解決への出口は子どもたちが自ら見つけられるようにします', '魔法の言葉はどうしようかです', '子供たちはそこでものすごくかんがえます', 'そして子供なりの解決策を導くのです', 'いつまでたっても解決しないときはヒントを与えてあげるといいでしょう', 'として喧嘩は成長喧嘩は良くないものと思ってしまいがちですが、そんなことはありません', '思いの違う相手とぶつかりあいながら、友だちの思いに気づいたり喧嘩を経験する中で解決策を自分たちで導けるようになったりするのです', '人間関係の中では大切な能力のひとつです', '喧嘩を全て止めてしまったり、ほったらかしになってしまっていては、育つちからも育ってきません', '喧嘩に上手に対応して、子供の思いを受け止めてあげてください', 'そんなことを経験できたお子さんはきっと人間関係がとても上手になるとおもいますよ']\n",
      "https://inubiyori.jp/shibainu/840/ \n",
      " ['喧嘩の理由、喧嘩の止め方などを知っておこう', 'なぜ喧嘩するのか性別で喧嘩の多い組み合わせを統計的に考えれば、 未去勢のオス犬同士、以下、去勢済みのオス、不妊前のメス、不妊済みのメスの順だが、個体差などにより全部に当てはまるとは言い切れない', 'では実際、どういうタイプなのだろうか散歩で出会う犬にすぐ喧嘩を売ってしまう犬には、 臆病で怖がり 、そして、 社会性に欠けているというのが原因である', '子犬のときにきちんと犬社会のルールを学んでいなければ、他の犬と出会ったときにどうすればいいか分からない、そのため、緊張や不安から相手を威嚇してしまうのである', 'また、出会った片方の犬が社会性を持っていたとしても、もう一方の犬がいかにも緊張した態度であれば警戒するのは当然のこと', 'そこで吠えたり、威嚇することから喧嘩は始まってしまう', 'さらに犬の喧嘩には飼い主が影響すると言うことも忘れてはいけない', '向こうから来た犬にうちの犬は吠えるんじゃないかと緊張すれば、飼い主の不安が愛犬にも伝わってしまい、より愛犬の緊張が伝わってしまうのだ', '無用な喧嘩を避けるために、 飼い主は愛犬の性質をよく理解しておきたい ものである', '日本犬が喧嘩を売られやすい理由姿勢のよさが誤解される  柴犬を散歩させていると、他の犬からよく吠えられることがある', 'それは柴犬の容姿が影響している', '怖がりの犬が柴犬の姿を見かけると、喧嘩を売っているぞと誤解して先制攻撃を受けるのだ', '姿勢の良さが誤解を招くとはなんとも複雑', ' 耳  ピンと立った三角形の耳はたれ耳の犬種に比べて、喧嘩を売っているものだと誤解を受けやすい', ' 尾  本来の巻き尾なのに、遠くから見れば威嚇で尾を立てているように勘違いされやすいのである', ' 胸  胸をぐっと張っての直立姿勢というのも威嚇と誤解されやすい', '老犬は姿勢が丸くなっているので襲われないのだ', '喧嘩学1柴犬が喧嘩する理由仲良しなはずが、ある時喧嘩  何かの取り合いなど必ずきっかけがあるはず', 'どんなにお互いの犬が仲良く見えても、遊びがエスカレートして喧嘩になることは起こりうる', '公園なら木の枝の取り合いなど、必ずきっかけがある', 'ご飯にまつわる喧嘩  食べ物に対し執着する価値が同じ犬同士だと喧嘩になりやすい', '同居犬の場合、充分に食事を与えていればあまり食事の取り合いで喧嘩になるということはない', 'ただし、食欲旺盛な犬が他の犬の食事を欲しがれば、自分のものを取られまいとして喧嘩になる', 'おやつに対して執着する価値が同じ犬同士も取り合いで喧嘩になることも', '遊びがいつのまにか喧嘩  はしゃぎすぎてしつこいと片方がたしなめることも', '成犬と子犬の組み合わせが多く見られるパターン', 'はしゃぎすぎてしつこい子犬をいい加減にしろよと年上犬がたしなめる', '落ち着きなさいよ、というカーミングシグナルを相手に送っているのに、気づいてもらえないと、攻撃されるのではないかと、先制攻撃を仕掛ける場合もある', '多頭飼いでの喧嘩  飼い主の行動が喧嘩になることが多い', '同じ犬で飼われている場合、犬の中には群れ意識があるので、ランクがきちんと決まっているときには飼い主がそれを乱してはいけない', '多頭飼いでの喧嘩には飼い主を巡っての争いが多い', '自分の行動が犬たちを争わせているのではないか、よく考えておきたいものである', 'すれ違い際にいきなり喧嘩  恐怖心や 社会性の不足 、 飼い主の態度にも影響する', '散歩の際に向こうから来た犬に喧嘩を売ってしまうのは、恐怖心や社会性の不足からくることが多い', 'また、自分の犬が吠えてしまうのではないかという飼い主の不安や緊張が伝わって、より愛犬の緊張を助長してしまうことも', '飼い主の態度次第で防げる場合が多いのだ', '挨拶しようとしたら喧嘩  自分の犬や相手の状態によって喧嘩になることも', '未去勢のオス同士の犬の場合だと、犬は最初から喧嘩を売ろうと思っていることも', 'また、相手が柔軟な対応をしてくれたら自分も恐くなかったのにと、恐怖のあまり攻撃的な行動に出てしまうことも', 'すれ違いの喧嘩と同じく、飼い主から影響というものも原因として考えられる', '喧嘩学2決着がつく瞬間犬同士の喧嘩は 負けを認めたら目をそらす', '喧嘩の瞬間というのは、お互いが正面を向き合っての真剣勝負だ', '犬の喧嘩の勝ち負けは先に目をそらしたほうが負け', '目をそらすというのは戦意喪失を意味している', 'こいつには勝てないと思った時にボディランゲージで負けを認めたことを示す', '優位だから上に行くのではなく弱いものが下に行くことで順列ができていると考えられている', 'また、同居犬同士でしっかりした群れができていれば、お互いを傷つけあうまで決着をつける喧嘩は起こりにくい', '喧嘩学3じゃれと喧嘩の見分け方  犬の表情と体の動きに注目  本気の喧嘩の場合、果たして犬はどこを攻撃することが多いのだろうか', '攻撃場所は犬によって違うが、 耳、鼻、アキレス腱', '睾丸、首 など', 'そして、仲良くじゃれあって遊んでいたのに急に犬の動きが止まった、振っていた尾が止まった、など体に硬直が起こるのが喧嘩への主なターニングポイントだ', 'これらの硬直は一瞬のことであれば、長い場合もある', 'また、体と同様、じゃれあっていたときには口をあけていたのに、口が閉じる、白目をむいてしまうなどパニックに近い表情へ変化が起こる', '遊んでいるときの声はウーッ、ウーッと比較的短い声であるが、もうこれ以上限界と言うときにはウーッが長くなる', 'そんな威圧的な声を発しているときには長い硬直も起こりやすい', 'だが、うなり声を出さずに突然喧嘩へ発展することもあるので、犬の表情と体の動きを良く見ておくことが、じゃれから喧嘩の見極めに役立つのだ', '自分の犬のことだけ見ていても、相手の犬が飛び掛ってくることもある', '必ず自分の犬だけではなく、相手の犬の様子も見ておくことが重要', '喧嘩学4喧嘩の止め方水をぶっかける  噛み付いてはなれないときに一気に水をかけるのは有効', 'だが、いつもそばに水があるとは限らない', '棒を振り回す  棒を振り回して犬を追い払おうとすれば、人間が襲われる危険が', '夢中で喧嘩している犬には棒が危ないと気づく余裕はないはず', '首輪をつかんで引き離す  がうがうと噛み合っている犬の首輪は触らないこと', '首元に来た人間の手を何だと振り返り様に犬が噛み付くことがある', '2匹の間に人間が張る  これは一番危険なこと', '間に入った人間が大怪我をする可能性がある', 'リードを引く  ただし、鼻の先端での喧嘩にはこの方法は有効', 'かみ合っているときはリードを離して止めるべき', 'どちらかを抱き上げる  人間が2人いて、片方が抱き上げて、もう片方が別の犬を押さえられればいいが、1人だけの場合は抱き上げる際にかまれることがある', '喧嘩で興奮しているときに無理矢理引き離そうと、下手に手を出すと人間が噛まれることがあるので用心することが必要だ', '犬の本能を理解し正しい認識を持つこと犬の本能を理解せず、ノーリードで飼ったり、きちんと再訓練しないと飼い主の犬が繰り返すことがある', '愛犬や自分が大怪我をしないためには犬同士の喧嘩を未然に防ぐことが大切', 'いつ、どこで、他の犬と喧嘩に発展する可能性があるかもしれないということを、飼い主はきちんと認識しておきたいものだ', '関連記事負け上手が世渡り上手平和な犬付き合いに必要なのは負け犬根性だ      shiba vol13 しないに限りますが、いざって時のためにも、知っておきましょ、喧嘩学 柴犬喧嘩道より抜粋  掲載されている写真はすべてイメージです']\n",
      "https://detail.chiebukuro.yahoo.co.jp/qa/question_detail/q1462043604 \n",
      " ['そしたら飼い猫も入ってきて2人とも血だらけになるぐらい引っ掻かれました', 'しばらく下手に近づくとシャーシャー言い警戒してました', '旦那の罵声が大きいのでそれにビックリしたのかなと思って悪いことをしちゃったと2人で反省してます  今は猫も撫でれるくらい落ち着いてますが、また多分下手に動くと引っ掻かれそうな感じです', '猫が喧嘩に入ってくることはよくあることですか  お願いします閲覧数    3090回答数    3お礼    25枚違反報告 ベストアンサーに選ばれた回答犬も猫も、そういうこと時々ありますね', 'お母さんに怒られてしょんぼりしている子どもを慰めに行ったりとか、飼い主さんのケンカの仲裁に入ったりとか', '知能は5歳程度なんて言われてますけど、相手の気持ちを推し量る、思いやるという点では人間は負けているところがあるかもしれません', '人語を話せないだけで、かなりの感情や状況は読み取っているように思います', 'うちも、夫婦げんかしていると、普段まったく無口な犬がくううんくうんと大きく、悲しげな泣き声を上げて、二人ともビックリ反省してケンカが終わったことがありました', 'いい猫ちゃんですね', '大事にしてあげてください', 'この質問は投票によってベストアンサーに選ばれました前の方が言っる通りだと思います', '猫の性格によってですが、親分肌の頭の良い猫に喧嘩なんかするな仲良くしろと仲裁された事あります', '空気の読める猫っていますよ', '宝ですね', '飼い主さんの興奮してる波長が猫ちゃんに伝染したのか  くだらん事でイチイチ喧嘩なんかしたらアカンやろ私が憎まれ役になってあげるから、もう喧嘩はお終いと言ったかどうかは定かではないですが猫も飼い主の気持ちを汲み取るので有り得ると思います']\n",
      "https://toyokeizai.net/articles/-/33829 \n",
      " ['特に身近な人、恋人や伴侶に対してもアンガーマネジメントを有効活用したい', '悪気は全くなかったのだが、どうやらパートナーの逆鱗に触れる一言を言ってしまったようで、不毛な罵り合いに発展', 'アンガーマネジメントの習得で、ケンカ知らずの円満カップルになろう 些細なミスで怒り爆発アンガーマネジメントを何のために行い、どんな効果が期待できるのかを簡単に知ってもらうため、人間の心をコップに例えてみよう', 'イライラの増幅によって、コップに水が注がれていく状況の変化をイメージしてほしい', 'まず、穏やかな心理状態のときは、コップに水がまったく溜まっていない', 'しかし、ときとしてこうなることがある', '1 ある日、仕事を終えようとすると、急に無理な残業を頼まれてイラっとしたことで、コップの水かさが少し増した', '2翌朝は、出掛けに妻がつまらない小言を言ってくる', '出勤前なのにうるさいなあー、もういい加減にしてくれよと、あなたのイライラは募り、心のコップの水かさがさらに増した', '3通勤電車に乗ると超満員', 'そんな中、大音量でヘッドホンステレオを聴いている若者から足を強く踏まれた', 'しかし、その若者は全く謝ろうとせずに素知らぬ顔', '謝ったらどうだと言葉にしたい気持ちを周囲の目もあるのでグッとこらえる', '前夜からの3つの不愉快な出来事で、心のコップの水かさはもう満タンの状態である', 'かなりの興奮状態で会社に到着', '自分のデスクにつくと、部下が業務報告書を提出してきた', '4報告書の内容に些細なミスを発見', 'そこであなたの怒りが爆発', 'おいっ、なんだこの報告書はと、あなたは部下を怒鳴りつけた', 'コップから水が溢れ出したのである', 'ミスをした部下を指導することは当然のことだが、先輩の気分や機嫌で指導法が変わるのはよろしくない', '部下から報告書を受けた際、前夜からの3つの不愉快な出来事を心の中に溜め込んでいなかったならば、あなたは部下を怒鳴りつけることはなかったかもしれない', 'アンガーマネジメントを体得することで、他者に気分や機嫌で対応することが減り、他者を傷つけることが少なくなる', 'また、そんなつもりじゃなかったあんな風に言わなければよかったなどと後悔したり、自己嫌悪に陥ることを防ぐ', 'アンガーマネジメントは、人間関係の潤滑油となり、私たちの精神衛生の安定に大きく寄与するのだ']\n",
      "http://kodokoko.com/2015/05/16/com-2/ \n",
      " ['コミュニケーションエラーとケンカの関係先ずコミュニケーションエラーとは、 コミュニケーション理論でいう 情報 が相手に正しく伝わっていない状態です', 'そしてケンカについて、コミュニケーションエラーの観点から考えると以下のようなプロセスが起因していると考えられます', '投げ手視線での会話    1投げ手が 情報 を伝える', '2受け手が 情報 を受け取り反応する', ' 情報 を受けとったサイン 3投げ手は受け手の反応をうけ取り、正しく伝わったか判断する', '4投げ手は判断した結果、誤りに気づき指摘する', '5投げ手は、先に渡した 情報 の修正もしくは不足を補うために新たな 情報 を受け手に渡す', '6受け手は投げ手からの新たな 情報 に対して再度反応する', '7この行為がコミュニケーションが成立するまで続くが、途中で感情的となりコミュニケーションが成立できなくなる', 'なんだか難しいですよねwこのようなキャッチボールが続いている状態で、受け手からの反応に攻撃的や不快だと思われる態度が含まれていたとき、返事を受け取った投げ手の感情や価値観に触れ、投げ手側も攻撃的な態度へ変化した状態がケンカと呼べるでしょう', 'また投げ手からの最初の 情報 に感情的な態度が含まれていたり、 情報 の投げ方が悪いと判断される場合もケンカにつながり、場合によってはキャッチボールすらできない状態になります', '相手に 情報 が正しく伝わっていない状態とは何なのかここまでの話では、コミュニケーションエラーに関する細かい単位でその仕組みを確認しました', 'そしてここからはもう少し大きな概念で考えをるため、先ほどとは違う観点で直し、日常生活での出来事と照らし合わせて考察を進めます', 'では先ずおさらいをします', 'コミュニケーションでは 情報 である 知識感情価値観をキャッチボールします', 'そして子供とのやり取りであれば未成熟であるという意味で情報不足だとわかります', 'しかし大人とのやりとりの場合や、子供であっても子供が知り得ている情報をもととしたコミュニケーションでは 情報不足ではない状態です', 'この事象について、まずは以下の例をご確ください', '例1 親子の会話 ママ玩具を使い終わったなら片づけなさい 子供はーい 了承した', 'しかし片付けない 数分後    片づいてないし、出している玩具が増えている', 'ママまだ片づけてないの何で片付けずに新しい玩具を出してるの 子供片付けはもう少ししたらやるよ ママ何で片付けながら遊ぶって約束でしょ ママ怒る 子供ママ何で怒っているのよ 子供も不機嫌になる', '結果として親子ゲンカとなる', 'この例の場合、ママは事前に 片付けながら遊ぶ約束をしていた伝えていたので知識の不足はないと思ってます', 'また、ママが最初の声掛けで子供は了承しています', 'しかし、よくよく考えると子供は全部の玩具を使って遊んでいる可能性もあるのでルールを破っているとは言い切れません', 'しかしママは 自分の思っていたことが実現されていないので 感情が抑えられなくなってしまったと考えられないでしょうかそしてこの場合、ママは片付けるという依頼のコミュニケーションで実現したかったものは何だったのでしょうかこの例をみると、単純な情報不足ではないケースだと解ります', 'そしてこのような状況は  情報の違いが発生したといえるでしょう', 'そしてその違いに気付かず話が進んでいたためコミュニケーションエラーが発生し、親子ゲンカになったと考えられます', 'ケンカの手前の黄色信号情報の違いが起こる3つの要因では次にこの情報の違いについて考察していきます', 'こちらはサブタイトルにありますように、以下の3の要因だと言われております', '1勘違いこれは解釈の誤り、思い込みや偏見などにより、本来とは違う 情報 を持ち合わせた状態', '早合点や情報の整理不足などにも含み、話し合いで解決しやすい違いです', '例1だと、ママから伝えた 玩具を使い終わったならという条件に対して、ママが今使ってないから使い終わったと解釈したことが該当するかと考えられます', '2ゴールの違いこれはコミュニケーションの目的であり、何のためという答えに違いがあるもの', 'こちらは先ず夫婦での例で学んでみましょう', '例2 夫婦の会話    ママが掃除中、テレビを観ているパパに片付けをお願いして、 パパは承諾した', 'その後ママは部屋を離れ戻ってくると片付けが終わってなかったので怒った', 'ママ何でやってないのよ パパ後でやるよなに怒ってんだよ ママの目的片付けを早く終わらせたかった', '一緒にテレビを見たかったかも パパの目的次立ち上がるタイミングで片付けたかった', '片付ければいつでも良しこのようなケースは日常生活でよく遭遇すると思います', '子供の食事が遅いとき、ママは早く終わらせることをゴールにしてしまうときありますよね子供は全部キレイに残さず食べることに意欲を持っていたらどうなるでしょうまた例1でのママはルールを守らせることや、部屋を散かしたくないをゴールとしていたかも知れませんね', '3価値観の違いこれはとある価値観に対して重要度優先度有意性の違いで、なかなか共感し合えないもの', 'おさらいになりますが、私が考えている価値観は以下10個です', '1金銭感覚 2対人関係家族以外 3仕事のため 4家族のため 5自己満足のため 6カラダ健康のため 7時間の使い方 8感情の捉え方 9環境モノことの考えて方 10労力の基準そしてこの価値観の違いについて、例えばパパが仕事帰りにお酒を飲んでくるとき、ママは金銭感覚や時間の使い方、カラダ健康のためには良くないと思うでしょう', 'しかしパパはママと同じ価値観を持っていても人間関係や仕事のためというママが持っていない価値観も持っていて、この優先順位が違うので家庭をかえりみず行動をしてしまっているのです', 'そのためパパが酔っ払って帰ってきたときコミュニケーションエラーが発生し、またママは何度言っても改善されないことについても怒ってしまう', 'このような考え方や大切なものの違いが価値観の違いです', 'また例1だと、子供には 時間の使い方、感情の捉え方、環境モノことの考えて方に対する自分なりの価値観があり、ママとの違いもある', 'また 情報 における知識の違いや知識の量によっても個人差があり、この個人差は生活環境や生い立ちなどでも違います', 'ママは育児に対して自分の母親からアレコレ言われるのはいやですよね  最後に配慮とお気遣いも忘れずにここまでコミュニケーションエラーについて情報不足と3つ違いについて考えを深めてきました', 'そして最後にもう1つ配慮とお気遣いもコミュニケーションエラーが起こる原因の1つです', 'これは立場や年齢性別、モノゴトの成熟度や身体能力などの個の違いへ対応と、 情報 の渡し方や態度、 情報 の渡す順序などに配慮と気遣いが必要となります', '具体的には会話とメールの違いだったり、会話中に目を見ているかどうかなど、話の内容によっては直接の距離と時間を取ってコミュニケーションをすることや、場合によっては絵や図を描いたり後から議事録を送ったりと、可視化することも必要でしょう', 'また強いていえば、タイミングも重要ですよね', 'この辺のお話は今後 やる気モチベーションというテーマのときに詳しくお話します ので、今回は配慮とお気遣いの概要のみご理解ください', '今回の内容いかがでしたかなんか長過ぎですよね', '詳しく伝えると情報量が多くなりますが、そんなときはを読んで全部読む価値があるから確認してください', 'ではます', '1 コミュニケーションエラーの原因は以下の状態が黄色信号である', '情報不足に陥る', '違いが主張になる', '配慮と気遣いが足りない', '2違いは以下3つの要因が関係している', '勘違い    ゴールの違い    価値観の違い 3もし今後、 コミュニケーションエラーやケンカになるような状態になったら、今回学んだことを思い出し心のブレーキを踏み、情報修正をする', 'コミュニケーションエラーの原因がわかれば問題解決や起動修正がやりやすくなり、コミュニケーションエラーの早期発見や予防ができるようになります', 'ポイントは心のブレーキを踏み、いったん気持ちや 情報 をホームポジションに戻して再構築することですね', 'この心のブレーキが当たり前のようにできればケンカをしない関係を維持できるはずです', 'しかしこの心のブレーキが踏めない状態で権威の差がある場合、権威が上の人が権力を振りかざして相手を服従させようとしがちてす', 'このことは親と子供やパパとママ、上司と部下など、権威を有している人がコミュニケーションエラーを認めないときに発生しがちです', '次回はこの相手を服従ということをについて育児パワハラという新しい考え方を学び、育児において自分自身が育児パワハラに陥らないよう考察していきます', 'それではまたコミュニケーション理論の基礎']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oshiete.goo.ne.jp/qa/4747293.html \n",
      " ['']\n",
      "Before subj  basis 喧嘩をする一番の原因なのです reslut  ので 12 A\n",
      "Before subj  basis 喧嘩をする一番の原因なのです reslut  なので 13 A\n",
      "Before subj  basis 喧嘩をする一番の原因なのです reslut  ので 16 A\n",
      "Before subj  basis 喧嘩をする一番の原因なのです reslut  なので 17 A\n",
      "Before subj  basis 喧嘩をする一番の原因なのです reslut  理由で 45 A\n",
      "Before subj  basis 喧嘩をする一番の原因なのです嫌いだからという reslut  から 61 A\n",
      "Before subj  basis 喧嘩をする一番の原因なのです reslut  なので 80 A\n",
      "Before subj  basis 喧嘩をする一番の原因なのです嫌いだからという reslut  だから 81 A\n",
      "Before subj 前もって喧嘩を防いだり、避けたり、謝ることが basis しない人は理解がある人です reslut 前もって喧嘩を防いだり、避けたり、謝ることができます から、 60 B\n",
      "Before subj 前もって喧嘩を防いだり、避けたり、謝ることが basis しない人は理解がある人ですから reslut 前もって喧嘩を防いだり、避けたり、謝ることができます から 61 B\n",
      "Before subj 行く先々でトラブルということに basis 人に理解が不足していたため、行く先々でトラブルということになるのです reslut  ので 12 B\n",
      "Before subj 行く先々でトラブルということに basis 人に理解が不足していたため、行く先々でトラブルということになるのです reslut  ので 16 B\n",
      "Before subj 行く先々でトラブルということに basis 人に理解が不足していた reslut 行く先々でトラブルということになるのです ため、 23 B\n",
      "Before subj 分からないときには教えてくださいと言えず、すぐ分からないから教えろと basis 分からない reslut ときには教えてくださいと言えず、すぐ分からないから教えろと怒ります から 61 B\n",
      "Before subj 分からないときには教えてくださいと言えず、すぐ分からないから教えろと basis ときには教えてくださいと言えず、すぐ reslut 教えろと怒ります から 61 B\n",
      "Before subj  basis 理解するより自分のことを理解させることを優先させてしまっているからです reslut  から 61 A\n",
      "Before subj  basis 喧嘩の原因なら理解力を身につけることこそが喧嘩をしないコツなのです reslut  ので 12 A\n",
      "Before subj  basis 喧嘩の原因なら理解力を身につけることこそが喧嘩をしないコツなのです reslut  なので 13 A\n",
      "Before subj  basis 喧嘩の原因なら理解力を身につけることこそが喧嘩をしないコツなのです reslut  ので 16 A\n",
      "Before subj  basis 喧嘩の原因なら理解力を身につけることこそが喧嘩をしないコツなのです reslut  なので 17 A\n",
      "Before subj  basis 喧嘩の原因なら理解力を身につけることこそが喧嘩をしないコツなのです reslut  なので 80 A\n",
      "Before subj 自分のことばかりを考えるのではなく、相手のことも理解するという理解力を basis ことばかりを考えるのではなく reslut 相手のことも理解するという理解力を持ちましょう ので 12 B\n",
      "Before subj 自分のことばかりを考えるのではなく、相手のことも理解するという理解力を basis ことばかりを考えるのではなく reslut 相手のことも理解するという理解力を持ちましょう ので 16 B\n",
      "Before subj  basis 上手な人は、理解力のある人なのです reslut  ので 12 A\n",
      "Before subj  basis 上手な人は、理解力のある人なのです reslut  なので 13 A\n",
      "Before subj  basis 上手な人は、理解力のある人なのです reslut  ので 16 A\n",
      "Before subj  basis 上手な人は、理解力のある人なのです reslut  なので 17 A\n",
      "Before subj  basis 上手な人は、理解力のある人なのです reslut  なので 80 A\n",
      "Before subj  basis カーミングシグナルとは、犬特有のコミュニケーション reslut 犬が野生時代に群れで暮らしていた時から備わっていたものです で、 10 A\n",
      "Before subj  basis カーミングシグナルとは、犬特有のコミュニケーションで、犬が野生時代に群れで暮らしていた時から備わっていたものです reslut  ので 12 A\n",
      "Before subj  basis カーミングシグナルとは、犬特有のコミュニケーションで、犬が野生時代に群れで暮らしていた時から備わっていたものです reslut  ので 16 A\n",
      "Before subj  basis カーミングシグナルとは、犬特有のコミュニケーションで、犬が野生時代に群れで暮らしていた reslut 備わっていたものです から 61 A\n",
      "Before subj ほかの犬に自分の意思を伝えるためのボディランゲージが basis 中では、リーダーを中心として円滑に暮らしていく必要があった reslut ほかの犬に自分の意思を伝えるためのボディランゲージが発達しました ため、 23 B\n",
      "Before subj 犬同士の無用な争いを basis 争う気がないことを示す reslut 犬同士の無用な争いを避けているのです で、 10 B\n",
      "Before subj 犬同士の無用な争いを basis 争う気がないことを示すことで、犬同士の無用な争いを避けているのです reslut  ので 12 B\n",
      "Before subj 犬同士の無用な争いを basis 争う気がないことを示すことで、犬同士の無用な争いを避けているのです reslut  ので 16 B\n",
      "Before subj 犬同士の無用な争いを basis 争う気がないことを示す reslut 犬同士の無用な争いを避けているのです ことで 86 B\n",
      "Before subj その行動で無用な争いはやめなさいと basis 犬であろうと、人間であろうと、犬はその行動で無用な争いはやめなさいと伝えてくれているのです reslut  ので 12 B\n",
      "Before subj その行動で無用な争いはやめなさいと basis 犬であろうと、人間であろうと、犬はその行動で無用な争いはやめなさいと伝えてくれているのです reslut  ので 16 B\n",
      "Before subj  basis 使われることがあるのです reslut  ので 12 A\n",
      "Before subj  basis 使われることがあるのです reslut  ので 16 A\n",
      "Before subj  basis 一緒にいる相手とより友好的に過ごしたい時にみせる行動なの reslut たくさん遊んであげましょう で、 10 A\n",
      "Before subj  basis 一緒にいる相手とより友好的に過ごしたい時にみせる行動な reslut たくさん遊んであげましょう ので、 11 A\n",
      "Before subj  basis 一緒にいる相手とより友好的に過ごしたい時にみせる行動なので reslut たくさん遊んであげましょう ので 12 A\n",
      "Before subj  basis 一緒にいる相手とより友好的に過ごしたい時にみせる行動なので reslut たくさん遊んであげましょう なので 13 A\n",
      "Before subj  basis 一緒にいる相手とより友好的に過ごしたい時にみせる行動 reslut たくさん遊んであげましょう なので、 14 A\n",
      "Before subj  basis 一緒にいる相手とより友好的に過ごしたい時にみせる行動な reslut たくさん遊んであげましょう ので、 15 A\n",
      "Before subj  basis 一緒にいる相手とより友好的に過ごしたい時にみせる行動なので reslut たくさん遊んであげましょう ので 16 A\n",
      "Before subj  basis 一緒にいる相手とより友好的に過ごしたい時にみせる行動なので reslut たくさん遊んであげましょう なので 17 A\n",
      "Before subj  basis 一緒にいる相手とより友好的に過ごしたい時にみせる行動 reslut たくさん遊んであげましょう なので、 18 A\n",
      "Before subj  basis 一緒にいる相手とより友好的に過ごしたい時にみせる行動 reslut たくさん遊んであげましょう なので、 78 A\n",
      "Before subj  basis 一緒にいる相手とより友好的に過ごしたい時にみせる行動なので reslut たくさん遊んであげましょう なので 80 A\n",
      "Before subj  basis 反省していないのではなく、わかりましたので落ち着いてくださいという意味です reslut  ので 12 A\n",
      "Before subj  basis 反省していないのではなく、わかりましたので落ち着いてくださいという意味です reslut  ので 12 A\n",
      "Before subj  basis 反省していないのではなく、わかりましたので落ち着いてくださいという意味です reslut  ので 16 A\n",
      "Before subj  basis 反省していないのではなく、わかりましたので落ち着いてくださいという意味です reslut  ので 16 A\n",
      "Before subj 日頃から愛犬の行動をよく観察し、カーミングシグナルに応えてあげることで、より深い信頼関係を basis 愛犬の行動をよく観察し、カーミングシグナルに応えてあげることで、より reslut 深い信頼関係を築きましょう で、 10 B\n",
      "Before subj 日頃から愛犬の行動をよく観察し、カーミングシグナルに応えてあげることで、より深い信頼関係を basis 日頃 reslut 愛犬の行動をよく観察し、カーミングシグナルに応えてあげることで、より深い信頼関係を築きましょう から 61 B\n",
      "Before subj 日頃から愛犬の行動をよく観察し、カーミングシグナルに応えてあげることで、より深い信頼関係を basis 愛犬の行動をよく観察し、カーミングシグナルに応えてあげる、より reslut 深い信頼関係を築きましょう ことで 86 B\n",
      "Before subj くわしい弁護士堀井亜生先生の解説から basis カップルが喧嘩する一番の原因って何また、喧嘩をしてしまったとき、仲直りするために効果的な謝り方とは働く男女369人のアンケートと男女の仲にくわしい弁護士堀井亜生先生の解説 reslut 探っていきましょう から 61 B\n",
      "Before subj  basis カップルが喧嘩する原因と時期ってカップルが喧嘩をしてしまうのには、それなりの理由や原因があるものです reslut  ので 12 A\n",
      "Before subj  basis カップルが喧嘩する原因と時期ってカップルが喧嘩をしてしまうのには、それなりの理由や原因があるものです reslut  ので 16 A\n",
      "Before subj カップルが喧嘩する原因ランキングちょっとしたことがきっかけで、 basis 喧嘩する原因ランキングちょっとしたことがきっかけ reslut あるでしょう で、 10 B\n",
      "Before subj ランキングに basis カップルたちはどんな原因によって喧嘩をしているのでしょうか男女 reslut 意見をランキングにました ので 12 B\n",
      "Before subj ランキングに basis カップルたちはどんな原因によって喧嘩をしているのでしょうか男女 reslut 意見をランキングにました ので 16 B\n",
      "Before subj ランキングに basis カップルたちはどんな原因 reslut 喧嘩をしているのでしょうか男女の意見をランキングにました によって 65 B\n",
      "Before subj 働く男女に basis 喧嘩が起こりやすくなるものなのでしょうかここでは、カップルの喧嘩が増える時期やタイミングについて、働く男女に尋ねてみました reslut  ので 12 B\n",
      "Before subj 働く男女に basis 喧嘩が起こりやすくなるものなのでしょうかここでは、カップルの喧嘩が増える時期やタイミングについて、働く男女に尋ねてみました reslut  なので 13 B\n",
      "Before subj 働く男女に basis 喧嘩が起こりやすくなるものなのでしょうかここでは、カップルの喧嘩が増える時期やタイミングについて、働く男女に尋ねてみました reslut  ので 16 B\n",
      "Before subj 働く男女に basis 喧嘩が起こりやすくなるものなのでしょうかここでは、カップルの喧嘩が増える時期やタイミングについて、働く男女に尋ねてみました reslut  なので 17 B\n",
      "Before subj 働く男女に basis 喧嘩が起こりやすくなるものなのでしょうかここでは、アンケート reslut 喧嘩が増える時期やタイミングについて、働く男女に尋ねてみました から 61 B\n",
      "Before subj 働く男女に basis 喧嘩が起こりやすくなるものなのでしょうかここでは、カップルの喧嘩が増える時期やタイミングについて reslut 男女に尋ねてみました によって 65 B\n",
      "Before subj 働く男女に basis 喧嘩が起こりやすくなるものなのでしょうかここでは、カップルの喧嘩が増える時期やタイミングについて、働く男女に尋ねてみました reslut  なので 80 B\n",
      "Before subj  basis 合わなくなる reslut  から 61 A\n",
      "Before subj  basis すれ違いなど reslut  から 61 A\n",
      "Before subj 関係が basis 大切に思う気持ちが薄れてくる reslut 女性23歳学校教育関連専門職ある程度長く付き合っていると、自然と関係がマンネリ化してしまいがちです から 61 B\n",
      "Before subj  basis 会いたい reslut いつしかそうした気遣いを忘れてしまうこともあります ので 12 A\n",
      "Before subj  basis 出てくるといつしかそうした気遣いを忘れてしまうこともありますものですが reslut  ので 12 A\n",
      "Before subj  basis 会いたい reslut いつしかそうした気遣いを忘れてしまうこともあります ので 16 A\n",
      "Before subj  basis 出てくるといつしかそうした気遣いを忘れてしまうこともありますものですが reslut  ので 16 A\n",
      "Before subj  basis 出てくるといつしか相手 reslut 気遣いを忘れてしまうこともあります から 61 A\n",
      "Before subj 不満に思う気持ちが募り、ある日爆発してしまうカップルが basis 思う気持ちが募り、ある日爆発してしまうカップルが多いのでしょう reslut  ので 12 B\n",
      "Before subj 不満に思う気持ちが募り、ある日爆発してしまうカップルが basis 思う気持ちが募り、ある日爆発してしまうカップルが多いのでしょう reslut  ので 16 B\n",
      "Before subj ケンカについて、コミュニケーションエラーの観点から考えると以下のようなプロセスが起因していると basis ケンカについて、コミュニケーションエラーの観点 reslut 考えると以下のようなプロセスが起因していると考えられます から 61 B\n",
      "Before subj 投げ手からの新たな情報に対して basis 投げ手からの reslut 新たな情報に対して再度反応する から 61 B\n",
      "Before subj ケンカと basis 難しいですよねwこのようなキャッチボールが続いている状態 reslut 受け手からの反応に攻撃的や不快だと思われる態度が含まれていたとき、返事を受け取った投げ手の感情や価値観に触れ、投げ手側も攻撃的な態度へ変化した状態がケンカと呼べるでしょう で、 10 B\n",
      "Before subj ケンカと basis 難しいですよねwこのようなキャッチボールが続いている状態で、受け手からの reslut 反応に攻撃的や不快だと思われる態度が含まれていたとき、返事を受け取った投げ手の感情や価値観に触れ、投げ手側も攻撃的な態度へ変化した状態がケンカと呼べるでしょう から 61 B\n",
      "Before subj 場合によってはキャッチボールすらできない状態に basis 投げ手からの reslut 最初の情報に感情的な態度が含まれていたり、情報の投げ方が悪いと判断される場合もケンカにつながり、場合によってはキャッチボールすらできない状態になります から 61 B\n",
      "Before subj 場合によってはキャッチボールすらできない状態に basis 投げ手からの最初の情報に感情的な態度が含まれていたり、情報の投げ方が悪いと判断される場合もケンカにつながり、場合によっては reslut キャッチボールすらできない状態になります によって 65 B\n",
      "Before subj 考察を basis ここからはもう少し大きな概念で考えをる reslut 先ほどとは違う観点で直し、日常生活での出来事と照らし合わせて考察を進めます ため、 23 B\n",
      "Before subj 考察を basis ここからは reslut もう少し大きな概念で考えをるため、先ほどとは違う観点で直し、日常生活での出来事と照らし合わせて考察を進めます から 61 B\n",
      "Before subj この例の場合、ママは事前に片付けながら遊ぶ約束をしていた伝えていたので知識の不足はないと basis 例の場合、ママは事前に片付けながら遊ぶ約束をしていた伝えていた reslut 知識の不足はないと思ってます ので 12 B\n",
      "Before subj この例の場合、ママは事前に片付けながら遊ぶ約束をしていた伝えていたので知識の不足はないと basis 例の場合、ママは事前に片付けながら遊ぶ約束をしていた伝えていた reslut 知識の不足はないと思ってます ので 16 B\n",
      "Before subj  basis よくよく考えると子供は全部の玩具を使って遊んでいる可能性もある reslut ルールを破っているとは言い切れません ので 12 A\n",
      "Before subj  basis よくよく考えると子供は全部の玩具を使って遊んでいる可能性もある reslut ルールを破っているとは言い切れません ので 16 A\n",
      "Before subj 単純な情報不足ではないケースだと basis ママは自分の思っていたことが実現されていない reslut 感情が抑えられなくなってしまったと考えられないでしょうかそしてこの場合、ママは片付けるという依頼のコミュニケーションで実現したかったものは何だったのでしょうかこの例をみると、単純な情報不足ではないケースだと解ります ので 12 B\n",
      "Before subj 単純な情報不足ではないケースだと basis ママは自分の思っていたことが実現されていないので感情が抑えられなくなってしまったと考えられないでしょうかそしてこの場合、ママは片付けるという依頼のコミュニケーションで実現したかったものは何だったのでしょうかこ reslut 例をみると、単純な情報不足ではないケースだと解ります ので 12 B\n",
      "Before subj 単純な情報不足ではないケースだと basis ママは自分の思っていたことが実現されていない reslut 感情が抑えられなくなってしまったと考えられないでしょうかそしてこの場合、ママは片付けるという依頼のコミュニケーションで実現したかったものは何だったのでしょうかこの例をみると、単純な情報不足ではないケースだと解ります ので 16 B\n",
      "Before subj 単純な情報不足ではないケースだと basis ママは自分の思っていたことが実現されていないので感情が抑えられなくなってしまったと考えられないでしょうかそしてこの場合、ママは片付けるという依頼のコミュニケーションで実現したかったものは何だったのでしょうかこ reslut 例をみると、単純な情報不足ではないケースだと解ります ので 16 B\n",
      "Before subj その違いに気付かず話が進んでいたためコミュニケーションエラーが発生し、親子ゲンカになったと basis その違いに気付かず話が進んでいたためコミュニケーションエラーが発生し、親子ゲンカになったと reslut その違いに気付かず話が進んでいた ため。 22 C\n",
      "Before subj  basis 解釈の誤り、思い込みや偏見などにより reslut 本来とは違う情報を持ち合わせた状態 により 66 A\n",
      "Before subj  basis 解釈の誤り、思い込みや偏見など reslut 本来とは違う情報を持ち合わせた状態 により、 67 A\n",
      "Before subj 例1だと、ママから伝えた玩具を使い終わったならという条件に対して、ママが今使ってないから使い終わったと解釈したことが該当するかと basis ママ reslut 伝えた玩具を使い終わったならという条件に対して、ママが今使ってないから使い終わったと解釈したことが該当するかと考えられます から 61 B\n",
      "Before subj 例1だと、ママから伝えた玩具を使い終わったならという条件に対して、ママが今使ってないから使い終わったと解釈したことが該当するかと basis ママから伝えた玩具を使い終わったならという条件に対して、ママが今使ってない reslut 使い終わったと解釈したことが該当するかと考えられます から 61 B\n",
      "Before subj  basis ママは部屋を離れ戻ってくると片付けが終わってなかった reslut 怒った ので 12 A\n",
      "Before subj  basis ママは部屋を離れ戻ってくると片付けが終わってなかった reslut 怒った ので 16 A\n",
      "Before subj 重要度優先度有意性の違いで、 basis 違いこれはとある価値観に対して重要度優先度有意性の reslut かなか共感し合えないもの で、 10 B\n",
      "Before subj 1金銭感覚2対人関係家族以外3仕事のため4家族のため5自己満足のため6カラダ健康のため7時間の使い方8感情の捉え方9環境モノことの考えて方10労力の基準そしてこの価値観の違いについて、例えばパパが仕事帰りにお酒を飲んでくるとき、ママは金銭感覚や時間の使い方、カラダ健康のためには良くないと basis 1金銭感覚2対人関係家族以外3仕事のため4家族のため5自己満足のため6カラダ健康のため7時間の使い方8感情の捉え方9環境モノことの考えて方10労力の基準そしてこの価値観の違いについて、例えばパパが仕事帰りにお酒を飲んでくるとき、ママは金銭感覚や時間の使い方、カラダ健康のためには良くないと reslut 3仕事の ため。 22 C\n",
      "Before subj 1金銭感覚2対人関係家族以外3仕事のため4家族のため5自己満足のため6カラダ健康のため7時間の使い方8感情の捉え方9環境モノことの考えて方10労力の基準そしてこの価値観の違いについて、例えばパパが仕事帰りにお酒を飲んでくるとき、ママは金銭感覚や時間の使い方、カラダ健康のためには良くないと basis 1金銭感覚2対人関係家族以外3仕事のため4家族のため5自己満足のため6カラダ健康のため7時間の使い方8感情の捉え方9環境モノことの考えて方10労力の基準そしてこの価値観の違いについて、例えばパパが仕事帰りにお酒を飲んでくるとき、ママは金銭感覚や時間の使い方、カラダ健康のためには良くないと reslut 3仕事のため4家族の ため。 22 C\n",
      "Before subj 1金銭感覚2対人関係家族以外3仕事のため4家族のため5自己満足のため6カラダ健康のため7時間の使い方8感情の捉え方9環境モノことの考えて方10労力の基準そしてこの価値観の違いについて、例えばパパが仕事帰りにお酒を飲んでくるとき、ママは金銭感覚や時間の使い方、カラダ健康のためには良くないと basis 1金銭感覚2対人関係家族以外3仕事のため4家族のため5自己満足のため6カラダ健康のため7時間の使い方8感情の捉え方9環境モノことの考えて方10労力の基準そしてこの価値観の違いについて、例えばパパが仕事帰りにお酒を飲んでくるとき、ママは金銭感覚や時間の使い方、カラダ健康のためには良くないと reslut 3仕事のため4家族のため5自己満足の ため。 22 C\n",
      "Before subj 1金銭感覚2対人関係家族以外3仕事のため4家族のため5自己満足のため6カラダ健康のため7時間の使い方8感情の捉え方9環境モノことの考えて方10労力の基準そしてこの価値観の違いについて、例えばパパが仕事帰りにお酒を飲んでくるとき、ママは金銭感覚や時間の使い方、カラダ健康のためには良くないと basis 1金銭感覚2対人関係家族以外3仕事のため4家族のため5自己満足のため6カラダ健康のため7時間の使い方8感情の捉え方9環境モノことの考えて方10労力の基準そしてこの価値観の違いについて、例えばパパが仕事帰りにお酒を飲んでくるとき、ママは金銭感覚や時間の使い方、カラダ健康のためには良くないと reslut 3仕事のため4家族のため5自己満足のため6カラダ健康の ため。 22 C\n",
      "Before subj 行動を basis パパはママと同じ価値観を持っていても人間関係や仕事のためというママが持っていない価値観も持っていて、この優先順位が違う reslut 家庭をかえりみず行動をしてしまっているのです ので 12 B\n",
      "Before subj 行動を basis パパはママと同じ価値観を持っていても人間関係や仕事のためというママが持っていない価値観も持っていて、この優先順位が違うので家庭をかえりみず行動をしてしまっているのです reslut  ので 12 B\n",
      "Before subj 行動を basis パパはママと同じ価値観を持っていても人間関係や仕事のためというママが持っていない価値観も持っていて、この優先順位が違う reslut 家庭をかえりみず行動をしてしまっているのです ので 16 B\n",
      "Before subj 行動を basis パパはママと同じ価値観を持っていても人間関係や仕事のためというママが持っていない価値観も持っていて、この優先順位が違うので家庭をかえりみず行動をしてしまっているのです reslut  ので 16 B\n",
      "Before subj  basis しかしパパはママと同じ価値観を持っていても人間関係や仕事のためというママが持っていない価値観も持っていて、この優先順位が違うので家庭をかえりみず行動をしてしまっているのです reslut その ため。 22 D\n",
      "Before subj  basis 情報における知識の違いや知識の量によっても reslut 個人差があり、この個人差は生活環境や生い立ちなどでも違います によって 65 A\n",
      "Before subj 考えを basis 育児に対して自分の母親 reslut アレコレ言われるのはいやですよね最後に配慮とお気遣いも忘れずにここまでコミュニケーションエラーについて情報不足と3つ違いについて考えを深めてきました から 61 B\n",
      "Before subj  basis 会話とメールの違いだったり、会話中に目を見ているかどうかなど、話の内容によっては必要でしょう描いたり後 reslut  から 61 A\n",
      "Before subj  basis 会話とメールの違いだったり、会話中に目を見ているかどうかなど、話の内容によっては reslut 必要でしょう によって 65 A\n",
      "Before subj  basis 会話とメールの違いだったり、会話中に目を見ているかどうかなど、話の内容によっては必要でしょう場合によっては reslut  によって 65 A\n",
      "Before subj  basis 辺のお話は今後やる気モチベーションというテーマのときに詳しくお話しますの reslut 今回は配慮とお気遣いの概要のみご理解ください で、 10 A\n",
      "Before subj  basis 辺のお話は今後やる気モチベーションというテーマのときに詳しくお話します reslut 今回は配慮とお気遣いの概要のみご理解ください ので、 11 A\n",
      "Before subj  basis 辺のお話は今後やる気モチベーションというテーマのときに詳しくお話しますので reslut 今回は配慮とお気遣いの概要のみご理解ください ので 12 A\n",
      "Before subj  basis 辺のお話は今後やる気モチベーションというテーマのときに詳しくお話します reslut 今回は配慮とお気遣いの概要のみご理解ください ので、 15 A\n",
      "Before subj  basis 辺のお話は今後やる気モチベーションというテーマのときに詳しくお話しますので reslut 今回は配慮とお気遣いの概要のみご理解ください ので 16 A\n",
      "Before subj  basis ときはを読んで全部読む価値があるから確認してください reslut  から 61 A\n",
      "Before subj  basis 心のブレーキを踏み、いったん気持ちや情報をホームポジションに戻して再構築するすね reslut  ことで 86 A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before subj 言葉や暴力による争いのことを basis 言葉や暴力による争いのことを reslut 喧嘩って何喧嘩とは、言葉や による。 51 C\n",
      "Before subj  basis 為、冷静に話し合っていても、言い争っているのであれば reslut それは喧嘩です ので 12 A\n",
      "Before subj  basis 為、冷静に話し合っていても、言い争っているのであれば reslut それは喧嘩です ので 16 A\n",
      "Before subj  basis 風に喧嘩の定義が分かると、喧嘩をしたことがないカップルでも、本当は喧嘩をしていたということになりませんか喧嘩とは、お付き合いしていく上で決して避けては通れない壁なのです reslut  ので 12 A\n",
      "Before subj  basis 風に喧嘩の定義が分かると、喧嘩をしたことがないカップルでも、本当は喧嘩をしていたということになりませんか喧嘩とは、お付き合いしていく上で決して避けては通れない壁なのです reslut  なので 13 A\n",
      "Before subj  basis 風に喧嘩の定義が分かると、喧嘩をしたことがないカップルでも、本当は喧嘩をしていたということになりませんか喧嘩とは、お付き合いしていく上で決して避けては通れない壁なのです reslut  ので 16 A\n",
      "Before subj  basis 風に喧嘩の定義が分かると、喧嘩をしたことがないカップルでも、本当は喧嘩をしていたということになりませんか喧嘩とは、お付き合いしていく上で決して避けては通れない壁なのです reslut  なので 17 A\n",
      "Before subj  basis 風に喧嘩の定義が分かると、喧嘩をしたことがないカップルでも、本当は喧嘩をしていたということになりませんか喧嘩とは、お付き合いしていく上で決して避けては通れない壁なのです reslut  なので 80 A\n",
      "Before subj  basis 原因や理由 reslut 喧嘩になってしまうのかを考えていくと、自ずと見つかっていきます から 61 A\n",
      "Before subj  basis 感情をぶつけてしまう喧嘩ばかりのカップルに多い原因は、自分の感情を恋人にぶつけてしまうす reslut  ことで 86 A\n",
      "Before subj 恋人には関係ないところでイライラしたのに、そのイライラを恋人にぶつけてしまい喧嘩になることが basis 関係ないところでイライラしたのに、そのイライラを恋人にぶつけてしまい喧嘩になることが多いのです reslut  ので 12 B\n",
      "Before subj 恋人には関係ないところでイライラしたのに、そのイライラを恋人にぶつけてしまい喧嘩になることが basis 関係ないところでイライラしたのに、そのイライラを恋人にぶつけてしまい喧嘩になることが多いのです reslut  ので 16 B\n",
      "Before subj  basis 感情に振り回されて恋人に突然甘えたり、素っ気なくしたりと reslut 態度が違えば、恋人だってイライラします によって 65 A\n",
      "Before subj 喧嘩になる原因を basis ところから、喧嘩になる原因を生み出してしまうのです reslut  ので 12 B\n",
      "Before subj 喧嘩になる原因を basis ところから、喧嘩になる原因を生み出してしまうのです reslut  ので 16 B\n",
      "Before subj 喧嘩になる原因を basis ところ reslut 喧嘩になる原因を生み出してしまうのです から、 60 B\n",
      "Before subj 喧嘩になる原因を basis ところから reslut 喧嘩になる原因を生み出してしまうのです から 61 B\n",
      "Before subj  basis わがままを言うのであれば reslut うんざりしてしまいます ので 12 A\n",
      "Before subj  basis わがままを聞かされているとうんざりしてしまいますものですが reslut  ので 12 A\n",
      "Before subj  basis わがままを言うのであれば reslut うんざりしてしまいます ので 16 A\n",
      "Before subj  basis わがままを聞かされているとうんざりしてしまいますものですが reslut  ので 16 A\n",
      "Before subj  basis わがままを聞かされているとうんざりしてしまいます reslut  から 61 A\n",
      "Before subj 喧嘩に basis 日頃の積み重ねが原因となって、喧嘩に発展してしまうのです reslut  ので 12 B\n",
      "Before subj 喧嘩に basis 日頃の積み重ねが原因となって、喧嘩に発展してしまうのです reslut  ので 16 B\n",
      "Before subj 喧嘩ばかりのカップルに basis 上手く伝える術を知らないカップルが、わがままを理由に喧嘩ばかりのカップルになってしまうのです reslut  ので 12 B\n",
      "Before subj 喧嘩ばかりのカップルに basis 上手く伝える術を知らないカップルが、わがままを理由に喧嘩ばかりのカップルになってしまうのです reslut  ので 16 B\n",
      "Before subj 喧嘩ばかりのカップルに basis 意外と浮気をしても別れないカップルが多く、恋人が浮気をする度に喧嘩となり、喧嘩ばかりのカップルになってしまうのです reslut  ので 12 B\n",
      "Before subj 喧嘩ばかりのカップルに basis 意外と浮気をしても別れないカップルが多く、恋人が浮気をする度に喧嘩となり、喧嘩ばかりのカップルになってしまうのです reslut  ので 16 B\n",
      "Before subj  basis いますことによって reslut  によって 65 A\n",
      "Before subj 喧嘩の原因と basis 食生活など小さな理由 reslut 喧嘩の原因となってしまいます から 61 B\n",
      "Before subj 喧嘩ばかりに basis 合わせようにも、お互いが引かない状態なの reslut 価値観のすり合わせが出来ず喧嘩ばかりになってしまうのです で、 10 B\n",
      "Before subj 喧嘩ばかりに basis 合わせようにも、お互いが引かない状態な reslut 価値観のすり合わせが出来ず喧嘩ばかりになってしまうのです ので、 11 B\n",
      "Before subj 喧嘩ばかりに basis 合わせようにも、お互いが引かない状態なので reslut 価値観のすり合わせが出来ず喧嘩ばかりになってしまうのです ので 12 B\n",
      "Before subj 喧嘩ばかりに basis 合わせようにも、お互いが引かない状態なので、価値観のすり合わせが出来ず喧嘩ばかりになってしまうのです reslut  ので 12 B\n",
      "Before subj 喧嘩ばかりに basis 合わせようにも、お互いが引かない状態なので reslut 価値観のすり合わせが出来ず喧嘩ばかりになってしまうのです なので 13 B\n",
      "Before subj 喧嘩ばかりに basis 合わせようにも、お互いが引かない状態 reslut 価値観のすり合わせが出来ず喧嘩ばかりになってしまうのです なので、 14 B\n",
      "Before subj 喧嘩ばかりに basis 合わせようにも、お互いが引かない状態な reslut 価値観のすり合わせが出来ず喧嘩ばかりになってしまうのです ので、 15 B\n",
      "Before subj 喧嘩ばかりに basis 合わせようにも、お互いが引かない状態なので reslut 価値観のすり合わせが出来ず喧嘩ばかりになってしまうのです ので 16 B\n",
      "Before subj 喧嘩ばかりに basis 合わせようにも、お互いが引かない状態なので、価値観のすり合わせが出来ず喧嘩ばかりになってしまうのです reslut  ので 16 B\n",
      "Before subj 喧嘩ばかりに basis 合わせようにも、お互いが引かない状態なので reslut 価値観のすり合わせが出来ず喧嘩ばかりになってしまうのです なので 17 B\n",
      "Before subj 喧嘩ばかりに basis 合わせようにも、お互いが引かない状態 reslut 価値観のすり合わせが出来ず喧嘩ばかりになってしまうのです なので、 18 B\n",
      "Before subj 喧嘩ばかりに basis 合わせようにも、お互いが引かない状態 reslut 価値観のすり合わせが出来ず喧嘩ばかりになってしまうのです なので、 78 B\n",
      "Before subj 喧嘩ばかりに basis 合わせようにも、お互いが引かない状態なので reslut 価値観のすり合わせが出来ず喧嘩ばかりになってしまうのです なので 80 B\n",
      "Before subj 喧嘩に basis 過剰な嫉妬や束縛 reslut 恋人が不自由を感じ、怒って喧嘩になるのです で、 10 B\n",
      "Before subj 喧嘩に basis 過剰な嫉妬や束縛で、恋人が不自由を感じ、怒って喧嘩になるのです reslut  ので 12 B\n",
      "Before subj 喧嘩に basis 過剰な嫉妬や束縛で、恋人が不自由を感じ、怒って喧嘩になるのです reslut  ので 16 B\n",
      "Before subj  basis 友好関係が広く男女ともに友達の多い恋人に対して、愛されているのか不安を抱いている reslut います ため、 23 A\n",
      "Before subj 喧嘩ばかりのカップルに basis 不安が原因となって、喧嘩ばかりのカップルになってしまうのです reslut  ので 12 B\n",
      "Before subj 喧嘩ばかりのカップルに basis 不安が原因となって、喧嘩ばかりのカップルになってしまうのです reslut  ので 16 B\n",
      "Before subj  basis カップルの恋人からの reslut 原因です から 61 A\n",
      "Before subj 喧嘩に basis 連絡してくれないのと、恋人が忙しいのに連絡を催促して、喧嘩になってしまうのです reslut  ので 12 B\n",
      "Before subj 喧嘩に basis 連絡してくれないのと、恋人が忙しいのに連絡を催促して、喧嘩になってしまうのです reslut  ので 16 B\n",
      "Before subj 喧嘩ばかりに basis 連絡を待っていられないの reslut 喧嘩ばかりになってしまうのです で、 10 B\n",
      "Before subj 喧嘩ばかりに basis 連絡を待っていられない reslut 喧嘩ばかりになってしまうのです ので、 11 B\n",
      "Before subj 喧嘩ばかりに basis 連絡を待っていられないので reslut 喧嘩ばかりになってしまうのです ので 12 B\n",
      "Before subj 喧嘩ばかりに basis 連絡を待っていられないので、喧嘩ばかりになってしまうのです reslut  ので 12 B\n",
      "Before subj 喧嘩ばかりに basis 連絡を待っていられない reslut 喧嘩ばかりになってしまうのです ので、 15 B\n",
      "Before subj 喧嘩ばかりに basis 連絡を待っていられないので reslut 喧嘩ばかりになってしまうのです ので 16 B\n",
      "Before subj 喧嘩ばかりに basis 連絡を待っていられないので、喧嘩ばかりになってしまうのです reslut  ので 16 B\n",
      "Before subj  basis 喧嘩ばかりのカップルに多いのは、何度も約束を破り、その度に喧嘩をしているす reslut  ことで 86 A\n",
      "Before subj 喧嘩に basis 守るよう話し合うなどはせず、ただ喧嘩をするの reslut 何度も約束を破ることを理由に喧嘩になります で、 10 B\n",
      "Before subj 喧嘩に basis 守るよう話し合うなどはせず、ただ喧嘩をする reslut 何度も約束を破ることを理由に喧嘩になります ので、 11 B\n",
      "Before subj 喧嘩に basis 守るよう話し合うなどはせず、ただ喧嘩をするので reslut 何度も約束を破ることを理由に喧嘩になります ので 12 B\n",
      "Before subj 喧嘩に basis 守るよう話し合うなどはせず、ただ喧嘩をする reslut 何度も約束を破ることを理由に喧嘩になります ので、 15 B\n",
      "Before subj 喧嘩に basis 守るよう話し合うなどはせず、ただ喧嘩をするので reslut 何度も約束を破ることを理由に喧嘩になります ので 16 B\n",
      "Before subj  basis カップルに多いことです reslut  ことで 86 A\n",
      "Before subj  basis 恋人の大切なものを捨てる意外と多い喧嘩の理由が、恋人の大切なものを勝手に捨てるす reslut  ことで 86 A\n",
      "Before subj  basis いますものだ reslut  から 61 A\n",
      "Before subj  basis いますもの reslut  だから 81 A\n",
      "Before subj 喧嘩ばかりのカップルに basis 理解できない人もおり、喧嘩ばかりのカップルになってしまうのです reslut  ので 12 B\n",
      "Before subj 喧嘩ばかりのカップルに basis 理解できない人もおり、喧嘩ばかりのカップルになってしまうのです reslut  ので 16 B\n",
      "Before subj 喧嘩に basis 繰り返される遅刻に恋人の堪忍袋の緒が切れてしまい、喧嘩になってしまうのです reslut  ので 12 B\n",
      "Before subj 喧嘩に basis 繰り返される遅刻に恋人の堪忍袋の緒が切れてしまい、喧嘩になってしまうのです reslut  ので 16 B\n",
      "Before subj  basis 意外と多いのが遅刻をする側は遅刻癖を直す気がない reslut  ことで 86 A\n",
      "Before subj 喧嘩に basis 気にしないであるのですが reslut 想いばかりで行動をしている為、恋人の不満が溜まり、喧嘩になるのです ので 12 B\n",
      "Before subj 喧嘩に basis 気にしないで自分の想いばかりで行動をしている為、恋人の不満が溜まり、喧嘩になるのです reslut  ので 12 B\n",
      "Before subj 喧嘩に basis 気にしないであるのですが reslut 想いばかりで行動をしている為、恋人の不満が溜まり、喧嘩になるのです ので 16 B\n",
      "Before subj 喧嘩に basis 気にしないで自分の想いばかりで行動をしている為、恋人の不満が溜まり、喧嘩になるのです reslut  ので 16 B\n",
      "Before subj 喧嘩に basis 気にせず恋人に良いところを見せようと、店員に横暴な態度を取ったりなど、そういった行動でも価値観が合わず喧嘩になるのです reslut  ので 12 B\n",
      "Before subj 喧嘩に basis 気にせず恋人に良いところを見せようと、店員に横暴な態度を取ったりなど、そういった行動でも価値観が合わず喧嘩になるのです reslut  ので 16 B\n",
      "Before subj  basis するととても不愉快ですsns上 reslut  で、 10 A\n",
      "Before subj  basis するととても不愉快です reslut  から 61 A\n",
      "Before subj  basis するととても不愉快です reslut  ことで 86 A\n",
      "Before subj 不安な状態が basis sns上だけで病んでいるアピールをするの reslut 恋人からすると何が不満なのと不安な状態が続きます で、 10 B\n",
      "Before subj 不安な状態が basis sns上だけで病んでいるアピールをする reslut 恋人からすると何が不満なのと不安な状態が続きます ので、 11 B\n",
      "Before subj 不安な状態が basis sns上だけで病んでいるアピールをするので reslut 恋人からすると何が不満なのと不安な状態が続きます ので 12 B\n",
      "Before subj 不安な状態が basis sns上だけで病んでいるアピールをする reslut 恋人からすると何が不満なのと不安な状態が続きます ので、 15 B\n",
      "Before subj 不安な状態が basis sns上だけで病んでいるアピールをするので reslut 恋人からすると何が不満なのと不安な状態が続きます ので 16 B\n",
      "Before subj 不安な状態が basis sns上だけで病んでいるアピールをするので、恋人 reslut すると何が不満なのと不安な状態が続きます から 61 B\n",
      "Before subj 喧嘩に basis 不安が苛立ちになり、喧嘩になってしまうのです reslut  ので 12 B\n",
      "Before subj 喧嘩に basis 不安が苛立ちになり、喧嘩になってしまうのです reslut  ので 16 B\n",
      "Before subj  basis 頻度や、自分への態度など、全てが自分の想い通りに恋人が動いてくれないと、嫌なのです reslut  ので 12 A\n",
      "Before subj  basis 頻度や、自分への態度など、全てが自分の想い通りに恋人が動いてくれないと、嫌なのです reslut  なので 13 A\n",
      "Before subj  basis 頻度や、自分への態度など、全てが自分の想い通りに恋人が動いてくれないと、嫌なのです reslut  ので 16 A\n",
      "Before subj  basis 頻度や、自分への態度など、全てが自分の想い通りに恋人が動いてくれないと、嫌なのです reslut  なので 17 A\n",
      "Before subj  basis 頻度や、自分への態度など、全てが自分の想い通りに恋人が動いてくれないと、嫌なのです reslut  なので 80 A\n",
      "Before subj 見当が basis 恋人はそんなこと思ってもいないの reslut ぜ怒っているのか見当がつきません で、 10 B\n",
      "Before subj 見当が basis 恋人はそんなこと思ってもいない reslut ぜ怒っているのか見当がつきません ので、 11 B\n",
      "Before subj 見当が basis 恋人はそんなこと思ってもいないので reslut ぜ怒っているのか見当がつきません ので 12 B\n",
      "Before subj 見当が basis 恋人はそんなこと思ってもいない reslut ぜ怒っているのか見当がつきません ので、 15 B\n",
      "Before subj 見当が basis 恋人はそんなこと思ってもいないので reslut ぜ怒っているのか見当がつきません ので 16 B\n",
      "Before subj 喧嘩に basis 為、お互いが不満を溜めて、喧嘩に発展していくのです reslut  ので 12 B\n",
      "Before subj 喧嘩に basis 為、お互いが不満を溜めて、喧嘩に発展していくのです reslut  ので 16 B\n",
      "Before subj 恋人を basis 完全に恋人を自分の物だと思っているので、恋人の友好関係や趣味から何まで口を reslut 恋人を怒らせてしまいます で、 10 B\n",
      "Before subj 恋人を basis 完全に恋人を自分の物だと思っているので、恋人の友好関係や趣味から何まで口を reslut 恋人を怒らせてしまいます ので、 11 B\n",
      "Before subj 恋人を basis 完全に恋人を自分の物だと思っているので、恋人の友好関係や趣味から何まで口を reslut 恋人を怒らせてしまいます ので 12 B\n",
      "Before subj 恋人を basis 完全に恋人を自分の物だと思っているので、恋人の友好関係や趣味から何まで口を reslut 恋人を怒らせてしまいます ので、 15 B\n",
      "Before subj 恋人を basis 完全に恋人を自分の物だと思っているので、恋人の友好関係や趣味から何まで口を reslut 恋人を怒らせてしまいます ので 16 B\n",
      "Before subj 恋人を basis 完全に恋人を自分の物だと思っているので、恋人の友好関係や趣味から何まで口を出して、恋人を怒らせてしまいます reslut  から 61 B\n",
      "Before subj 話が basis 不満がいっぱいなの reslut 感情的になっていますし、自分は恋人が自分の思う通りに動いて当然だと思っているので、話が噛み合いません で、 10 B\n",
      "Before subj 話が basis 不満がいっぱいなので、感情的になっていますし、自分は恋人が自分の思う通りに動いて当然だと思っているの reslut 話が噛み合いません で、 10 B\n",
      "Before subj 話が basis 不満がいっぱいな reslut 感情的になっていますし、自分は恋人が自分の思う通りに動いて当然だと思っているので、話が噛み合いません ので、 11 B\n",
      "Before subj 話が basis 不満がいっぱいなので、感情的になっていますし、自分は恋人が自分の思う通りに動いて当然だと思っている reslut 話が噛み合いません ので、 11 B\n",
      "Before subj 話が basis 不満がいっぱいなので reslut 感情的になっていますし、自分は恋人が自分の思う通りに動いて当然だと思っているので、話が噛み合いません ので 12 B\n",
      "Before subj 話が basis 不満がいっぱいなので、感情的になっていますし、自分は恋人が自分の思う通りに動いて当然だと思っているので reslut 話が噛み合いません ので 12 B\n",
      "Before subj 話が basis 不満がいっぱいなので reslut 感情的になっていますし、自分は恋人が自分の思う通りに動いて当然だと思っているので、話が噛み合いません なので 13 B\n",
      "Before subj 話が basis 不満がいっぱい reslut 感情的になっていますし、自分は恋人が自分の思う通りに動いて当然だと思っているので、話が噛み合いません なので、 14 B\n",
      "Before subj 話が basis 不満がいっぱいな reslut 感情的になっていますし、自分は恋人が自分の思う通りに動いて当然だと思っているので、話が噛み合いません ので、 15 B\n",
      "Before subj 話が basis 不満がいっぱいなので、感情的になっていますし、自分は恋人が自分の思う通りに動いて当然だと思っている reslut 話が噛み合いません ので、 15 B\n",
      "Before subj 話が basis 不満がいっぱいなので reslut 感情的になっていますし、自分は恋人が自分の思う通りに動いて当然だと思っているので、話が噛み合いません ので 16 B\n",
      "Before subj 話が basis 不満がいっぱいなので、感情的になっていますし、自分は恋人が自分の思う通りに動いて当然だと思っているので reslut 話が噛み合いません ので 16 B\n",
      "Before subj 話が basis 不満がいっぱいなので reslut 感情的になっていますし、自分は恋人が自分の思う通りに動いて当然だと思っているので、話が噛み合いません なので 17 B\n",
      "Before subj 話が basis 不満がいっぱい reslut 感情的になっていますし、自分は恋人が自分の思う通りに動いて当然だと思っているので、話が噛み合いません なので、 18 B\n",
      "Before subj 話が basis 不満がいっぱい reslut 感情的になっていますし、自分は恋人が自分の思う通りに動いて当然だと思っているので、話が噛み合いません なので、 78 B\n",
      "Before subj 話が basis 不満がいっぱいなので reslut 感情的になっていますし、自分は恋人が自分の思う通りに動いて当然だと思っているので、話が噛み合いません なので 80 B\n",
      "Before subj 喧嘩ばかりのカップルに basis お互いの価値観のすれ違いから、喧嘩ばかりのカップルになってしまうのです reslut  ので 12 B\n",
      "Before subj 喧嘩ばかりのカップルに basis お互いの価値観のすれ違いから、喧嘩ばかりのカップルになってしまうのです reslut  ので 16 B\n",
      "Before subj 喧嘩ばかりのカップルに basis お互いの価値観のすれ違い reslut 喧嘩ばかりのカップルになってしまうのです から、 60 B\n",
      "Before subj 喧嘩ばかりのカップルに basis お互いの価値観のすれ違いから reslut 喧嘩ばかりのカップルになってしまうのです から 61 B\n",
      "Before subj 喧嘩ばかりの恋人と仲直りする方法を basis 恋人と仲直りする方法とはカップルになってしまう原因や理由がわかったところ reslut 喧嘩ばかりの恋人と仲直りする方法は、どのようなものがあるのでしょうかここでは、喧嘩ばかりの恋人と仲直りする方法をご紹介します で、 10 B\n",
      "Before subj 喧嘩ばかりの恋人と仲直りする方法を basis 恋人と仲直りする方法とはカップルになってしまう原因や理由がわかったところで、恋人と仲直りする方法は、どのようなものがあるのでしょうかここでは reslut 喧嘩ばかりの恋人と仲直りする方法をご紹介します ので 12 B\n",
      "Before subj 喧嘩ばかりの恋人と仲直りする方法を basis 恋人と仲直りする方法とはカップルになってしまう原因や理由がわかったところで、恋人と仲直りする方法は、どのようなものがあるのでしょうかここでは reslut 喧嘩ばかりの恋人と仲直りする方法をご紹介します ので 16 B\n",
      "Before subj 謝罪の気持ちが basis 目を見て、反省している姿を見せることがきるの reslut 謝罪の気持ちが伝わります で、 10 B\n",
      "Before subj 謝罪の気持ちが basis 目を見て、反省している姿を見せることがきる reslut 謝罪の気持ちが伝わります ので、 11 B\n",
      "Before subj 謝罪の気持ちが basis 目を見て、反省している姿を見せることがきるので reslut 謝罪の気持ちが伝わります ので 12 B\n",
      "Before subj 謝罪の気持ちが basis 目を見て、反省している姿を見せることがきる reslut 謝罪の気持ちが伝わります ので、 15 B\n",
      "Before subj 謝罪の気持ちが basis 目を見て、反省している姿を見せることがきるので reslut 謝罪の気持ちが伝わります ので 16 B\n",
      "Before subj この方法を取るのが一番と basis ときに日頃の感謝の気持ちなどを伝えると、よりぐっとお互いの距離が近くなるの reslut この方法を取るのが一番といえます で、 10 B\n",
      "Before subj この方法を取るのが一番と basis ときに日頃の感謝の気持ちなどを伝えると、よりぐっとお互いの距離が近くなる reslut この方法を取るのが一番といえます ので、 11 B\n",
      "Before subj この方法を取るのが一番と basis ときに日頃の感謝の気持ちなどを伝えると、よりぐっとお互いの距離が近くなるので reslut この方法を取るのが一番といえます ので 12 B\n",
      "Before subj この方法を取るのが一番と basis ときに日頃の感謝の気持ちなどを伝えると、よりぐっとお互いの距離が近くなる reslut この方法を取るのが一番といえます ので、 15 B\n",
      "Before subj この方法を取るのが一番と basis ときに日頃の感謝の気持ちなどを伝えると、よりぐっとお互いの距離が近くなるので reslut この方法を取るのが一番といえます ので 16 B\n",
      "Before subj はっきりと basis 今回の喧嘩の内容を話し合うこと reslut どこが悪かったのか、次から気を付けることはなんなのか、原因や理由がはっきりとします で、 10 B\n",
      "Before subj はっきりと basis 今回の喧嘩の内容を話し合うことで、どこが悪かったのか、次 reslut 気を付けることはなんなのか、原因や理由がはっきりとします から 61 B\n",
      "Before subj はっきりと basis 今回の喧嘩の内容を話し合う reslut どこが悪かったのか、次から気を付けることはなんなのか、原因や理由がはっきりとします ことで 86 B\n",
      "Before subj  basis 冷静に話し合う状況を作ること reslut 喧嘩別れを防ぐこともできますので、別れたくないカップルは必ず取ったほうがいい方法です で、 10 A\n",
      "Before subj  basis 冷静に話し合う状況を作ることで、喧嘩別れを防ぐこともきますの reslut 別れたくないカップルは必ず取ったほうがいい方法です で、 10 A\n",
      "Before subj  basis 冷静に話し合う状況を作ることで、喧嘩別れを防ぐこともきます reslut 別れたくないカップルは必ず取ったほうがいい方法です ので、 11 A\n",
      "Before subj  basis 冷静に話し合う状況を作ることで、喧嘩別れを防ぐこともきますので reslut 別れたくないカップルは必ず取ったほうがいい方法です ので 12 A\n",
      "Before subj  basis 冷静に話し合う状況を作ることで、喧嘩別れを防ぐこともきます reslut 別れたくないカップルは必ず取ったほうがいい方法です ので、 15 A\n",
      "Before subj  basis 冷静に話し合う状況を作ることで、喧嘩別れを防ぐこともきますので reslut 別れたくないカップルは必ず取ったほうがいい方法です ので 16 A\n",
      "Before subj  basis 冷静に話し合う状況を作る reslut 喧嘩別れを防ぐこともできますので、別れたくないカップルは必ず取ったほうがいい方法です ことで 86 A\n",
      "Before subj  basis 電話で謝る喧嘩の熱をお互いが距離を取ること reslut 冷ます効果が期待できる方法です で、 10 A\n",
      "Before subj  basis 電話で謝る喧嘩の熱をお互いが距離を取る reslut 冷ます効果が期待できる方法です ことで 86 A\n",
      "Before subj そんなときに、 basis ときに、手紙や電話であれば顔を見ることはないの reslut 感情を落ち着かせながら謝罪や話し合いができ仲直りできます で、 10 B\n",
      "Before subj そんなときに、 basis ときに、手紙や電話であれば顔を見ることはない reslut 感情を落ち着かせながら謝罪や話し合いができ仲直りできます ので、 11 B\n",
      "Before subj そんなときに、 basis ときに、手紙や電話であれば顔を見ることはないので reslut 感情を落ち着かせながら謝罪や話し合いができ仲直りできます ので 12 B\n",
      "Before subj そんなときに、 basis ときに、手紙や電話であれば顔を見ることはない reslut 感情を落ち着かせながら謝罪や話し合いができ仲直りできます ので、 15 B\n",
      "Before subj そんなときに、 basis ときに、手紙や電話であれば顔を見ることはないので reslut 感情を落ち着かせながら謝罪や話し合いができ仲直りできます ので 16 B\n",
      "Before subj  basis 入れて会う喧嘩ばかりのカップルに多いのは、喧嘩別れや言い争いになってしまうす reslut  ことで 86 A\n",
      "Before subj  basis その時にお互いの価値観を擦り合わせること reslut 第三者が証人となり、なくなります で、 10 A\n",
      "Before subj  basis その時にお互いの価値観を擦り合わせる reslut 第三者が証人となり、なくなります ことで 86 A\n",
      "Before subj  basis してしまうとずっと嫌喧嘩の多いカップルの喧嘩の内容では、喧嘩の多いカップルの喧嘩の内容はどのようなものでしょうか reslut  ので 12 A\n",
      "Before subj  basis してしまうとずっと嫌喧嘩の多いカップルの喧嘩の内容では、喧嘩の多いカップルの喧嘩の内容はどのようなものでしょうか reslut  ので 16 A\n",
      "Before subj 喧嘩の多いカップルの喧嘩の原因や理由ではなく、どのような喧嘩をするのかを basis 喧嘩の多いカップルの喧嘩の原因やはなく reslut どのような喧嘩をするのかを考えていきます 理由で 45 B\n",
      "Before subj  basis 任せて言葉を発するの reslut 言ってしまいます で、 10 A\n",
      "Before subj  basis 任せて言葉を発する reslut 言ってしまいます ので、 11 A\n",
      "Before subj  basis 任せて言葉を発するので reslut 言ってしまいます ので 12 A\n",
      "Before subj  basis 任せて言葉を発する reslut 言ってしまいます ので、 15 A\n",
      "Before subj  basis 任せて言葉を発するので reslut 言ってしまいます ので 16 A\n",
      "Before subj  basis 多いです状態な reslut  ので 12 A\n",
      "Before subj  basis 多いです状態 reslut  なので 13 A\n",
      "Before subj  basis 多いです状態な reslut  ので 16 A\n",
      "Before subj  basis 多いです状態 reslut  なので 17 A\n",
      "Before subj  basis 多いです状態 reslut  なので 80 A\n",
      "Before subj 注意が basis 喧嘩が多いカップルは、dvや依存系のカップルになりやすいの reslut 注意が必要です で、 10 B\n",
      "Before subj 注意が basis 喧嘩が多いカップルは、dvや依存系のカップルになりやすい reslut 注意が必要です ので、 11 B\n",
      "Before subj 注意が basis 喧嘩が多いカップルは、dvや依存系のカップルになりやすいので reslut 注意が必要です ので 12 B\n",
      "Before subj 注意が basis 喧嘩が多いカップルは、dvや依存系のカップルになりやすい reslut 注意が必要です ので、 15 B\n",
      "Before subj 注意が basis 喧嘩が多いカップルは、dvや依存系のカップルになりやすいので reslut 注意が必要です ので 16 B\n",
      "Before subj どんどん重く酷い喧嘩に basis 為、喧嘩が再発しやすく、また謝った側はストレスを溜めるだけなの reslut どんどん重く酷い喧嘩になりやすくなります で、 10 B\n",
      "Before subj どんどん重く酷い喧嘩に basis 為、喧嘩が再発しやすく、また謝った側はストレスを溜めるだけな reslut どんどん重く酷い喧嘩になりやすくなります ので、 11 B\n",
      "Before subj どんどん重く酷い喧嘩に basis 為、喧嘩が再発しやすく、また謝った側はストレスを溜めるだけなので reslut どんどん重く酷い喧嘩になりやすくなります ので 12 B\n",
      "Before subj どんどん重く酷い喧嘩に basis 為、喧嘩が再発しやすく、また謝った側はストレスを溜めるだけなので reslut どんどん重く酷い喧嘩になりやすくなります なので 13 B\n",
      "Before subj どんどん重く酷い喧嘩に basis 為、喧嘩が再発しやすく、また謝った側はストレスを溜めるだけ reslut どんどん重く酷い喧嘩になりやすくなります なので、 14 B\n",
      "Before subj どんどん重く酷い喧嘩に basis 為、喧嘩が再発しやすく、また謝った側はストレスを溜めるだけな reslut どんどん重く酷い喧嘩になりやすくなります ので、 15 B\n",
      "Before subj どんどん重く酷い喧嘩に basis 為、喧嘩が再発しやすく、また謝った側はストレスを溜めるだけなので reslut どんどん重く酷い喧嘩になりやすくなります ので 16 B\n",
      "Before subj どんどん重く酷い喧嘩に basis 為、喧嘩が再発しやすく、また謝った側はストレスを溜めるだけなので reslut どんどん重く酷い喧嘩になりやすくなります なので 17 B\n",
      "Before subj どんどん重く酷い喧嘩に basis 為、喧嘩が再発しやすく、また謝った側はストレスを溜めるだけ reslut どんどん重く酷い喧嘩になりやすくなります なので、 18 B\n",
      "Before subj どんどん重く酷い喧嘩に basis 為、喧嘩が再発しやすく、また謝った側はストレスを溜めるだけ reslut どんどん重く酷い喧嘩になりやすくなります なので、 78 B\n",
      "Before subj どんどん重く酷い喧嘩に basis 為、喧嘩が再発しやすく、また謝った側はストレスを溜めるだけなので reslut どんどん重く酷い喧嘩になりやすくなります なので 80 B\n",
      "Before subj 喧嘩が多いカップルに basis その試行錯誤が見つからない為に、喧嘩が多いカップルになってしまうのです reslut  ので 12 B\n",
      "Before subj 喧嘩が多いカップルに basis その試行錯誤が見つからない為に、喧嘩が多いカップルになってしまうのです reslut  ので 16 B\n",
      "Before subj 喧嘩が多いカップルに basis その試行錯誤が見つからない reslut 為に、喧嘩が多いカップルになってしまうのです から 61 B\n",
      "Before subj  basis 長続きする秘訣や特徴13選恋人と長続きさせたい付き合うのであれば reslut 長続きしたいと思うのは当たり前ですよね ので 12 A\n",
      "Before subj  basis 長続きする秘訣や特徴13選恋人と長続きさせたい付き合うのであれば reslut 長続きしたいと思うのは当たり前ですよね ので 16 A\n",
      "Before subj 仲直りが basis 記事では、カップルが長続きす素直にごめんが言える喧嘩例え激しい喧嘩になっても長続きするカップルは、素直にごめんとあやまることができ、仲直りが早いのです reslut  ので 12 B\n",
      "Before subj 仲直りが basis 記事では、カップルが長続きす素直にごめんが言える喧嘩例え激しい喧嘩になっても長続きするカップルは、素直にごめんとあやまることができ、仲直りが早いのです reslut  ので 16 B\n",
      "Before subj そういう素直さから、長続きするカップルに basis 素直さから、長続きするカップルになれるのです reslut  ので 12 B\n",
      "Before subj そういう素直さから、長続きするカップルに basis 素直さから、長続きするカップルになれるのです reslut  ので 16 B\n",
      "Before subj そういう素直さから、長続きするカップルに basis 素直さ reslut 長続きするカップルになれるのです から、 60 B\n",
      "Before subj そういう素直さから、長続きするカップルに basis 素直さから reslut 長続きするカップルになれるのです から 61 B\n",
      "Before subj  basis 為、同じことで喧嘩が起きることはなく、絆が強くなるような喧嘩をして長続きするのです reslut  ので 12 A\n",
      "Before subj  basis 為、同じことで喧嘩が起きることはなく、絆が強くなるような喧嘩をして長続きするのです reslut  ので 16 A\n",
      "Before subj  basis 為、同じ reslut 喧嘩が起きることはなく、絆が強くなるような喧嘩をして長続きするのです ことで 86 A\n",
      "Before subj  basis 為、乱暴な言葉などを使わないので拗れず、恋人が自分を想ってくれる気持ちも伝わっているの reslut 早く仲直りします で、 10 A\n",
      "Before subj  basis 為、乱暴な言葉などを使わないので拗れず、恋人が自分を想ってくれる気持ちも伝わっている reslut 早く仲直りします ので、 11 A\n",
      "Before subj  basis 為、乱暴な言葉などを使わない reslut 拗れず、恋人が自分を想ってくれる気持ちも伝わっているので、早く仲直りします ので 12 A\n",
      "Before subj  basis 為、乱暴な言葉などを使わないので拗れず、恋人が自分を想ってくれる気持ちも伝わっているので reslut 早く仲直りします ので 12 A\n",
      "Before subj  basis 為、乱暴な言葉などを使わないので拗れず、恋人が自分を想ってくれる気持ちも伝わっている reslut 早く仲直りします ので、 15 A\n",
      "Before subj  basis 為、乱暴な言葉などを使わない reslut 拗れず、恋人が自分を想ってくれる気持ちも伝わっているので、早く仲直りします ので 16 A\n",
      "Before subj  basis 為、乱暴な言葉などを使わないので拗れず、恋人が自分を想ってくれる気持ちも伝わっているので reslut 早く仲直りします ので 16 A\n",
      "Before subj 作ったほうが basis お互いの頭が冷えていない状態で謝ったり、話し合いをすると喧嘩が泥沼化する危険性があるの reslut 頭を冷やす時間だけは作ったほうがいいでしょう で、 10 B\n",
      "Before subj 作ったほうが basis お互いの頭が冷えていない状態で謝ったり、話し合いをすると喧嘩が泥沼化する危険性がある reslut 頭を冷やす時間だけは作ったほうがいいでしょう ので、 11 B\n",
      "Before subj 作ったほうが basis お互いの頭が冷えていない状態で謝ったり、話し合いをすると喧嘩が泥沼化する危険性があるので reslut 頭を冷やす時間だけは作ったほうがいいでしょう ので 12 B\n",
      "Before subj 作ったほうが basis お互いの頭が冷えていない状態で謝ったり、話し合いをすると喧嘩が泥沼化する危険性がある reslut 頭を冷やす時間だけは作ったほうがいいでしょう ので、 15 B\n",
      "Before subj 作ったほうが basis お互いの頭が冷えていない状態で謝ったり、話し合いをすると喧嘩が泥沼化する危険性があるので reslut 頭を冷やす時間だけは作ったほうがいいでしょう ので 16 B\n",
      "Before subj 勝手に会いに行ったり、会わなかったりせず、約束を作ることで仲直りしたいという意思表示が basis 会いに行ったり、会わなかったりせず、約束を作る reslut 仲直りしたいという意思表示ができます ことで 86 B\n",
      "Before subj 仲直りできる雰囲気を basis 直接会って言葉を交わすこと reslut 仲直りできる雰囲気を作れるのです で、 10 B\n",
      "Before subj 仲直りできる雰囲気を basis 直接会って言葉を交わすことで、仲直りできる雰囲気を作れるのです reslut  ので 12 B\n",
      "Before subj 仲直りできる雰囲気を basis 直接会って言葉を交わすことで、仲直りできる雰囲気を作れるのです reslut  ので 16 B\n",
      "Before subj 仲直りできる雰囲気を basis 直接会って言葉を交わす reslut 仲直りできる雰囲気を作れるのです ことで 86 B\n",
      "Before subj 会う約束を basis 頑なに会ってくれなかったり、そもそも連絡が出来ない状態の場合は、少し時間を空けて落ち着いて reslut 会う約束をしましょう から、 60 B\n",
      "Before subj 会う約束を basis 頑なに会ってくれなかったり、そもそも連絡が出来ない状態の場合は、少し時間を空けて落ち着いてから reslut 会う約束をしましょう から 61 B\n",
      "Before subj  basis 為、早く仲直りをしたいのであれば reslut 決して泣いてはいけません ので 12 A\n",
      "Before subj  basis 為、早く仲直りをしたいのであれば reslut 決して泣いてはいけません ので 16 A\n",
      "Before subj 悪い立場に basis ことで恋人を悪い立場にしてしまうからです reslut  から 61 B\n",
      "Before subj 悪い立場に basis  reslut 恋人を悪い立場にしてしまうからです ことで 86 B\n",
      "Before subj 喧嘩したときに basis いった理由から、喧嘩したときに決して泣いてはいけないのです reslut  ので 12 B\n",
      "Before subj 喧嘩したときに basis いった理由から、喧嘩したときに決して泣いてはいけないのです reslut  ので 16 B\n",
      "Before subj 喧嘩したときに basis いった理由 reslut 喧嘩したときに決して泣いてはいけないのです から、 60 B\n",
      "Before subj 喧嘩したときに basis いった理由から reslut 喧嘩したときに決して泣いてはいけないのです から 61 B\n",
      "Before subj そんなスタンプを送られてきた恋人は、ふざけてんのと basis スタンプを送られてきた恋人は、ふざけてんのと更にヒートアップしてしまうからです reslut  から 61 B\n",
      "Before subj 恋人を basis 長文でlineを送ったところ reslut 読まなければいいですし、そもそもlineで済まそうとしてくる精神が恋人をヒートアップさせてしまいます で、 10 B\n",
      "Before subj  basis 為、lineで謝るのは最悪な手段となるの reslut 絶対にしてはいけません で、 10 A\n",
      "Before subj  basis 為、lineで謝るのは最悪な手段となる reslut 絶対にしてはいけません ので、 11 A\n",
      "Before subj  basis 為、lineで謝るのは最悪な手段となるので reslut 絶対にしてはいけません ので 12 A\n",
      "Before subj  basis 為、lineで謝るのは最悪な手段となる reslut 絶対にしてはいけません ので、 15 A\n",
      "Before subj  basis 為、lineで謝るのは最悪な手段となるので reslut 絶対にしてはいけません ので 16 A\n",
      "Before subj 長続きするカップルに basis 喧嘩の再発防止にもなりますの reslut 改善点を伝えるようにすると仲直りしやすく、長続きするカップルになれます で、 10 B\n",
      "Before subj 長続きするカップルに basis 喧嘩の再発防止にもなります reslut 改善点を伝えるようにすると仲直りしやすく、長続きするカップルになれます ので、 11 B\n",
      "Before subj 長続きするカップルに basis 喧嘩の再発防止にもなりますので reslut 改善点を伝えるようにすると仲直りしやすく、長続きするカップルになれます ので 12 B\n",
      "Before subj 長続きするカップルに basis 喧嘩の再発防止にもなります reslut 改善点を伝えるようにすると仲直りしやすく、長続きするカップルになれます ので、 15 B\n",
      "Before subj 長続きするカップルに basis 喧嘩の再発防止にもなりますので reslut 改善点を伝えるようにすると仲直りしやすく、長続きするカップルになれます ので 16 B\n",
      "Before subj 喧嘩ばかりのカップルが気を付けたい事を basis カップルが気をつけたい事仲直りの方法もわかったところ reslut そもそも喧嘩をしないようにするには、どうしたらいいのでしょうかここでは、喧嘩ばかりのカップルが気を付けたい事をご紹介します で、 10 B\n",
      "Before subj 喧嘩ばかりのカップルが気を付けたい事を basis カップルが気をつけたい事仲直りの方法もわかったところで、そもそも喧嘩をしないようにするには、どうしたらいいのでしょうかここでは reslut 喧嘩ばかりのカップルが気を付けたい事をご紹介します ので 12 B\n",
      "Before subj 喧嘩ばかりのカップルが気を付けたい事を basis カップルが気をつけたい事仲直りの方法もわかったところで、そもそも喧嘩をしないようにするには、どうしたらいいのでしょうかここでは reslut 喧嘩ばかりのカップルが気を付けたい事をご紹介します ので 16 B\n",
      "Before subj 喧嘩別れするような内容の喧嘩が減り、長続きするカップルに basis すること reslut 喧嘩別れするような内容の喧嘩が減り、長続きするカップルになれるのです で、 10 B\n",
      "Before subj 喧嘩別れするような内容の喧嘩が減り、長続きするカップルに basis することで、喧嘩別れするような内容の喧嘩が減り、長続きするカップルになれるのです reslut  ので 12 B\n",
      "Before subj 喧嘩別れするような内容の喧嘩が減り、長続きするカップルに basis することで、喧嘩別れするような内容の喧嘩が減り、長続きするカップルになれるのです reslut  ので 16 B\n",
      "Before subj 喧嘩別れするような内容の喧嘩が減り、長続きするカップルに basis する reslut 喧嘩別れするような内容の喧嘩が減り、長続きするカップルになれるのです ことで 86 B\n",
      "Before subj  basis 言葉を使わない気を許している恋人だからと reslut いって、汚い言葉を使って傷つけるのはやめましょう から 61 A\n",
      "Before subj  basis 言葉を使わない気を許している恋人だからと reslut いって、汚い言葉を使って傷つけるのはやめましょう だから 81 A\n",
      "Before subj  basis 言葉 reslut  から、 60 A\n",
      "Before subj  basis 言葉から reslut  から 61 A\n",
      "Before subj 長続きしてお互いを想いあうカップルに basis 気持ちをきちんと考えて、言葉を発するようにすると、長続きしてお互いを想いあうカップルになれるのです reslut  ので 12 B\n",
      "Before subj 長続きしてお互いを想いあうカップルに basis 気持ちをきちんと考えて、言葉を発するようにすると、長続きしてお互いを想いあうカップルになれるのです reslut  ので 16 B\n",
      "Before subj 早急に直すことを basis 為、もし物に当たる癖などがあるのであれば reslut 早急に直すことをおすすめします ので 12 B\n",
      "Before subj 早急に直すことを basis 為、もし物に当たる癖などがあるのであれば reslut 早急に直すことをおすすめします ので 16 B\n",
      "Before subj  basis 当たることなどは、恋人に負担がかかる行為なの reslut 恋人を想うのであれば、やめられるはずです で、 10 A\n",
      "Before subj  basis 当たることなどは、恋人に負担がかかる行為な reslut 恋人を想うのであれば、やめられるはずです ので、 11 A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before subj  basis 当たることなどは、恋人に負担がかかる行為なので reslut 恋人を想うのであれば、やめられるはずです ので 12 A\n",
      "Before subj  basis 当たることなどは、恋人に負担がかかる行為なので、恋人を想うのであれば reslut やめられるはずです ので 12 A\n",
      "Before subj  basis 当たることなどは、恋人に負担がかかる行為なので reslut 恋人を想うのであれば、やめられるはずです なので 13 A\n",
      "Before subj  basis 当たることなどは、恋人に負担がかかる行為 reslut 恋人を想うのであれば、やめられるはずです なので、 14 A\n",
      "Before subj  basis 当たることなどは、恋人に負担がかかる行為な reslut 恋人を想うのであれば、やめられるはずです ので、 15 A\n",
      "Before subj  basis 当たることなどは、恋人に負担がかかる行為なので reslut 恋人を想うのであれば、やめられるはずです ので 16 A\n",
      "Before subj  basis 当たることなどは、恋人に負担がかかる行為なので、恋人を想うのであれば reslut やめられるはずです ので 16 A\n",
      "Before subj  basis 当たることなどは、恋人に負担がかかる行為なので reslut 恋人を想うのであれば、やめられるはずです なので 17 A\n",
      "Before subj  basis 当たることなどは、恋人に負担がかかる行為 reslut 恋人を想うのであれば、やめられるはずです なので、 18 A\n",
      "Before subj  basis 当たることなどは、恋人に負担がかかる行為 reslut 恋人を想うのであれば、やめられるはずです なので、 78 A\n",
      "Before subj  basis 当たることなどは、恋人に負担がかかる行為なので reslut 恋人を想うのであれば、やめられるはずです なので 80 A\n",
      "Before subj スルーできる広い心を持ったほうが、 basis ことなどであればまあいいかくらいの気持ち reslut スルーできる広い心を持ったほうが、お互いストレスなく過ごせます で、 10 B\n",
      "Before subj 恋人の行動に対してのストレスが多いと、別れる原因にもなってしまいますので、恋人との価値観を合わせられるくらい広い心を持つように心がけるのが basis 行動に対してのストレスが多いと、別れる原因にもなってしまいますの reslut 恋人との価値観を合わせられるくらい広い心を持つように心がけるのがいいでしょう で、 10 B\n",
      "Before subj 恋人の行動に対してのストレスが多いと、別れる原因にもなってしまいますので、恋人との価値観を合わせられるくらい広い心を持つように心がけるのが basis 行動に対してのストレスが多いと、別れる原因にもなってしまいます reslut 恋人との価値観を合わせられるくらい広い心を持つように心がけるのがいいでしょう ので、 11 B\n",
      "Before subj 恋人の行動に対してのストレスが多いと、別れる原因にもなってしまいますので、恋人との価値観を合わせられるくらい広い心を持つように心がけるのが basis 行動に対してのストレスが多いと、別れる原因にもなってしまいますので reslut 恋人との価値観を合わせられるくらい広い心を持つように心がけるのがいいでしょう ので 12 B\n",
      "Before subj 恋人の行動に対してのストレスが多いと、別れる原因にもなってしまいますので、恋人との価値観を合わせられるくらい広い心を持つように心がけるのが basis 行動に対してのストレスが多いと、別れる原因にもなってしまいます reslut 恋人との価値観を合わせられるくらい広い心を持つように心がけるのがいいでしょう ので、 15 B\n",
      "Before subj 恋人の行動に対してのストレスが多いと、別れる原因にもなってしまいますので、恋人との価値観を合わせられるくらい広い心を持つように心がけるのが basis 行動に対してのストレスが多いと、別れる原因にもなってしまいますので reslut 恋人との価値観を合わせられるくらい広い心を持つように心がけるのがいいでしょう ので 16 B\n",
      "Before subj 対処方法などを basis カップルを卒業する方法ここま reslut 喧嘩の内容についてや、対処方法などを考えてきました で、 10 B\n",
      "Before subj その方法を basis そもそも喧嘩をしないカップルになる為には、どういうことをするといいのでしょうかここ reslut その方法を考えていきます ので 12 B\n",
      "Before subj その方法を basis そもそも喧嘩をしないカップルになる為には、どういうことをするといいのでしょうかここ reslut その方法を考えていきます ので 16 B\n",
      "Before subj 深呼吸をすることで、頭を冷やし本当に怒ることなのかを basis すること reslut 頭を冷やし本当に怒ることなのかを考えられるようになります で、 10 B\n",
      "Before subj 深呼吸をすることで、頭を冷やし本当に怒ることなのかを basis する reslut 頭を冷やし本当に怒ることなのかを考えられるようになります ことで 86 B\n",
      "Before subj  basis 一息つく reslut 気持ちが落ち着き、感情的に怒るようなことにはならず、冷静に話し合いができる良い方法です ことで 86 A\n",
      "Before subj 効果的な方法と basis 長続きするカップルの中にも、実践しているカップルがいるそうなの reslut 効果的な方法と言えます で、 10 B\n",
      "Before subj 効果的な方法と basis 長続きするカップルの中にも、実践しているカップルがいるそうな reslut 効果的な方法と言えます ので、 11 B\n",
      "Before subj 効果的な方法と basis 長続きするカップルの中にも、実践しているカップルがいるそうなので reslut 効果的な方法と言えます ので 12 B\n",
      "Before subj 効果的な方法と basis 長続きするカップルの中にも、実践しているカップルがいるそうなので reslut 効果的な方法と言えます なので 13 B\n",
      "Before subj 効果的な方法と basis 長続きするカップルの中にも、実践しているカップルがいるそう reslut 効果的な方法と言えます なので、 14 B\n",
      "Before subj 効果的な方法と basis 長続きするカップルの中にも、実践しているカップルがいるそうな reslut 効果的な方法と言えます ので、 15 B\n",
      "Before subj 効果的な方法と basis 長続きするカップルの中にも、実践しているカップルがいるそうなので reslut 効果的な方法と言えます ので 16 B\n",
      "Before subj 効果的な方法と basis 長続きするカップルの中にも、実践しているカップルがいるそうなので reslut 効果的な方法と言えます なので 17 B\n",
      "Before subj 効果的な方法と basis 長続きするカップルの中にも、実践しているカップルがいるそう reslut 効果的な方法と言えます なので、 18 B\n",
      "Before subj 効果的な方法と basis 長続きするカップルの中にも、実践しているカップルがいるそう reslut 効果的な方法と言えます なので、 78 B\n",
      "Before subj 効果的な方法と basis 長続きするカップルの中にも、実践しているカップルがいるそうなので reslut 効果的な方法と言えます なので 80 B\n",
      "Before subj 恋人を別の人間だと認識して、お互いの価値観などを擦り合わせていくことが、 basis 別の人間だと認識して、お互いの価値観などを擦り合わせていくことが、長続きするカップルの秘訣なのです reslut  ので 12 B\n",
      "Before subj 恋人を別の人間だと認識して、お互いの価値観などを擦り合わせていくことが、 basis 別の人間だと認識して、お互いの価値観などを擦り合わせていくことが、長続きするカップルの秘訣なのです reslut  なので 13 B\n",
      "Before subj 恋人を別の人間だと認識して、お互いの価値観などを擦り合わせていくことが、 basis 別の人間だと認識して、お互いの価値観などを擦り合わせていくことが、長続きするカップルの秘訣なのです reslut  ので 16 B\n",
      "Before subj 恋人を別の人間だと認識して、お互いの価値観などを擦り合わせていくことが、 basis 別の人間だと認識して、お互いの価値観などを擦り合わせていくことが、長続きするカップルの秘訣なのです reslut  なので 17 B\n",
      "Before subj 恋人を別の人間だと認識して、お互いの価値観などを擦り合わせていくことが、 basis 別の人間だと認識して、お互いの価値観などを擦り合わせていくことが、長続きするカップルの秘訣なのです reslut  なので 80 B\n",
      "Before subj 原因を取り除けていない為に basis 同じ喧嘩を繰り返すカップルは、原因を取り除けていない為に繰り返すのです reslut  ので 12 B\n",
      "Before subj 原因を取り除けていない為に basis 同じ喧嘩を繰り返すカップルは、原因を取り除けていない為に繰り返すのです reslut  ので 16 B\n",
      "Before subj  basis きちんと話し合って、価値観や考えを擦り合わせ、仲良く長続きするカップルになれるように考えていくのです reslut  ので 12 A\n",
      "Before subj  basis きちんと話し合って、価値観や考えを擦り合わせ、仲良く長続きするカップルになれるように考えていくのです reslut  ので 16 A\n",
      "Before subj そうすることが、 basis することが、喧嘩を減らし長続きするカップルになれる近道なのです reslut  ので 12 B\n",
      "Before subj そうすることが、 basis することが、喧嘩を減らし長続きするカップルになれる近道なのです reslut  なので 13 B\n",
      "Before subj そうすることが、 basis することが、喧嘩を減らし長続きするカップルになれる近道なのです reslut  ので 16 B\n",
      "Before subj そうすることが、 basis することが、喧嘩を減らし長続きするカップルになれる近道なのです reslut  なので 17 B\n",
      "Before subj そうすることが、 basis することが、喧嘩を減らし長続きするカップルになれる近道なのです reslut  なので 80 B\n",
      "Before subj  basis 喧嘩ばかりしている reslut ダメなカップルということはありません から、 60 A\n",
      "Before subj  basis 喧嘩ばかりしているから reslut ダメなカップルということはありません から 61 A\n",
      "Before subj  basis しているからダメなカップルだと思っているのであれば reslut それは間違った考えです ので 12 A\n",
      "Before subj  basis しているからダメなカップルだと思っているのであれば reslut それは間違った考えです ので 16 A\n",
      "Before subj  basis している reslut ダメなカップルだと思っているのであれば、それは間違った考えです から 61 A\n",
      "Before subj 喧嘩をする度にお互いの考えや価値観がわかり、絆が深まることが basis する度にお互いの考えや価値観がわかり、絆が深まることがあるからです reslut  から 61 B\n",
      "Before subj 絆が深まり仲良く長続きするカップルに basis した後に、絆が深まり仲良く長続きするカップルになれていればいいのです reslut  ので 12 B\n",
      "Before subj 絆が深まり仲良く長続きするカップルに basis した後に、絆が深まり仲良く長続きするカップルになれていればいいのです reslut  ので 16 B\n",
      "Before subj  basis 対応すればいいのでしょうかやり方を reslut  ので 12 A\n",
      "Before subj  basis 対応すればいいのでしょうかやり方を reslut  ので 16 A\n",
      "Before subj 意見の不一致という明らかな理由が basis 本質なぜあんなに喧嘩が絶えないのでしょうか理由は reslut 意見の不一致という明らかな理由があります ので 12 B\n",
      "Before subj 意見の不一致という明らかな理由が basis 本質なぜあんなに喧嘩が絶えないのでしょうか理由は reslut 意見の不一致という明らかな理由があります ので 16 B\n",
      "Before subj 意見の不一致という明らかな理由が basis 本質なぜあんなに喧嘩が絶えないのでしょうか reslut 意見の不一致という明らかな理由があります 理由は 50 B\n",
      "Before subj それらが目指すところということはつまり、まだ備わっていないという basis 目指すところということはつまり、まだ備わっていないというすよね reslut  ことで 86 B\n",
      "Before subj それが違う意見であるということに basis 段々と友だちにも気持ちがあって、違う意見であるということに気づいていくのです reslut  ので 12 B\n",
      "Before subj それが違う意見であるということに basis 段々と友だちにも気持ちがあって、違う意見であるということに気づいていくのです reslut  ので 16 B\n",
      "Before subj  basis 子供同士が遊ぶわけです reslut 当然ぶつかるわけです から、 60 A\n",
      "Before subj  basis 子供同士が遊ぶわけですから reslut 当然ぶつかるわけです から 61 A\n",
      "Before subj  basis 間違ってはないのですが reslut これだけで本当に解決したといえるのか疑問です ので 12 A\n",
      "Before subj  basis 間違ってはないのですが reslut これだけで本当に解決したといえるのか疑問です ので 16 A\n",
      "Before subj 他には年上だから我慢しなさいという basis 年上だ reslut 我慢しなさいという方法です から 61 B\n",
      "Before subj 他には年上だから我慢しなさいという basis 年上 reslut 我慢しなさいという方法です だから 81 B\n",
      "Before subj  basis 全くそうではありません思えるのですが reslut  ので 12 A\n",
      "Before subj  basis 全くそうではありません思えるのですが reslut  ので 16 A\n",
      "Before subj  basis 大人 reslut そうではありません から 61 A\n",
      "Before subj  basis 全くそうではありません reslut  から 61 A\n",
      "Before subj 大人の力で無理やり喧嘩を終了させたことに basis 大人の力で無理やり喧嘩を終了させたことにすぎないのです reslut  ので 12 B\n",
      "Before subj 大人の力で無理やり喧嘩を終了させたことに basis 大人の力で無理やり喧嘩を終了させたことにすぎないのです reslut  ので 16 B\n",
      "Before subj 子供に basis 解決策をとってしまっていませんかどうやって解決するか子供に適切な喧嘩の解決方法とはどんなものなのでしょうか reslut  ので 12 B\n",
      "Before subj 子供に basis 解決策をとってしまっていませんかどうやって解決するか子供に適切な喧嘩の解決方法とはどんなものなのでしょうか reslut  なので 13 B\n",
      "Before subj 子供に basis 解決策をとってしまっていませんかどうやって解決するか子供に適切な喧嘩の解決方法とはどんなものなのでしょうか reslut  ので 16 B\n",
      "Before subj 子供に basis 解決策をとってしまっていませんかどうやって解決するか子供に適切な喧嘩の解決方法とはどんなものなのでしょうか reslut  なので 17 B\n",
      "Before subj 子供に basis 解決策をとってしまっていませんかどうやって解決するか子供に適切な喧嘩の解決方法とはどんなものなのでしょうか reslut  なので 80 B\n",
      "Before subj ポイントが basis その仲介方法にポイントがあるのです reslut  ので 12 B\n",
      "Before subj ポイントが basis その仲介方法にポイントがあるのです reslut  ので 16 B\n",
      "Before subj ここで重要なのが、 basis 重要なのが、a君b君別々に聞くす reslut  ことで 86 B\n",
      "Before subj 新しい状況が basis 行動をする reslut 新しい状況が見えてきたりします ことで 86 B\n",
      "Before subj  basis b君はそのおもちゃがほしかったんだね reslut 取っちゃったんだね だから 61 E\n",
      "Before subj  basis b君はそのおもちゃがほしかったんだね reslut 取っちゃったんだね だから 81 E\n",
      "Before subj 子供なりの解決策を basis 子供なりの解決策を導くのです reslut  ので 12 B\n",
      "Before subj 子供なりの解決策を basis 子供なりの解決策を導くのです reslut  ので 16 B\n",
      "Before subj 自分たちで basis 違う相手とぶつかりあいながら、友だちの思いに気づいたり喧嘩を経験する中で解決策を自分たちで導けるようになったりするのです reslut  ので 12 B\n",
      "Before subj 自分たちで basis 違う相手とぶつかりあいながら、友だちの思いに気づいたり喧嘩を経験する中で解決策を自分たちで導けるようになったりするのです reslut  ので 16 B\n",
      "Before subj  basis 全て止めてしまったり、ほったらかしになってしまっていては、育つちからも reslut  から 61 A\n",
      "Before subj 不毛な罵り合いに basis パートナーの逆鱗に触れる一言を言ってしまったようで、不毛な罵り合いに reslut  で、 10 B\n",
      "Before subj コップに basis 習得 reslut ケンカ知らずの円満カップルになろう些細なミスで怒り爆発アンガーマネジメントを何のために行い、どんな効果が期待できるのかを簡単に知ってもらうため、人間の心をコップに例えてみよう で、 10 B\n",
      "Before subj コップに basis 習得で、ケンカ知らずの円満カップルになろう些細なミスで怒り爆発アンガーマネジメントを何のために行い、どんな効果が期待できるのかを簡単に知ってもらう reslut 人間の心をコップに例えてみよう ため、 23 B\n",
      "Before subj コップに水が注がれていく状況の変化を basis 増幅によって reslut コップに水が注がれていく状況の変化をイメージしてほしい によって 65 B\n",
      "Before subj コップの水かさが basis ある日、仕事を終えようとすると、急に無理な残業を頼まれてイラっとしたこと reslut コップの水かさが少し増した で、 10 B\n",
      "Before subj コップの水かさが basis ある日、仕事を終えようとすると、急に無理な残業を頼まれてイラっとした reslut コップの水かさが少し増した ことで 86 B\n",
      "Before subj 足を basis 中、大音量でヘッドホンステレオを聴いている若者 reslut 足を強く踏まれた から 61 B\n",
      "Before subj  basis どうだと言葉にしたい気持ちを周囲の目もある reslut グッとこらえる ので 12 A\n",
      "Before subj  basis どうだと言葉にしたい気持ちを周囲の目もある reslut グッとこらえる ので 16 A\n",
      "Before subj 前夜からの3つの不愉快な出来事で、 basis 3つの不愉快な出来事 reslut 心のコップの水かさはもう満タンの状態である で、 10 B\n",
      "Before subj 前夜からの3つの不愉快な出来事で、 basis 前夜からの reslut 3つの不愉快な出来事で、心のコップの水かさはもう満タンの状態である から 61 B\n",
      "Before subj 水が basis 水が溢れ出したのである reslut  ので 12 B\n",
      "Before subj 水が basis 水が溢れ出したのである reslut  ので 16 B\n",
      "Before subj 水が basis コップ reslut 水が溢れ出したのである から 61 B\n",
      "Before subj  basis 部下 reslut 報告書を受けた際、前夜からの3つの不愉快な出来事を心の中に溜め込んでいなかったならば、あなたは部下を怒鳴りつけることはなかったかもしれない から 61 A\n",
      "Before subj  basis 報告書を受けた際、前夜からの reslut 3つの不愉快な出来事を心の中に溜め込んでいなかったならば、あなたは部下を怒鳴りつけることはなかったかもしれない から 61 A\n",
      "Before subj 他者に気分や機嫌で対応することが減り、他者を傷つけることが basis 体得すること reslut 他者に気分や機嫌で対応することが減り、他者を傷つけることが少なくなる で、 10 B\n",
      "Before subj 他者に気分や機嫌で対応することが減り、他者を傷つけることが basis 体得する reslut 他者に気分や機嫌で対応することが減り、他者を傷つけることが少なくなる ことで 86 B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before subj  basis 罵声が大きい reslut それにビックリしたのかなと思って悪いことをしちゃったと2人で反省してます今は猫も撫でれるくらい落ち着いてますが、また多分下手に動くと引っ掻かれそうな感じです ので 12 A\n",
      "Before subj  basis 罵声が大きい reslut それにビックリしたのかなと思って悪いことをしちゃったと2人で反省してます今は猫も撫でれるくらい落ち着いてますが、また多分下手に動くと引っ掻かれそうな感じです ので 16 A\n",
      "Before subj  basis 喧嘩に入ってくることはそういうこと時々すか reslut  ことで 86 A\n",
      "Before subj  basis 話せないだけ reslut かなりの感情や状況は読み取っているように思います で、 10 A\n",
      "Before subj この質問は投票によってベストアンサーに選ばれました前の方が言っる通りだと basis 質問は投票 reslut ベストアンサーに選ばれました前の方が言っる通りだと思います によって 65 B\n",
      "Before subj  basis 性格によってですが reslut 良い猫に喧嘩なんかするな仲良くしろと仲裁された事あります によって 65 A\n",
      "Before subj 飼い主さんの興奮してる波長が猫ちゃんに伝染したのかくだらん事でイチイチ喧嘩なんかしたらアカンやろ私が憎まれ役になってあげるから、もう喧嘩はお終いと言ったかどうかは定かではないですが猫も飼い主の気持ちを汲み取るので有り得ると basis 興奮してる波長が猫ちゃんに伝染したのかくだらん事でイチイチ喧嘩なんかしたらアカンやろ私が憎まれ役になってあげるから、もう喧嘩はお終いと言ったかどうかは定かではないですが猫も飼い主の気持ちを汲み取る reslut 有り得ると思います ので 12 B\n",
      "Before subj 飼い主さんの興奮してる波長が猫ちゃんに伝染したのかくだらん事でイチイチ喧嘩なんかしたらアカンやろ私が憎まれ役になってあげるから、もう喧嘩はお終いと言ったかどうかは定かではないですが猫も飼い主の気持ちを汲み取るので有り得ると basis 興奮してる波長が猫ちゃんに伝染したのかくだらん事でイチイチ喧嘩なんかしたらアカンやろ私が憎まれ役になってあげるから、もう喧嘩はお終いと言ったかどうかは定かではないですが猫も飼い主の気持ちを汲み取る reslut 有り得ると思います ので 16 B\n",
      "Before subj 飼い主さんの興奮してる波長が猫ちゃんに伝染したのかくだらん事でイチイチ喧嘩なんかしたらアカンやろ私が憎まれ役になってあげるから、もう喧嘩はお終いと言ったかどうかは定かではないですが猫も飼い主の気持ちを汲み取るので有り得ると basis 興奮してる波長が猫ちゃんに伝染したのかくだらん事でイチイチ喧嘩なんかしたらアカンやろ私が憎まれ役になってあげる reslut もう喧嘩はお終いと言ったかどうかは定かではないですが猫も飼い主の気持ちを汲み取るので有り得ると思います から、 60 B\n",
      "Before subj 飼い主さんの興奮してる波長が猫ちゃんに伝染したのかくだらん事でイチイチ喧嘩なんかしたらアカンやろ私が憎まれ役になってあげるから、もう喧嘩はお終いと言ったかどうかは定かではないですが猫も飼い主の気持ちを汲み取るので有り得ると basis 興奮してる波長が猫ちゃんに伝染したのかくだらん事でイチイチ喧嘩なんかしたらアカンやろ私が憎まれ役になってあげるから reslut もう喧嘩はお終いと言ったかどうかは定かではないですが猫も飼い主の気持ちを汲み取るので有り得ると思います から 61 B\n",
      "Before subj  basis 喧嘩するのか性別で喧嘩の多い組み合わせを統計的に考えれば、個体差などにより全部に当てはまるとは言い切れない reslut  により 66 A\n",
      "Before subj 相手を basis ときにきちんと犬社会のルールを学んでいなければ、他の犬と出会ったときにどうすればいいか分からない、そのため、緊張や不安から相手を威嚇してしまうのである reslut  ので 12 B\n",
      "Before subj 相手を basis ときにきちんと犬社会のルールを学んでいなければ、他の犬と出会ったときにどうすればいいか分からない、そのため、緊張や不安から相手を威嚇してしまうのである reslut  ので 16 B\n",
      "Before subj 相手を basis ときにきちんと犬社会のルールを学んでいなければ、他の犬と出会ったときにどうすればいいか分からない、その reslut 緊張や不安から相手を威嚇してしまうのである ため、 23 B\n",
      "Before subj 相手を basis ときにきちんと犬社会のルールを学んでいなければ、他の犬と出会ったときにどうすればいいか分からない reslut そのため、緊張や不安から相手を威嚇してしまうのである から 61 B\n",
      "Before subj 相手を basis ときにきちんと犬社会のルールを学んでいなければ、他の犬と出会ったときにどうすればいいか分からない、そのため、緊張や不安 reslut 相手を威嚇してしまうのである から 61 B\n",
      "Before subj そこで吠えたり、威嚇することから basis 吠えたり、威嚇すること reslut 喧嘩は始まってしまう から 61 B\n",
      "Before subj 愛犬の緊張が basis 向こう reslut 来た犬にうちの犬は吠えるんじゃないかと緊張すれば、飼い主の不安が愛犬にも伝わってしまい、より愛犬の緊張が伝わってしまうのだ から 61 B\n",
      "Before subj 無用な喧嘩を避けるために、 basis 喧嘩を避けるために、飼い主は愛犬の性質をよく理解しておきたいものである reslut  ので 12 B\n",
      "Before subj 無用な喧嘩を避けるために、 basis 喧嘩を避けるために、飼い主は愛犬の性質をよく理解しておきたいものである reslut  ので 16 B\n",
      "Before subj 日本犬が喧嘩を売られやすい理由姿勢のよさが誤解される柴犬を散歩させていると、他の犬からよく吠えられることが basis 喧嘩を売られやすい理由姿勢のよさが誤解される柴犬を散歩させていると、他の reslut よく吠えられることがある から 61 B\n",
      "Before subj  basis 巻き尾なのに、遠くから見れば威嚇で尾を立てているように勘違いされやすいのである reslut  ので 12 A\n",
      "Before subj  basis 巻き尾なのに、遠くから見れば威嚇で尾を立てているように勘違いされやすいのである reslut  ので 16 A\n",
      "Before subj  basis 巻き尾なのに、遠く reslut 見れば威嚇で尾を立てているように勘違いされやすいのである から 61 A\n",
      "Before subj  basis 姿勢が丸くなっている reslut 襲われないのだ ので 12 A\n",
      "Before subj  basis 姿勢が丸くなっている reslut 襲われないのだ ので 16 A\n",
      "Before subj 落ち着きなさいよ、というカーミングシグナルを相手に送っているのに、気づいてもらえないと、攻撃されるのではないかと、 basis カーミングシグナルを相手に送っているのに、気づいてもらえないと、攻撃されるのではないかと reslut ある ので 12 B\n",
      "Before subj 落ち着きなさいよ、というカーミングシグナルを相手に送っているのに、気づいてもらえないと、攻撃されるのではないかと、 basis カーミングシグナルを相手に送っているのに、気づいてもらえないと、攻撃されるのではないかと reslut ある ので 16 B\n",
      "Before subj それを basis 犬で飼われている場合、犬の中には群れ意識があるの reslut ランクがきちんと決まっているときには飼い主がそれを乱してはいけない で、 10 B\n",
      "Before subj それを basis 犬で飼われている場合、犬の中には群れ意識がある reslut ランクがきちんと決まっているときには飼い主がそれを乱してはいけない ので、 11 B\n",
      "Before subj それを basis 犬で飼われている場合、犬の中には群れ意識があるので reslut ランクがきちんと決まっているときには飼い主がそれを乱してはいけない ので 12 B\n",
      "Before subj それを basis 犬で飼われている場合、犬の中には群れ意識がある reslut ランクがきちんと決まっているときには飼い主がそれを乱してはいけない ので、 15 B\n",
      "Before subj それを basis 犬で飼われている場合、犬の中には群れ意識があるので reslut ランクがきちんと決まっているときには飼い主がそれを乱してはいけない ので 16 B\n",
      "Before subj  basis 行動が犬たちを争わせているのではないか reslut よく考えておきたいものである ので 12 A\n",
      "Before subj  basis 行動が犬たちを争わせているのではないか、よく考えておきたいものである reslut  ので 12 A\n",
      "Before subj  basis 行動が犬たちを争わせているのではないか reslut よく考えておきたいものである ので 16 A\n",
      "Before subj  basis 行動が犬たちを争わせているのではないか、よく考えておきたいものである reslut  ので 16 A\n",
      "Before subj 恐怖心や社会性の不足からくることが basis 際に向こう reslut 来た犬に喧嘩を売ってしまうのは、恐怖心や社会性の不足からくることが多い から 61 B\n",
      "Before subj 恐怖心や社会性の不足からくることが basis 際に向こうから来た犬に喧嘩を売ってしまうのは、恐怖心や社会性の不足 reslut くることが多い から 61 B\n",
      "Before subj  basis 自分の犬が吠えてしまうのではないかという reslut 飼い主の不安や緊張が伝わって、より愛犬の緊張を助長してしまう ので 12 A\n",
      "Before subj  basis 自分の犬が吠えてしまうのではないかという reslut 飼い主の不安や緊張が伝わって、より愛犬の緊張を助長してしまう ので 16 A\n",
      "Before subj  basis 喧嘩自分の犬や相手の状態 reslut 喧嘩になる によって 65 A\n",
      "Before subj  basis オス同士の犬の場合だと、犬は最初 reslut 喧嘩を売ろうと思っている から 61 A\n",
      "Before subj  basis 喧嘩と同じく、飼い主 reslut 考えられる から 61 A\n",
      "Before subj 優位だから上に行くのではなく弱いものが下に行くことで順列ができていると basis 上に行くのではなく reslut 弱いものが下に行くことで順列ができていると考えられている ので 12 B\n",
      "Before subj 優位だから上に行くのではなく弱いものが下に行くことで順列ができていると basis 上に行くのではなく reslut 弱いものが下に行くことで順列ができていると考えられている ので 16 B\n",
      "Before subj 優位だから上に行くのではなく弱いものが下に行くことで順列ができていると basis 優位だ reslut 上に行くのではなく弱いものが下に行くことで順列ができていると考えられている から 61 B\n",
      "Before subj 優位だから上に行くのではなく弱いものが下に行くことで順列ができていると basis 優位 reslut 上に行くのではなく弱いものが下に行くことで順列ができていると考えられている だから 81 B\n",
      "Before subj 優位だから上に行くのではなく弱いものが下に行くことで順列ができていると basis 上に行くのではなく弱いものが下に行く reslut 順列ができていると考えられている ことで 86 B\n",
      "Before subj  basis 犬 reslut アキレス腱 によって 65 A\n",
      "Before subj  basis 硬直は一瞬のあれば reslut ある ことで 86 A\n",
      "Before subj 喧嘩の見極めに basis うなり声を出さずに突然喧嘩へ発展することもあるの reslut 犬の表情と体の動きを良く見ておくことが、じゃれから喧嘩の見極めに役立つのだ で、 10 B\n",
      "Before subj 喧嘩の見極めに basis うなり声を出さずに突然喧嘩へ発展することもある reslut 犬の表情と体の動きを良く見ておくことが、じゃれから喧嘩の見極めに役立つのだ ので、 11 B\n",
      "Before subj 喧嘩の見極めに basis うなり声を出さずに突然喧嘩へ発展することもあるので reslut 犬の表情と体の動きを良く見ておくことが、じゃれから喧嘩の見極めに役立つのだ ので 12 B\n",
      "Before subj 喧嘩の見極めに basis うなり声を出さずに突然喧嘩へ発展することもある reslut 犬の表情と体の動きを良く見ておくことが、じゃれから喧嘩の見極めに役立つのだ ので、 15 B\n",
      "Before subj 喧嘩の見極めに basis うなり声を出さずに突然喧嘩へ発展することもあるので reslut 犬の表情と体の動きを良く見ておくことが、じゃれから喧嘩の見極めに役立つのだ ので 16 B\n",
      "Before subj 喧嘩の見極めに basis うなり声を出さずに突然喧嘩へ発展することもあるので、犬の表情と体の動きを良く見ておくことが、じゃれ reslut 喧嘩の見極めに役立つのだ から 61 B\n",
      "Before subj 用心することが basis 興奮しているときに無理矢理引き離そうと、下手に手を出すと人間が噛まれることがある reslut 用心することが必要だ ので 12 B\n",
      "Before subj 用心することが basis 興奮しているときに無理矢理引き離そうと、下手に手を出すと人間が噛まれることがある reslut 用心することが必要だ ので 16 B\n",
      "Before subj  basis どこ reslut 他の犬と喧嘩に発展する可能性があるかもしれないということを、飼い主はきちんと認識しておきたいものだ で、 10 A\n",
      "after subj 犬同士の無用な争いを basis 争う気がないことを示す reslut 犬同士の無用な争いを避けているのです ことで 86 B\n",
      "after subj  basis カーミングシグナルとは、犬特有のコミュニケーション reslut 犬が野生時代に群れで暮らしていた時から備わっていたものです で、 10 A\n",
      "after subj カップルが喧嘩する原因ランキングちょっとしたことがきっかけで、 basis 喧嘩する原因ランキングちょっとしたことがきっかけ reslut あるでしょう で、 10 B\n",
      "after subj 関係が basis 大切に思う気持ちが薄れてくる reslut 女性23歳学校教育関連専門職ある程度長く付き合っていると、自然と関係がマンネリ化してしまいがちです から 61 B\n",
      "after subj 仲直りできる雰囲気を basis 直接会って言葉を交わすこと reslut 仲直りできる雰囲気を作れるのです で、 10 B\n",
      "after subj  basis 任せて言葉を発する reslut 言ってしまいます ので、 11 A\n",
      "after subj 勝手に会いに行ったり、会わなかったりせず、約束を作ることで仲直りしたいという意思表示が basis 会いに行ったり、会わなかったりせず、約束を作る reslut 仲直りしたいという意思表示ができます ことで 86 B\n",
      "after subj  basis 当たることなどは、恋人に負担がかかる行為 reslut 恋人を想うのであれば、やめられるはずです なので、 78 A\n",
      "after subj  basis 言葉を使わない気を許している恋人だからと reslut いって、汚い言葉を使って傷つけるのはやめましょう だから 81 A\n",
      "after subj  basis 為、lineで謝るのは最悪な手段となる reslut 絶対にしてはいけません ので、 11 A\n",
      "after subj  basis 電話で謝る喧嘩の熱をお互いが距離を取る reslut 冷ます効果が期待できる方法です ことで 86 A\n",
      "after subj 不安な状態が basis sns上だけで病んでいるアピールをする reslut 恋人からすると何が不満なのと不安な状態が続きます ので、 11 B\n",
      "after subj 喧嘩に basis 過剰な嫉妬や束縛 reslut 恋人が不自由を感じ、怒って喧嘩になるのです で、 10 B\n",
      "after subj 喧嘩ばかりに basis 合わせようにも、お互いが引かない状態 reslut 価値観のすり合わせが出来ず喧嘩ばかりになってしまうのです なので、 78 B\n",
      "after subj 謝罪の気持ちが basis 目を見て、反省している姿を見せることがきる reslut 謝罪の気持ちが伝わります ので、 11 B\n",
      "after subj どんどん重く酷い喧嘩に basis 為、喧嘩が再発しやすく、また謝った側はストレスを溜めるだけ reslut どんどん重く酷い喧嘩になりやすくなります なので、 78 B\n",
      "after subj 前夜からの3つの不愉快な出来事で、 basis 3つの不愉快な出来事 reslut 心のコップの水かさはもう満タンの状態である で、 10 B\n",
      "after subj  basis 喧嘩自分の犬や相手の状態 reslut 喧嘩になる によって 65 A\n",
      "after subj 優位だから上に行くのではなく弱いものが下に行くことで順列ができていると basis 上に行くのではなく弱いものが下に行く reslut 順列ができていると考えられている ことで 86 B\n"
     ]
    }
   ],
   "source": [
    "repository = causalRepository()\n",
    "extractor =  extractor()\n",
    "crawlers = repository.syncCrawle(\"人間が喧嘩する理由\")\n",
    "causals, crawlers = extractor.extract(crawlers, Relation.cause)\n",
    "repository.setCausalData(causals, crawlers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossBootstrap:\n",
    "    \n",
    "    clueList = []\n",
    "    \n",
    "    eclueList = []\n",
    "    \n",
    "    gclueList = []\n",
    "    \n",
    "    geclueList = []\n",
    "    \n",
    "    eqclueList = []\n",
    "    \n",
    "    eqeclueList = []\n",
    "    \n",
    "    rclueList = []\n",
    "    \n",
    "    grclueList = []\n",
    "    \n",
    "    eqrclueList = []\n",
    "    \n",
    "    reclueList = []\n",
    "    \n",
    "    greclueList = []\n",
    "    \n",
    "    eqreclueList = []\n",
    "        \n",
    "    skipList = []\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.utilSet()\n",
    "\n",
    "    def utilSet(self):\n",
    "        \n",
    "        self.skipList = pd.read_csv(\"Util/ja_skip_list.csv\").dropna(subset=['clue'])['clue']\n",
    "        \n",
    "        self.clueList = pd.read_csv(\"Util/ja_clue_list.csv\").dropna(subset=['clue'])\n",
    "        self.eclueList = pd.read_csv(\"Util/ja_eclue_list.csv\").dropna(subset=['clue'])\n",
    "        self.gclueList = pd.read_csv(\"Util/ja_goal_clue_list.csv\").dropna(subset=['clue'])\n",
    "        self.geclueList = pd.read_csv(\"Util/ja_goal_eclue_list.csv\").dropna(subset=['clue'])\n",
    "        self.eqclueList = pd.read_csv(\"Util/ja_equal_clue_list.csv\").dropna(subset=['clue'])\n",
    "        self.eqeclueList = pd.read_csv(\"Util/ja_equal_eclue_list.csv\").dropna(subset=['clue'])\n",
    "        \n",
    "        self.rclueList = []\n",
    "        self.grclueList = []\n",
    "        self.eqrclueList = []\n",
    "#         self.rclueList = pd.read_csv(\"Util/ja_result_list.csv\").dropna(subset=['clue'])['clue']\n",
    "#         self.grclueList =pd.read_csv(\"Util/ja_skip_list.csv\").dropna(subset=['clue'])['clue']\n",
    "#         self.eqrclueList = pd.read_csv(\"Util/ja_skip_list.csv\").dropna(subset=['clue'])['clue']\n",
    "    \n",
    "    def checkResult(self, resultChunk):\n",
    "        pos = resultChunk[resultChunk.token_size - 1].pos\n",
    "        pos1 = resultChunk[resultChunk.token_size - 1].pos1\n",
    "        if pos == \"助詞\":\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "    def getEndResult(self, texts):\n",
    "        analyzer = CaboChaAnalyzer()\n",
    "        results = []\n",
    "        for text in texts:\n",
    "            tree = analyzer.parse(text)\n",
    "            lastChunk = tree[tree.chunk_size - 1]\n",
    "            if self.checkResult(lastChunk):\n",
    "                results.append(lastChunk)\n",
    "        return results\n",
    "            \n",
    "    def getResultFromCausal(self, causal):\n",
    "        results = []\n",
    "        if causal.pattern == Pattern.A or Pattern.B:\n",
    "            results = self.getEndResult(causal.sentence.split(causal.clue))\n",
    "        elif causal.pattern == Pattern.C:\n",
    "            results = self.getEndResult(causal.sentence.split(causal.clue))\n",
    "        elif causal.pattern == Pattern.D:\n",
    "            results = self.getEndResult(causal.sentence.split(causal.clue))\n",
    "        elif causal.pattern == Pattern.E:\n",
    "            results = self.getEndResult(causal.sentence.split(\"。\"))\n",
    "        return results\n",
    "    \n",
    "    def getClueFromSentence(self, sentence):\n",
    "        analyzer = CaboChaAnalyzer()\n",
    "        tree = analyzer.parse(sentence)\n",
    "        for result in self.rclueList:\n",
    "            if sentence.endswith(result):\n",
    "                pass # TODO: E pattern\n",
    "            elif str(result) in sentence:\n",
    "                matcher = sentence.split(result)[1]\n",
    "                return analyzer.parse(matcher)[0]\n",
    "            else:\n",
    "                return None\n",
    "    \n",
    "    def getResultExpression(self, causals):\n",
    "        results = []\n",
    "        results.extend([self.getResultFromCausal(causal) for causal in causals])\n",
    "        return results\n",
    "    \n",
    "    def getClueExpression(self, sentences):\n",
    "        clues =[]\n",
    "        clues.extend([self.getClueFromSentence(sentence) for sentence in sentences])\n",
    "        return clues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.drop(['ID', 'Label', 'Causal_Basis', 'Causal_Result', 'Causal_Clue', 'Causal_Sentence', 'CausalPattern'], axis=1)\n",
    "Y_train = data['Label']\n",
    "X_test = test.drop(['ID', 'Label', 'Causal_Basis', 'Causal_Result', 'Causal_Clue', 'Causal_Sentence', 'Pattern'], axis=1)\n",
    "Y_test = test['Label']\n",
    "X_pred = pred.drop(['ID', 'Causal_Basis', 'Causal_Result', 'Causal_Clue', 'Causal_Sentence', 'Causal_Pattern'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Basis</th>\n",
       "      <th>Result</th>\n",
       "      <th>Clue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>71.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.014085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.639767</td>\n",
       "      <td>0.471310</td>\n",
       "      <td>0.005185</td>\n",
       "      <td>0.005336</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007501</td>\n",
       "      <td>0.007253</td>\n",
       "      <td>0.013615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009797</td>\n",
       "      <td>0.010394</td>\n",
       "      <td>0.014085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012636</td>\n",
       "      <td>0.013323</td>\n",
       "      <td>0.014085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017421</td>\n",
       "      <td>0.016176</td>\n",
       "      <td>0.014085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030989</td>\n",
       "      <td>0.039756</td>\n",
       "      <td>0.016097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID      Label      Basis     Result       Clue\n",
       "count  71.000000  71.000000  71.000000  71.000000  71.000000\n",
       "mean   35.000000   0.676056   0.014085   0.014085   0.014085\n",
       "std    20.639767   0.471310   0.005185   0.005336   0.000335\n",
       "min     0.000000   0.000000   0.007501   0.007253   0.013615\n",
       "25%    17.500000   0.000000   0.009797   0.010394   0.014085\n",
       "50%    35.000000   1.000000   0.012636   0.013323   0.014085\n",
       "75%    52.500000   1.000000   0.017421   0.016176   0.014085\n",
       "max    70.000000   1.000000   0.030989   0.039756   0.016097"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Basis</th>\n",
       "      <th>Result</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>68.312500</td>\n",
       "      <td>0.598214</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.008929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>38.700055</td>\n",
       "      <td>0.492462</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>0.003189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003095</td>\n",
       "      <td>0.003561</td>\n",
       "      <td>0.003614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>34.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.006970</td>\n",
       "      <td>0.006491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.008387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>102.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010126</td>\n",
       "      <td>0.011057</td>\n",
       "      <td>0.010668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>133.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023785</td>\n",
       "      <td>0.020409</td>\n",
       "      <td>0.019761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID       Label       Basis      Result    Sentence\n",
       "count  112.000000  112.000000  112.000000  112.000000  112.000000\n",
       "mean    68.312500    0.598214    0.008929    0.008929    0.008929\n",
       "std     38.700055    0.492462    0.003125    0.002864    0.003189\n",
       "min      1.000000    0.000000    0.003095    0.003561    0.003614\n",
       "25%     34.750000    0.000000    0.007103    0.006970    0.006491\n",
       "50%     70.000000    1.000000    0.008929    0.008266    0.008387\n",
       "75%    102.250000    1.000000    0.010126    0.011057    0.010668\n",
       "max    133.000000    1.000000    0.023785    0.020409    0.019761"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Basis</th>\n",
       "      <th>Result</th>\n",
       "      <th>Clue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.019608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.866069</td>\n",
       "      <td>0.008156</td>\n",
       "      <td>0.009352</td>\n",
       "      <td>0.001151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009641</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>0.014706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>0.014114</td>\n",
       "      <td>0.019608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.018573</td>\n",
       "      <td>0.017927</td>\n",
       "      <td>0.019608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.500000</td>\n",
       "      <td>0.022339</td>\n",
       "      <td>0.021415</td>\n",
       "      <td>0.019608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.048973</td>\n",
       "      <td>0.059873</td>\n",
       "      <td>0.024074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID      Basis     Result       Clue\n",
       "count  51.000000  51.000000  51.000000  51.000000\n",
       "mean   25.000000   0.019608   0.019608   0.019608\n",
       "std    14.866069   0.008156   0.009352   0.001151\n",
       "min     0.000000   0.009641   0.009334   0.014706\n",
       "25%    12.500000   0.013072   0.014114   0.019608\n",
       "50%    25.000000   0.018573   0.017927   0.019608\n",
       "75%    37.500000   0.022339   0.021415   0.019608\n",
       "max    50.000000   0.048973   0.059873   0.024074"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_log_error(truth, pred):\n",
    "    return np.sqrt(mean_squared_log_error(truth, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 8\n",
    "max_words = 15000\n",
    "\n",
    "def tokenize(texts):\n",
    "    texts = [re.sub('\\n', \"\", prune_sentence) for prune_sentence in texts]\n",
    "    tokenizer = Tokenizer(num_words=max_words)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    print(\"Found {} unique tokens.\".format(len(word_index)))\n",
    "\n",
    "    data = pad_sequences(sequences, maxlen=maxlen)\n",
    "    print(\"Shape of data tensor:{}\".format(data.shape))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2215 unique tokens.\n",
      "Shape of data tensor:(380, 8)\n",
      "Found 597 unique tokens.\n",
      "Shape of data tensor:(71, 8)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Util/causal_train_data1.csv')\n",
    "data1 = pd.read_csv('Util/test20181120070201.csv')\n",
    "repository = causalRepository()\n",
    "# x_train = pd.DataFrame()\n",
    "# x_val = pd.DataFrame()\n",
    "\n",
    "# x_train['Basis'] = tokenize([repository.tokenize(item['Causal_Basis']) for index, item in data.iterrows()])\n",
    "# x_train['Result'] = tokenize([repository.tokenize(item['Causal_Result']) for index, item in data.iterrows()])\n",
    "# x_train['Clue'] = tokenize([repository.tokenize(item['Causal_Clue']) for index, item in data.iterrows()])\n",
    "# x_train['Sentence'] = tokenize([repository.tokenize(item['Causal_Sentence']) for index, item in data.iterrows()])\n",
    "\n",
    "# x_val['Basis'] = tokenize([repository.tokenize(item['Causal_Basis']) for index, item in test.iterrows()])\n",
    "# x_val['Result'] = tokenize([repository.tokenize(item['Causal_Result']) for index, item in test.iterrows()])\n",
    "# x_val['Clue'] = tokenize([repository.tokenize(item['Causal_Clue']) for index, item in test.iterrows()])\n",
    "# x_val['Sentence'] = tokenize([repository.tokenize(item['Causal_Sentence']) for index, item in test.iterrows()])\n",
    "x_train = tokenize([repository.tokenize(str(item['Sentence'])) for index, item in data.iterrows()]) \n",
    "x_val = tokenize([repository.tokenize(item['Causal_Sentence']) for index, item in data1.iterrows()])\n",
    "y_train = np.asarray(to_categorical(data['Label']))\n",
    "y_val =np.asarray(to_categorical(data1['Label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 8, 1000)           15000000  \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 32)                132224    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 15,132,290\n",
      "Trainable params: 15,132,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 380 samples, validate on 71 samples\n",
      "Epoch 1/30\n",
      "380/380 [==============================] - 2s 6ms/step - loss: 0.6915 - acc: 0.5421 - val_loss: 0.6827 - val_acc: 0.6761\n",
      "Epoch 2/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.6771 - acc: 0.6158 - val_loss: 0.6738 - val_acc: 0.6761\n",
      "Epoch 3/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.6591 - acc: 0.6263 - val_loss: 0.6656 - val_acc: 0.6761\n",
      "Epoch 4/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.6324 - acc: 0.6632 - val_loss: 0.6602 - val_acc: 0.7042\n",
      "Epoch 5/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.5925 - acc: 0.7026 - val_loss: 0.6633 - val_acc: 0.6479\n",
      "Epoch 6/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.5339 - acc: 0.7500 - val_loss: 0.6778 - val_acc: 0.6197\n",
      "Epoch 7/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.4539 - acc: 0.8395 - val_loss: 0.7066 - val_acc: 0.4930\n",
      "Epoch 8/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.3603 - acc: 0.8895 - val_loss: 0.7514 - val_acc: 0.4930\n",
      "Epoch 9/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.2547 - acc: 0.9447 - val_loss: 0.8127 - val_acc: 0.5211\n",
      "Epoch 10/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.1652 - acc: 0.9684 - val_loss: 0.9150 - val_acc: 0.5352\n",
      "Epoch 11/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.1075 - acc: 0.9763 - val_loss: 1.0481 - val_acc: 0.5211\n",
      "Epoch 12/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.0720 - acc: 0.9816 - val_loss: 1.1929 - val_acc: 0.5070\n",
      "Epoch 13/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.0445 - acc: 0.9921 - val_loss: 1.3280 - val_acc: 0.4648\n",
      "Epoch 14/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.0288 - acc: 0.9947 - val_loss: 1.4486 - val_acc: 0.4789\n",
      "Epoch 15/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.0209 - acc: 0.9974 - val_loss: 1.5563 - val_acc: 0.4930\n",
      "Epoch 16/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.0178 - acc: 0.9947 - val_loss: 1.6347 - val_acc: 0.5070\n",
      "Epoch 17/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.0214 - acc: 0.9947 - val_loss: 1.7068 - val_acc: 0.4930\n",
      "Epoch 18/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.0156 - acc: 0.9974 - val_loss: 1.7357 - val_acc: 0.4789\n",
      "Epoch 19/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.0102 - acc: 0.9974 - val_loss: 1.7650 - val_acc: 0.4789\n",
      "Epoch 20/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.0145 - acc: 0.9974 - val_loss: 1.7918 - val_acc: 0.4789\n",
      "Epoch 21/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.0121 - acc: 0.9974 - val_loss: 1.8199 - val_acc: 0.4648\n",
      "Epoch 22/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.0080 - acc: 0.9974 - val_loss: 1.8433 - val_acc: 0.4507\n",
      "Epoch 23/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.0100 - acc: 0.9947 - val_loss: 1.8561 - val_acc: 0.4507\n",
      "Epoch 24/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.0078 - acc: 0.9947 - val_loss: 1.8757 - val_acc: 0.4507\n",
      "Epoch 25/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.0076 - acc: 0.9947 - val_loss: 1.8932 - val_acc: 0.4507\n",
      "Epoch 26/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.0086 - acc: 0.9947 - val_loss: 1.9084 - val_acc: 0.4507\n",
      "Epoch 27/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.0063 - acc: 0.9974 - val_loss: 1.9327 - val_acc: 0.4507\n",
      "Epoch 28/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.0077 - acc: 0.9974 - val_loss: 1.9421 - val_acc: 0.4648\n",
      "Epoch 29/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.0065 - acc: 0.9947 - val_loss: 1.9545 - val_acc: 0.4930\n",
      "Epoch 30/30\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.0067 - acc: 0.9974 - val_loss: 1.9693 - val_acc: 0.4930\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'): # because CPU is faster than GPU\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(15000, 1000, input_length=maxlen))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(x_train, y_train, epochs=30, batch_size=100, validation_split=0.2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3XmcFNW5//HPI6sssruyariRfXEiJkAARcQYQQwqCHGJSDQuUWN+Ek1cg0FDlKtyjai4gSBXrhEjiCRiiMZtUAQBEUTQQUBAGUVwGXh+f5waaMZZemZ6prfv+/WqV3dXnap+ahqePn3q1Dnm7oiISPY4INkBiIhI9VLiFxHJMkr8IiJZRolfRCTLKPGLiGQZJX4RkSyjxC/lZmY1zGyHmbVOZNlkMrPvmVnC+zab2UAzWxfzepWZ9Y2nbAXe6wEzu7ai+5dy3D+a2cOJPq4kT81kByBVz8x2xLysB3wN7I5e/9Ldp5fneO6+G2iQ6LLZwN2/n4jjmNkYYLS794859phEHFsynxJ/FnD3vYk3qlGOcfd/lFTezGq6e0F1xCYi1U9NPVL4U/4JM5thZl8Ao83sh2b2qpltN7ONZnaXmdWKytc0MzezttHradH2eWb2hZm9Ymbtyls22n6ymb1nZvlmdreZvWxm55UQdzwx/tLM1pjZZ2Z2V8y+NczsTjPbZmZrgcGl/H2uM7OZRdZNNrM7oudjzGxldD7vR7Xxko6VZ2b9o+f1zOyxKLblwDFFyv7ezNZGx11uZkOi9V2Ae4C+UTPa1pi/7Y0x+18Unfs2M/ubmR0Wz9+mLGY2LIpnu5m9YGbfj9l2rZl9bGafm9m7Med6nJm9Ga3fbGZ/jvf9pAq4u5YsWoB1wMAi6/4IfAOcSqgMHAj8AOhF+FV4JPAecGlUvibgQNvo9TRgK5AD1AKeAKZVoOzBwBfA0GjbVcC3wHklnEs8MT4NNALaAp8WnjtwKbAcaAk0AxaF/w7Fvs+RwA6gfsyxPwFyotenRmUMOB7YBXSNtg0E1sUcKw/oHz2fCLwINAHaACuKlD0TOCz6TM6OYjgk2jYGeLFInNOAG6Png6IYuwN1gf8BXojnb1PM+f8ReDh63iGK4/joM7oWWBU97wSsBw6NyrYDjoyevwGMjJ43BHol+/9CNi+q8Uuhl9z9GXff4+673P0Nd3/N3QvcfS0wBehXyv5Punuuu38LTCcknPKW/SmwxN2fjrbdSfiSKFacMf7J3fPdfR0hyRa+15nAne6e5+7bgAmlvM9a4B3CFxLAicBn7p4bbX/G3dd68ALwT6DYC7hFnAn80d0/c/f1hFp87PvOcveN0WfyOOFLOyeO4wKMAh5w9yXu/hUwDuhnZi1jypT0tynNCGCOu78QfUYTCF8evYACwpdMp6i58IPobwfhC7y9mTVz9y/c/bU4z0OqgBK/FPoo9oWZHW1mz5rZJjP7HLgZaF7K/ptinu+k9Au6JZU9PDYOd3dCDblYccYY13sRaqqleRwYGT0/O3pdGMdPzew1M/vUzLYTatul/a0KHVZaDGZ2npm9HTWpbAeOjvO4EM5v7/Hc/XPgM+CImDLl+cxKOu4ewmd0hLuvAn5D+Bw+iZoOD42Kng90BFaZ2etm9pM4z0OqgBK/FCralfE+Qi33e+5+EHA9oSmjKm0kNL0AYGbG/omqqMrEuBFoFfO6rO6ms4CBZnYEoeb/eBTjgcCTwJ8IzTCNgefjjGNTSTGY2ZHAvcDFQLPouO/GHLesrqcfE5qPCo/XkNCktCGOuMpz3AMIn9kGAHef5u69Cc08NQh/F9x9lbuPIDTn/QWYbWZ1KxmLVJASv5SkIZAPfGlmHYBfVsN7/h3oaWanmllN4NdAiyqKcRZwhZkdYWbNgGtKK+zum4CXgIeBVe6+OtpUB6gNbAF2m9lPgRPKEcO1ZtbYwn0Ol8Zsa0BI7lsI34EXEmr8hTYDLQsvZhdjBnCBmXU1szqEBPxvdy/xF1Q5Yh5iZv2j9/4t4brMa2bWwcwGRO+3K1r2EE7g52bWPPqFkB+d255KxiIVpMQvJfkNcC7hP/V9hIuwVcrdNwNnAXcA24CjgLcI9x0kOsZ7CW3xywgXHp+MY5/HCRdr9zbzuPt24ErgKcIF0uGEL7B43ED45bEOmAc8GnPcpcDdwOtRme8Dse3iC4DVwGYzi22yKdz/OUKTy1PR/q0J7f6V4u7LCX/zewlfSoOBIVF7fx3gdsJ1mU2EXxjXRbv+BFhpodfYROAsd/+msvFIxVhoRhVJPWZWg9C0MNzd/53seEQyhWr8klLMbHDU9FEH+AOhN8jrSQ5LJKMo8Uuq6QOsJTQjnAQMc/eSmnpEpALU1CMikmVU4xcRyTIpOUhb8+bNvW3btskOQ0QkbSxevHiru5fW/XmvlEz8bdu2JTc3N9lhiIikDTMr6+7zvdTUIyKSZZT4RUSyTJmJ38xamdlCM1sRjcH962LKmIWx0NeY2VIz6xmz7VwzWx0t5yb6BEREpHziaeMvAH7j7m9GAz0tNrMF7r4ipszJQPto6UW4nbuXmTUl3JaeQxibY7GZzXH3z8ob6LfffkteXh5fffVVeXeVala3bl1atmxJrVolDSMjIslUZuJ3942EsT5w9y/MbCVhxMTYxD8UeDQaRvfV6M7Lw4D+wAJ3/xTAzBYQxvaYUd5A8/LyaNiwIW3btiUM2iipyN3Ztm0beXl5tGvXruwdRKTalauN38L0eT3Yf7AoCF8EseOK50XrSlpf3LHHmlmumeVu2bLlO9u/+uormjVrpqSf4syMZs2a6ZeZSAqLO/GbWQNgNnBFNKlDQrn7FHfPcfecFi2K74qqpJ8e9DmJpLa4+vFH427PBqa7+/8VU2QD+08oUTgxwwZCc0/s+hcrEqiISKYpKIB162DNGli9GnbuhGtKnRkiMcpM/NEsSA8CK939jhKKzQEuNbOZhIu7+e6+0czmA7eaWZOo3CDgdwmIu1pt27aNE04Ic2ts2rSJGjVqUPir5PXXX6d27dplHuP8889n3LhxfP/73y+xzOTJk2ncuDGjRlV62HT69OnDPffcQ/fu8UyjKiJV5dtv90/usY/r1oXkX+iww+D//T+o6h/N8dT4ewM/B5aZ2ZJo3bVE08S5+1+BuYSJFtYQ5u48P9r2qZndQpjoAuDmwgu9VW36dLjuOvjwQ2jdGsaPh4rm02bNmrFkSTj1G2+8kQYNGnD11VfvV2bv7PUHFN969tBDD5X5PpdccknFAhSRpMnPD3mmcFm/fv/XGzbAnpi5xho0gPbtoWdPOPPM8Px73wvLIYdUfdKH+Hr1vEQZ84dGvXmKzVruPhWYWqHoKmj6dBg7NvxsgvBBjB0bniegMr3XmjVrGDJkCD169OCtt95iwYIF3HTTTbz55pvs2rWLs846i+uvvx7YVwPv3LkzzZs356KLLmLevHnUq1ePp59+moMPPpjf//73NG/enCuuuII+ffrQp08fXnjhBfLz83nooYf40Y9+xJdffsk555zDypUr6dixI+vWreOBBx4otWY/bdo0brvtNtydIUOGcOutt1JQUMD555/PkiVLcHfGjh3L5Zdfzp133sn9999PzZo16dq1K9OmTUvcH0wkTezeDVu3wubNJS8ffxwSe37+/vvWqgWtWoUK54AB4fGoo/Yl+IMPrp7kXpqUHKunsq67bl/SL7RzZ1ifyMQP8O677/Loo4+Sk5MDwIQJE2jatCkFBQUMGDCA4cOH07Fjx/32yc/Pp1+/fkyYMIGrrrqKqVOnMm7cuO8c2915/fXXmTNnDjfffDPPPfccd999N4ceeiizZ8/m7bffpmfPnt/ZL1ZeXh6///3vyc3NpVGjRgwcOJC///3vtGjRgq1bt7Js2TIAtm/fDsDtt9/O+vXrqV279t51IpksLw9efhleeglefTUk861b96+lF6pTJ9TKDzkE2rWDfv2gTZuQ3AuXQw+FEn74p4yMTPwffli+9ZVx1FFH7U36ADNmzODBBx+koKCAjz/+mBUrVnwn8R944IGcfPLJABxzzDH8+9/Fzyp4+umn7y2zbt06AF566SWuia7+dOvWjU6dOpUa32uvvcbxxx9P8+bNATj77LNZtGgR11xzDatWreLyyy/nlFNOYdCgQQB06tSJ0aNHM3ToUE477bRy/jVEUtuePbB8+b5E/9JLoUUAoH59OPZYGDp0X3KPXQ49FA46KPm19UTIyMTfuvW+D7Po+kSrX7/+3uerV6/mv//7v3n99ddp3Lgxo0ePLrY/e+zF4Bo1alAQe3UnRp06dcosU1HNmjVj6dKlzJs3j8mTJzN79mymTJnC/Pnz+de//sWcOXO49dZbWbp0KTVq1Ejoe4tUh8IeM++9B2+/HZL8f/4DhT9kDz0U+vSBK68Mj926Qc2MzIjflZGnOX78/m38APXqhfVV6fPPP6dhw4YcdNBBbNy4kfnz5zN48OCEvkfv3r2ZNWsWffv2ZdmyZaxYsaLU8r169eLqq69m27ZtNGrUiJkzZ3L11VezZcsW6tatyxlnnEH79u0ZM2YMu3fvJi8vj+OPP54+ffrQqlUrdu7cScOGDRN6DiKJsmdPaKp5773QUyb28YMP9u8x07FjuJjau3dI9O3aZUbtvSIyMvEXtuMnqldPvHr27EnHjh05+uijadOmDb179074e1x22WWcc845dOzYce/SqFGjEsu3bNmSW265hf79++PunHrqqZxyyim8+eabXHDBBbg7ZsZtt91GQUEBZ599Nl988QV79uzh6quvVtKXlFBQELo/Ll8OK1bse1y9GmJ/VNerFy6idusGZ5wRnv/Xf8HRR0PTpsmLP9Wk5Jy7OTk5XnQilpUrV9KhQ4ckRZQ6CgoKKCgooG7duqxevZpBgwaxevVqaqbYb1R9XlIRu3fD+++HxB67rFoF33yzr1y7dtCpU0johcm9fXs4/PDsrcWb2WJ3zym7ZIbW+DPZjh07OOGEEygoKMDdue+++1Iu6YvEY+dOWLoUlizZtyxdCrt27SvTtm1I8CefHB4Lk33MpTWpAGWMNNO4cWMWL16c7DBE4uYOGzfCsmX7J/n33tvXZbJxY+jeHX75S+jaFTp3hg4dws1OknhK/CJSKbt3h8S+fn3oRVP4WPh8/Xr4+ut95du0CUl+xIjw2L17uA6XrU00yaDELyJx27ULFi+GV14Jy9KloQPFt9/uX65Fi9BM060bDBkSkn3nzuF1kybFHlqqkRK/iBTLHT76aF+Sf+UVeOutfUn+qKPgmGNg+PCQ5Nu23XcXq9rgU5sSv4gAIdEvXw7/+Ee4s/WVV8IAYwAHHgg/+AFcdRX86Edw3HFhzBlJTyk+okTqGDBgAPPnz99v3aRJk7j44otL3a9BdHXq448/Zvjw4cWW6d+/P0W7rxY1adIkdsbckfaTn/wkIWPp3HjjjUycOLHSx5H0tHEjPPYYnHMOHHEEdOkS7mTNzYUf/xjuugveeCMMRPavf8GECaHpRkk/vanGH6eRI0cyc+ZMTjrppL3rZs6cye233x7X/ocffjhPPvlkhd9/0qRJjB49mnr16gEwd+7cCh9LstfOnbBoESxYAM8/D++8E9Y3awYDB8KgQeGxKoY3kdShGn+chg8fzrPPPss30V0k69at4+OPP6Zv3757+9b37NmTLl268PTTT39n/3Xr1tG5c2cAdu3axYgRI+jQoQPDhg1jV0zH5YsvvpicnBw6derEDTfcAMBdd93Fxx9/zIABAxgwYAAAbdu2ZevWrQDccccddO7cmc6dOzNp0qS979ehQwcuvPBCOnXqxKBBg/Z7n+IsWbKE4447jq5duzJs2DA+++yzve/fsWNHunbtyogRIwD417/+Rffu3enevTs9evTgiy++qPDfVqrOt9+GJptbb4Xjjw8XVk8+Ge65Jww8NmFCuFj7yScwcyb84hdK+tkgLWv8V1wR+gEnUvfuEOXMYjVt2pRjjz2WefPmMXToUGbOnMmZZ56JmVG3bl2eeuopDjroILZu3cpxxx3HkCFDSpx79t5776VevXqsXLmSpUuX7je08vjx42natCm7d+/mhBNOYOnSpVx++eXccccdLFy4cO8om4UWL17MQw89xGuvvYa706tXL/r160eTJk1YvXo1M2bM4P777+fMM89k9uzZjB49usRzPOecc7j77rvp168f119/PTfddBOTJk1iwoQJfPDBB9SpU2dv89LEiROZPHkyvXv3ZseOHdStW7ccf22pKrt3hwHJXngBFi4MtfsdO8K2Ll3gssvgxBOhb98wvIFkpzJr/GY21cw+MbN3Stj+WzNbEi3vmNluM2sabVtnZsuibaU3YqeBwuYeCM08I0eOBMK4+ddeey1du3Zl4MCBbNiwgc2bN5d4nEWLFu1NwF27dqVr1657t82aNYuePXvSo0cPli9fXuYgbC+99BLDhg2jfv36NGjQgNNPP33vMM/t2rXbO0FL7NDOxcnPz2f79u3069cPgHPPPZdFixbtjXHUqFFMmzZt713CvXv35qqrruKuu+5i+/btuns4SdxDc83dd8OwYdC8eehp89vfhqEPfv5zmDUr1OiXLoWJE+Gkk5T0s108/1sfBu4BHi1uo7v/GfgzgJmdClxZZHrFAe6+tZJx7qe0mnlVGjp0KFdeeSVvvvkmO3fu5JhjjgFg+vTpbNmyhcWLF1OrVi3atm1b7HDMZfnggw+YOHEib7zxBk2aNOG8886r0HEKFQ7rDGFo57Kaekry7LPPsmjRIp555hnGjx/PsmXLGDduHKeccgpz586ld+/ezJ8/n6OPPrrCsUr8tm4NbfTz5oV2+sI6Rrt2cPrpoUlnwIAwbo1Iccqs8bv7IiDeeXJHAjMqFVEKa9CgAQMGDOAXv/jF3to+hNrywQcfTK1atVi4cCHri5sMIMaPf/xjHn/8cQDeeecdli5dCoRhnevXr0+jRo3YvHkz8+bN27tPw4YNi21H79u3L3/729/YuXMnX375JU899RR9+/Yt97k1atSIJk2a7P218Nhjj9GvXz/27NnDRx99xIABA7jtttvIz89nx44dvP/++3Tp0oVrrrmGH/zgB7z77rvlfk+Jz+7doZ3+hhugV6/Qo+bss2Hu3JDkp04NQxCvXQsPPhhGoVXSl9Ik7Pe5mdUDBgOXxqx24Hkzc+A+d59Syv5jgbEArVP46tLIkSMZNmzY3iYfgFGjRnHqqafSpUsXcnJyyqz5XnzxxZx//vl06NCBDh067P3l0K1bN3r06MHRRx9Nq1at9hvWeezYsQwePJjDDz+chQsX7l3fs2dPzjvvPI499lgAxowZQ48ePUpt1inJI488wkUXXcTOnTs58sgjeeihh9i9ezejR48mPz8fd+fyyy+ncePG/OEPf2DhwoUccMABdOrUae+MYpIYGzfC/Pnw3HOhVv/ZZ2E6v1694MYbYfDg0KSjOXKkIuIaltnM2gJ/d/fOpZQ5Cxjt7qfGrDvC3TeY2cHAAuCy6BdEqTQsc/rT51U+X38dZoiaPz8s0Y9ADj00JPmTTw7dLDWmvJQkWcMyj6BIM4+7b4gePzGzp4BjgTITv0imcw+jUxYm+hdfDH3sa9UKM0T96U8h2XftqsHLJPESkvjNrBHQDxgds64+cIC7fxE9HwTcnIj3E0lH+flhOIT580PzTeGloPbtQ//5k06C/v01FLFUvTITv5nNAPoDzc0sD7gBqAXg7n+Nig0Dnnf3L2N2PQR4KurLXhN43N2fq0ywhdMESmpLxVndkskd7r8/jHPz5ZfQsCGccAKMGxeSfbt2yY5Qsk2Zid/dR8ZR5mFCt8/YdWuBbhUNrKi6deuybds2mjVrpuSfwtydbdu26YauyKZNMGYMPPtsaKMv7JlTq1ayI5NsljZ33bRs2ZK8vDy2bNmS7FCkDHXr1qVly5bJDiPpZs8OM0p9+WUY7OySS0LPHJFkS5vEX6tWLdrpN7Gkgfz8MDTCY4+FLpfTpoV5YkVSheofIgn0wgthTJzHH4frrw83XinpS6pR4hdJgF27wjj2J5wQJi35z3/gppvUli+pKW2aekRS1ZtvhsHQVqwI7fi3365B0CS1qcYvUkF79oQk36sXbN8e+uffc4+SvqQ+1fhFKmDrVjj33DBQ2vDhcN99Gk5B0ocSv0g5vfwyjBgRxrifPBkuvljDKkh6UVOPSJz27IE//xn69YPatcMF3F/9Sklf0o9q/CJx+PTT0LTz97/Dz34Wxr1v1CjZUYlUjGr8ImV49VXo0SNcvL37bvjf/1XSl/SmxC9SAnf4y1/CxOQ1aoSmnUsvVdOOpD819YgU47PP4LzzYM6cMIn51KnQuHGyoxJJDCV+kSLWrw+TleflwaRJcPnlquVLZlHiF4mxYUOYwPyzz2DRIjjuuGRHJJJ4SvwikU2bQtLfsgUWLAh35IpkojIv7prZVDP7xMzeKWF7fzPLN7Ml0XJ9zLbBZrbKzNaY2bhEBi6SSFu3holS8vLC3bhK+pLJ4unV8zAwuIwy/3b37tFyM4CZ1QAmAycDHYGRZtaxMsGKVIXPPoNBg+D99+GZZ6BPn2RHJFK1ykz87r4I+LQCxz4WWOPua939G2AmMLQCxxGpMp9/DoMHw/Ll8NRToalHJNMlqh//D83sbTObZ2adonVHAB/FlMmL1omkhC+/hFNOCcMqz5oVvgBEskEiLu6+CbRx9x1m9hPgb0D78h7EzMYCYwFat26dgLBESrZrFwwZEm7KmjkThuq3qGSRStf43f1zd98RPZ8L1DKz5sAGoFVM0ZbRupKOM8Xdc9w9p0WLFpUNS6REX38dxttZuBAeeQTOOCPZEYlUr0onfjM71Czc3mJmx0bH3Aa8AbQ3s3ZmVhsYAcyp7PuJVMa338JZZ8G8eTBlCoweneyIRKpfmU09ZjYD6A80N7M84AagFoC7/xUYDlxsZgXALmCEuztQYGaXAvOBGsBUd19eJWchEoeCgpDon346zJQ1ZkyyIxJJjjITv7uPLGP7PcA9JWybC8ytWGgiieMexs6fNQsmTgxz44pkK43OKVnhttvg/vvh2mvhN79JdjQiyaXELxnviSfgd7+Ds8+GP/4x2dGIJJ8Sv2S0l18OM2f17RuGVtYomyJK/JLB1qwJ/fNbtw535dapk+yIRFKDEr9kpK1b4eSTQw1/7lxo1izZEYmkDg3LLBnnq6/gtNPgo4/ghRfge99LdkQiqUWJXzLKnj1w/vmhbX/WLPjRj5IdkUjqUVOPZJQ//CGMvXPbbRqKQaQkSvySMR54AG69FcaOhd/+NtnRiKQuJX7JCAsWwEUXwUknweTJ6rYpUholfkl7y5bB8OHQsWNo16+pK1cipVLil7S2ZQv89KfQoAE8+ywcdFCyIxJJfaobSdravRtGjYLNm0Mvnlatyt5HRJT4JY3ddFNo23/gATjmmGRHI5I+1NQjaWnuXLjlltBn/4ILkh2NSHpR4pe0s25dmFClW7fQg0dEykeJX9LKV1+FHjx79sDs2XDggcmOSCT9lJn4zWyqmX1iZu+UsH2UmS01s2Vm9h8z6xazbV20fomZ5SYycMlOV1wBixeHSdKPOirZ0Yikp3hq/A8Dg0vZ/gHQz927ALcAU4psH+Du3d09p2IhigSPPgr33QfXXBOGWxaRiolnzt1FZta2lO3/iXn5KtCy8mGJ7G/p0nBnbv/+mkVLpLIS3cZ/ATAv5rUDz5vZYjMbW9qOZjbWzHLNLHfLli0JDkvSWX4+/Oxn0LgxzJihO3NFKith/4XMbAAh8feJWd3H3TeY2cHAAjN7190XFbe/u08haibKycnxRMUl6c09dNn84ANYuBAOPTTZEYmkv4TU+M2sK/AAMNTdtxWud/cN0eMnwFPAsYl4P8kef/lLmDbx9tvDvLkiUnmVTvxm1hr4P+Dn7v5ezPr6Ztaw8DkwCCi2Z5BIcRYtgnHjQjPPlVcmOxqRzFFmU4+ZzQD6A83NLA+4AagF4O5/Ba4HmgH/Y2Es3IKoB88hwFPRuprA4+7+XBWcg2SgTZvgrLPgyCNh6lQNsyySSPH06hlZxvYxwJhi1q8Fun13D5HS7dkT7szNz4fnn9eImyKJpv4RknL+8hf45z/h/vuhS5dkRyOSeTRkg6SU3Fy49trQrq/B10SqhhK/pIwdO2DkyNBlc8oUteuLVBU19UjKuPxyeP/90F+/adNkRyOSuVTjl5TwxBPw0ENw3XXQr1+yoxHJbEr8knTr1sEvfwnHHQfXX5/saEQynxK/JFVBQei6uWcPTJ8OtWolOyKRzKc2fkmqP/4xTJQ+bVq4WUtEqp5q/JI0L70U5s39+c9h1KhkRyOSPZT4JSm2bw/Jvm1buOeeZEcjkl3U1CPVzj1czN2wITTzaEgGkeqlxC/V7uGHYdYsGD8eevVKdjQi2UdNPVKt3nsPLrssTKF4zTXJjkYkOynxS7X56is4+2yoXRseewxq1Eh2RCLZSU09Um1+/WtYvDjMqNWyZbKjEcleqvFLtZg6NQy8ds01cNppyY5GJLvFlfjNbKqZfWJmxU6daMFdZrbGzJaaWc+Ybeea2epoOTdRgUv6WLwYfvUrOOGEcMOWiCRXvDX+h4HBpWw/GWgfLWOBewHMrClhqsZehInWbzCzJhUNVtLPtm1hbP2DD4YZM6CmGhdFki6uxO/ui4BPSykyFHjUg1eBxmZ2GHASsMDdP3X3z4AFlP4FIhlk9+5wMXfjRnjySWjRItkRiQgkro3/COCjmNd50bqS1n+HmY01s1wzy92yZUuCwpJkuvHGMGfu3XfDsccmOxoRKZQyF3fdfYq757h7TgtVDdPeM8+E9vxf/AIuvDDZ0YhIrEQl/g1Aq5jXLaN1Ja2XDLZmTRh4rWfPMA6PplAUSS2JSvxzgHOi3j3HAfnuvhGYDwwysybRRd1B0TrJUF9+CaefHm7Omj0bDjww2RGJSFFx9bEwsxlAf6C5meUReurUAnD3vwJzgZ8Aa4CdwPnRtk/N7BbgjehQN7t7aReJJY25w9ix8M478NxzYeRNEUk9cSV+dx9ZxnYHLilh21RgavlDk3Rzzz3w+OOhbX/QoGRHIyIlSZmLu5LeXn4Zrroxe9Q8AAAQNElEQVQKTj0Vfve7ZEcjIqVR4pdK27QJzjgjNO08+igcoH9VIilN91FKpWzeDAMHQn4+zJ8PjRsnOyIRKYsSv1TYxo1w/PHw4Yeh336XLsmOSETiocQvFbJhQ0j6GzbA3LnQr1+yIxKReCnxS7l99BEMGBCaeZ57Dvr0SXZEIlIeSvxSLuvWhZr+tm2wYAEcd1yyIxKR8lLil7itXRtq+p9/Dv/4B/zgB8mOSEQqQolf4rJ6dajp79wJ//xnGIdHRNKTEr+UadWqkPS/+QZeeAG6dUt2RCJSGUr8UqoVK8KUiXv2wMKF0LlzsiMSkcrSPZZSonfegf79w/MXX1TSF8kUSvzyHQUFYcC1Pn2gVq2Q9Dt0SHZUIpIoSvyynxdfDBduL7sMcnLg3/+G738/2VGJSCIp8QsQbso666x93TVnzw799I88MtmRiUiiKfFnua++gvHj4eijYc6cMEH6ypVhFi1NmSiSmeKdgWsw8N9ADeABd59QZPudwIDoZT3gYHdvHG3bDSyLtn3o7kMSEbhUjnsYWO3KK8ONWT/7GUycqFmzRLJBmYnfzGoAk4ETgTzgDTOb4+4rCsu4+5Ux5S8DesQcYpe7d09cyFJZq1bBr38dhlHu2DE06QwcmOyoRKS6xNPUcyywxt3Xuvs3wExgaCnlRwIzEhGcJNbSpXDhhWH45FdegTvvhCVLlPRFsk08if8I4KOY13nRuu8wszZAO+CFmNV1zSzXzF41s9NKehMzGxuVy92yZUscYUk8du+Gp54KF227dYPp02HMmDAEwxVXhO6aIpJdEn3n7gjgSXffHbOujbtvMLMjgRfMbJm7v190R3efAkwByMnJ8QTHlXU+/RQefBAmT4b166F1a7j9drjgAmjaNNnRiUgyxZP4NwCtYl63jNYVZwRwSewKd98QPa41sxcJ7f/fSfySGMuXw913h7lvd+0Kd97eeWeYBL2mBugQEeJr6nkDaG9m7cysNiG5zylayMyOBpoAr8Ssa2JmdaLnzYHewIqi+ybC9OmhR8oBB4TH6dOr4l1SU2G/+4EDw7AKjzwCZ58d2u8XLoRhw5T0RWSfMhO/uxcAlwLzgZXALHdfbmY3m1ls18wRwEx3j22m6QDkmtnbwEJgQmxvoESZPh3Gjg1NGu7hcezY4pN/JnxB7NkDubmh//2PfwzNmsHw4aG3zp/+FG7GeuABjaIpIsWz/fN0asjJyfHc3Ny4y7dtG5J9UW3ahBmjChV+QezcuW9dvXowZQqMGlXhcKvFhg3w/PNhWbAgzIAFYXiFk06CQYPC2Dqq2YtkJzNb7O45cZXNhMR/wAGhpl+cq66Cgw8OyzXXQHEdhop+QRSaPh2uuw4+/DBcHB0/vuq/INxDUl+zJixvvRX62y9fHrYfeui+RH/iidCiRdXGIyLpoTyJPyPqh61bF1/jr1ED7r03XOQszfr1IZm2aAHNm4dl7dqQ+L/5Zl+ZCy8Mr887r3LDGbjDxo0hsb///r4kX/g6P39f2Tp1oG/f8J6DBoU++BpKQUQqIyNq/GU14Xz5Zajp//CHsGnTd/c/8EDo2jWU2bo1XCwtTc2a0LDh/stBB0HduvD112H56quwFD4vum53TIfXGjWgXTv43vfCctRR+563axeSv4hIabKuxl/Y/FJSs0z9+mGZODG+Nv5vvik92f72t/DFF/uW996DN98M+9WuHUa0bNUq/IKoWzccq+jjEUfsS/KtW+tGKhGpPhlR4y+PeNvts+GCsYhkjqy7uFsV4k3o8X5BiIhUpfIkfo3HX4JRo0KSb9MmXExt06b4WvyHHxa/f0nrRUSSTYm/FKNGhVr7nj3hsbimm9ati9+3pPWZcAOZiKQ3Jf5KGj8+NAHFqlcvrC+qPHcYi4hUFSX+Soq3SQjCReXYawYQXl93XfXEKiICurhbrUq6w9gsNCeJiFSULu6mqPJeDxARqQpK/NWoPNcDRESqihJ/NSrP9QD1/hGRqpIRQzakk1Gjyr6jt+jNY4W9fwr3FxGpDNX4U5B6/4hIVYor8ZvZYDNbZWZrzGxcMdvPM7MtZrYkWsbEbDvXzFZHy7mJDD5T6W5gEalKZTb1mFkNYDJwIpAHvGFmc4qZQvEJd7+0yL5NgRuAHMCBxdG+nyUk+gxV0vwC6v0jIokQT43/WGCNu69192+AmcDQOI9/ErDA3T+Nkv0CYHDFQs0e6v0jIlUpnsR/BPBRzOu8aF1RPzOzpWb2pJm1Kue+mNlYM8s1s9wtxc2PmEXK0/tHRKS8EnVx9xmgrbt3JdTqHynvAdx9irvnuHtOC00kG9cAcSIiFRFP4t8AtIp53TJat5e7b3P3r6OXDwDHxLuvVJ76/ItIecST+N8A2ptZOzOrDYwA5sQWMLPDYl4OAVZGz+cDg8ysiZk1AQZF6yRBNOKniJRXmYnf3QuASwkJeyUwy92Xm9nNZjYkKna5mS03s7eBy4Hzon0/BW4hfHm8AdwcrZMEUZ9/ESkvjc6Z5jTip4iARufMKhrxU0TKS4k/zanPv4iUlxJ/mlOffxEpL43OmQHiGfFTRKSQavwiIllGiT+L6EYvEQE19WQNTe4iIoVU488SutFLRAop8WcJTe4iIoWU+LOEbvQSkUJK/FlCN3qJSCEl/iyhG71EpJB69WQR3eglIqAav4hI1lHiFxHJMkr8IiJZJq7Eb2aDzWyVma0xs3HFbL/KzFaY2VIz+6eZtYnZttvMlkTLnKL7SmrS8A4imavMi7tmVgOYDJwI5AFvmNkcd18RU+wtIMfdd5rZxcDtwFnRtl3u3j3BcUsV0vAOIpktnhr/scAad1/r7t8AM4GhsQXcfaG7Fw4I8CrQMrFhSnXS8A4imS2exH8E8FHM67xoXUkuAObFvK5rZrlm9qqZnVbSTmY2NiqXu2XLljjCkqqi4R1EMltCL+6a2WggB/hzzOo20QTAZwOTzOyo4vZ19ynunuPuOS1atEhkWFJOGt5BJLPFk/g3AK1iXreM1u3HzAYC1wFD3P3rwvXuviF6XAu8CPSoRLxSDTS8g0hmiyfxvwG0N7N2ZlYbGAHs1zvHzHoA9xGS/icx65uYWZ3oeXOgNxB7UVhSkIZ3EMlsZfbqcfcCM7sUmA/UAKa6+3IzuxnIdfc5hKadBsD/mhnAh+4+BOgA3GdmewhfMhOK9AaSFKXhHUQyl7l7smP4jpycHM/NzU12GCIiacPMFkfXU8ukO3elUnSjl0j60eicUmG60UskPanGLxWmG71E0pMSv1SYbvQSSU9K/FJhutFLJD0p8UuF6UYvkfSkxC8VVt4bvdQDSCQ1qFePVEq8N3qpB5BI6lCNX6qFegCJpA4lfqkW5ekBpCYhkaqlxC/VIt4eQIVNQuvXg/u+JiElf5HEUeKXahFvDyA1CYlUPSV+qRbx9gAq701hahYSKT/16pFqE08PoNatQ/NOceuLUk8hkYpRjV9SSnluCitPs1B5fhlUxa8I/TKRlOLuKbccc8wxLtlr2jT3Nm3czcLjtGnFlzNzD5eA91/Mvnu8evX2L1OvXvHHLW/ZeOKsimOWR3mOWRXvL9WDMDFWXDk2vkIwGFgFrAHGFbO9DvBEtP01oG3Mtt9F61cBJ8Xzfkr8Eo82bYpP/G3aVKxcecqWJ5lXxTELy5eVpJP9pVeesjpm5b5wE5r4CdMtvg8cCdQG3gY6FinzK+Cv0fMRwBPR845R+TpAu+g4Ncp6TyV+iUe8iSreXwblKVueL5OqOGa8557sL714y+qY8X/hlyTRif+HwPyY178DflekzHzgh9HzmsBWwIqWjS1X2qLEL/GKp6ZUFcmvPF8m6XLMqviCSuavskw8ZmkSnfiHAw/EvP45cE+RMu8ALWNevw80B+4BRsesfxAYXtZ7KvFLIlVFLS3ZtfNkJumq+DLRMeM7ZmnKk/hTplePmY01s1wzy92yZUuyw5EMUp5RROMtW57eR1VxzHjvhC7PMeMtW555GOItq2PGv39ClPXNgJp6RIqVzB44ybwQm+x27mw+ZmlIcFNPTWAt4eJs4cXdTkXKXML+F3dnRc87sf/F3bXo4q5IQiSz62Wye7Zk8zFLUp7Eb6F86czsJ8AkQg+fqe4+3sxujt5ojpnVBR4DegCfAiPcfW2073XAL4AC4Ap3n1fW++Xk5Hhubm6ZcYmISGBmi909J66y8ST+6qbELyJSPuVJ/ClzcVdERKqHEr+ISJZR4hcRyTJK/CIiWSYlL+6a2RYgdlT25oR7AzJJpp1Tpp0PZN45Zdr5QOadU2XOp427t4inYEom/qLMLDfeq9XpItPOKdPOBzLvnDLtfCDzzqm6zkdNPSIiWUaJX0Qky6RL4p+S7ACqQKadU6adD2TeOWXa+UDmnVO1nE9atPGLiEjipEuNX0REEkSJX0Qky6R84jezwWa2yszWmNm4ZMdTWWa2zsyWmdkSM0vLkejMbKqZfWJm78Ssa2pmC8xsdfTYJJkxlkcJ53OjmW2IPqcl0Qi1acPMWpnZQjNbYWbLzezX0fq0/JxKOZ+0/ZzMrK6ZvW5mb0fndFO0vp2ZvRblvCfMrHbC3zuV2/jNrAbwHnAikAe8AYx09xVJDawSzGwdkOPuaXvTiZn9GNgBPOrunaN1twOfuvuE6Au6ibtfk8w441XC+dwI7HD3icmMraLM7DDgMHd/08waAouB04DzSMPPqZTzOZM0/ZzMzID67r7DzGoBLwG/Bq4C/s/dZ5rZX4G33f3eRL53qtf4jwXWuPtad/8GmAkMTXJMWc/dFxHmXYg1FHgkev4I4T9lWijhfNKau2909zej518AK4EjSNPPqZTzSVvR/Ck7ope1osWB44Eno/VV8hmleuI/Avgo5nUeaf5hEz7Y581ssZmNTXYwCXSIu2+Mnm8CDklmMAlyqZktjZqC0qJJpDhm1pYwSdJrZMDnVOR8II0/JzOrYWZLgE+ABcD7wHZ3L4iKVEnOS/XEn4n6uHtP4GTgkqiZIaNE08ClbhtifO4FjgK6AxuBvyQ3nIoxswbAbMLsd5/HbkvHz6mY80nrz8ndd7t7d6AloYXj6Op431RP/BuAVjGvW0br0pa7b4gePwGeInzYmWBz1A5b2B77SZLjqRR33xz9p9wD3E8afk5Ru/FsYLq7/1+0Om0/p+LOJxM+JwB33w4sBH4INDazmtGmKsl5qZ743wDaR1e5axMmcp+T5JgqzMzqRxemMLP6wCDgndL3ShtzgHOj5+cCTycxlkorTI6RYaTZ5xRdOHwQWOnud8RsSsvPqaTzSefPycxamFnj6PmBhE4sKwlfAMOjYlXyGaV0rx4ofqL3JIdUYWZ2JKGWD1ATeDwdz8fMZgD9CUPIbgZuAP4GzAJaE4bUPtPd0+KCaQnn05/QfODAOuCXMW3jKc/M+gD/BpYBe6LV1xLaxdPucyrlfEaSpp+TmXUlXLytQaiEz3L3m6M8MRNoCrwFjHb3rxP63qme+EVEJLFSvalHREQSTIlfRCTLKPGLiGQZJX4RkSyjxC8ikmWU+EVEsowSv4hIlvn/sqY2P3xUNk8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/.pyenv/versions/3.6.0/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4393622166024848"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n",
    "acc_log\n",
    "eval_val = root_mean_squared_log_error(Y_test, Y_pred) \n",
    "eval_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/.pyenv/versions/3.6.0/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4393622166024848"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train)\n",
    "Y_pred = svc.predict(X_test)\n",
    "acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n",
    "acc_svc\n",
    "eval_val = root_mean_squared_log_error(Y_test, Y_pred) \n",
    "eval_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5157180055768339"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "acc_knn\n",
    "eval_val = root_mean_squared_log_error(Y_test, Y_pred) \n",
    "eval_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4393622166024848"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, Y_train)\n",
    "Y_pred = gaussian.predict(X_test)\n",
    "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n",
    "acc_gaussian\n",
    "eval_val = root_mean_squared_log_error(Y_test, Y_pred) \n",
    "eval_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/.pyenv/versions/3.6.0/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4393622166024848"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, Y_train)\n",
    "Y_pred = perceptron.predict(X_test)\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n",
    "acc_perceptron\n",
    "eval_val = root_mean_squared_log_error(Y_test, Y_pred) \n",
    "eval_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4393622166024848"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(X_train, Y_train)\n",
    "Y_pred = linear_svc.predict(X_test)\n",
    "acc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\n",
    "acc_linear_svc\n",
    "eval_val = root_mean_squared_log_error(Y_test, Y_pred) \n",
    "eval_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/.pyenv/versions/3.6.0/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5361099295297119"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, Y_train)\n",
    "Y_pred = sgd.predict(X_test)\n",
    "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
    "acc_sgd\n",
    "eval_val = root_mean_squared_log_error(Y_test, Y_pred) \n",
    "eval_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5115420825536313"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, Y_train)\n",
    "Y_pred = decision_tree.predict(X_test)\n",
    "acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\n",
    "acc_decision_tree\n",
    "eval_val = root_mean_squared_log_error(Y_test, Y_pred) \n",
    "eval_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5157180055768339"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "random_forest.score(X_train, Y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
    "acc_random_forest\n",
    "eval_val = root_mean_squared_log_error(Y_test, Y_pred) \n",
    "eval_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>76.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>67.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>67.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>67.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stochastic Gradient Decent</td>\n",
       "      <td>67.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>67.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>53.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model   Score\n",
       "3               Random Forest  100.00\n",
       "8               Decision Tree  100.00\n",
       "1                         KNN   76.06\n",
       "0     Support Vector Machines   67.61\n",
       "2         Logistic Regression   67.61\n",
       "5                  Perceptron   67.61\n",
       "6  Stochastic Gradient Decent   67.61\n",
       "7                  Linear SVC   67.61\n",
       "4                 Naive Bayes   53.52"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "              'Stochastic Gradient Decent', 'Linear SVC', \n",
    "              'Decision Tree'],\n",
    "    'Score': [acc_svc, acc_knn, acc_log, \n",
    "              acc_random_forest, acc_gaussian, acc_perceptron, \n",
    "              acc_sgd, acc_linear_svc, acc_decision_tree]})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-20 15:28:26,352 : INFO : collecting all words and their counts\n",
      "2018-11-20 15:28:26,376 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-11-20 15:29:58,697 : INFO : PROGRESS: at sentence #10000, processed 100000000 words, keeping 37869465 word types\n",
      "2018-11-20 15:30:19,911 : INFO : collected 44586799 word types from a corpus of 121045863 raw words and 12105 sentences\n",
      "2018-11-20 15:30:19,915 : INFO : Loading a fresh vocabulary\n",
      "2018-11-20 15:34:40,576 : INFO : effective_min_count=1 retains 44586799 unique words (100% of original 44586799, drops 0)\n",
      "2018-11-20 15:34:40,607 : INFO : effective_min_count=1 leaves 121045863 word corpus (100% of original 121045863, drops 0)\n",
      "2018-11-20 15:38:28,252 : INFO : deleting the raw counts dictionary of 44586799 items\n",
      "2018-11-20 15:38:56,899 : INFO : sample=0.001 downsamples 14 most-common words\n",
      "2018-11-20 15:38:56,921 : INFO : downsampling leaves estimated 100556564 word corpus (83.1% of prior 121045863)\n",
      "2018-11-20 15:52:21,071 : INFO : estimated required memory for 44586799 words and 100 dimensions: 57962838700 bytes\n",
      "2018-11-20 15:52:21,117 : INFO : resetting layer weights\n",
      "2018-11-20 16:01:25,659 : INFO : training model with 3 workers on 44586799 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=15\n",
      "2018-11-20 16:01:30,135 : INFO : EPOCH 1 - PROGRESS: at 0.01% examples, 1719 words/s, in_qsize 4, out_qsize 2\n",
      "2018-11-20 16:01:31,147 : INFO : EPOCH 1 - PROGRESS: at 0.07% examples, 11865 words/s, in_qsize 1, out_qsize 0\n",
      "2018-11-20 16:01:32,162 : INFO : EPOCH 1 - PROGRESS: at 0.13% examples, 19475 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:01:33,209 : INFO : EPOCH 1 - PROGRESS: at 0.19% examples, 24349 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:01:34,404 : INFO : EPOCH 1 - PROGRESS: at 0.26% examples, 29307 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:01:35,534 : INFO : EPOCH 1 - PROGRESS: at 0.34% examples, 32730 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:01:36,695 : INFO : EPOCH 1 - PROGRESS: at 0.41% examples, 35103 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:01:37,877 : INFO : EPOCH 1 - PROGRESS: at 0.49% examples, 37657 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:01:38,944 : INFO : EPOCH 1 - PROGRESS: at 0.56% examples, 39378 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:01:39,973 : INFO : EPOCH 1 - PROGRESS: at 0.62% examples, 39937 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:01:41,013 : INFO : EPOCH 1 - PROGRESS: at 0.67% examples, 40433 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:01:42,047 : INFO : EPOCH 1 - PROGRESS: at 0.72% examples, 40725 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:01:43,063 : INFO : EPOCH 1 - PROGRESS: at 0.78% examples, 41327 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:01:44,074 : INFO : EPOCH 1 - PROGRESS: at 0.82% examples, 41274 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:01:45,287 : INFO : EPOCH 1 - PROGRESS: at 0.88% examples, 41431 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:01:46,429 : INFO : EPOCH 1 - PROGRESS: at 0.93% examples, 41244 words/s, in_qsize 5, out_qsize 2\n",
      "2018-11-20 16:01:47,478 : INFO : EPOCH 1 - PROGRESS: at 0.98% examples, 41652 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:01:48,564 : INFO : EPOCH 1 - PROGRESS: at 1.05% examples, 42150 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:01:49,632 : INFO : EPOCH 1 - PROGRESS: at 1.11% examples, 42183 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:01:50,852 : INFO : EPOCH 1 - PROGRESS: at 1.16% examples, 42118 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:01:51,908 : INFO : EPOCH 1 - PROGRESS: at 1.21% examples, 42153 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:01:52,933 : INFO : EPOCH 1 - PROGRESS: at 1.27% examples, 42282 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:01:54,249 : INFO : EPOCH 1 - PROGRESS: at 1.31% examples, 41545 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:01:55,322 : INFO : EPOCH 1 - PROGRESS: at 1.35% examples, 41005 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:01:56,325 : INFO : EPOCH 1 - PROGRESS: at 1.39% examples, 40827 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:01:57,467 : INFO : EPOCH 1 - PROGRESS: at 1.43% examples, 40602 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:01:58,682 : INFO : EPOCH 1 - PROGRESS: at 1.48% examples, 40627 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:01:59,890 : INFO : EPOCH 1 - PROGRESS: at 1.53% examples, 40654 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:00,910 : INFO : EPOCH 1 - PROGRESS: at 1.57% examples, 40700 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:02:02,150 : INFO : EPOCH 1 - PROGRESS: at 1.62% examples, 40665 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:03,287 : INFO : EPOCH 1 - PROGRESS: at 1.67% examples, 40766 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:02:04,384 : INFO : EPOCH 1 - PROGRESS: at 1.72% examples, 40881 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:02:05,542 : INFO : EPOCH 1 - PROGRESS: at 1.77% examples, 40920 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:06,610 : INFO : EPOCH 1 - PROGRESS: at 1.81% examples, 40850 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:07,810 : INFO : EPOCH 1 - PROGRESS: at 1.85% examples, 40683 words/s, in_qsize 5, out_qsize 1\n",
      "2018-11-20 16:02:09,042 : INFO : EPOCH 1 - PROGRESS: at 1.90% examples, 40674 words/s, in_qsize 5, out_qsize 1\n",
      "2018-11-20 16:02:10,101 : INFO : EPOCH 1 - PROGRESS: at 1.94% examples, 40620 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:02:11,523 : INFO : EPOCH 1 - PROGRESS: at 1.97% examples, 40045 words/s, in_qsize 5, out_qsize 1\n",
      "2018-11-20 16:02:12,733 : INFO : EPOCH 1 - PROGRESS: at 2.02% examples, 40060 words/s, in_qsize 5, out_qsize 1\n",
      "2018-11-20 16:02:13,844 : INFO : EPOCH 1 - PROGRESS: at 2.07% examples, 40049 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:02:15,149 : INFO : EPOCH 1 - PROGRESS: at 2.12% examples, 39983 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:02:16,366 : INFO : EPOCH 1 - PROGRESS: at 2.17% examples, 40001 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:17,434 : INFO : EPOCH 1 - PROGRESS: at 2.22% examples, 40092 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:18,615 : INFO : EPOCH 1 - PROGRESS: at 2.27% examples, 40122 words/s, in_qsize 5, out_qsize 1\n",
      "2018-11-20 16:02:19,711 : INFO : EPOCH 1 - PROGRESS: at 2.32% examples, 40210 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:20,796 : INFO : EPOCH 1 - PROGRESS: at 2.37% examples, 40318 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:21,960 : INFO : EPOCH 1 - PROGRESS: at 2.42% examples, 40348 words/s, in_qsize 5, out_qsize 1\n",
      "2018-11-20 16:02:23,029 : INFO : EPOCH 1 - PROGRESS: at 2.47% examples, 40416 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:02:24,081 : INFO : EPOCH 1 - PROGRESS: at 2.52% examples, 40512 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:25,189 : INFO : EPOCH 1 - PROGRESS: at 2.57% examples, 40570 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:26,261 : INFO : EPOCH 1 - PROGRESS: at 2.61% examples, 40528 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:02:27,460 : INFO : EPOCH 1 - PROGRESS: at 2.67% examples, 40645 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:02:28,611 : INFO : EPOCH 1 - PROGRESS: at 2.72% examples, 40650 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:29,752 : INFO : EPOCH 1 - PROGRESS: at 2.77% examples, 40678 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:30,853 : INFO : EPOCH 1 - PROGRESS: at 2.82% examples, 40751 words/s, in_qsize 5, out_qsize 1\n",
      "2018-11-20 16:02:31,960 : INFO : EPOCH 1 - PROGRESS: at 2.87% examples, 40779 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:02:33,003 : INFO : EPOCH 1 - PROGRESS: at 2.92% examples, 40865 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:34,089 : INFO : EPOCH 1 - PROGRESS: at 2.97% examples, 40914 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:02:35,214 : INFO : EPOCH 1 - PROGRESS: at 3.02% examples, 40943 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:02:36,234 : INFO : EPOCH 1 - PROGRESS: at 3.06% examples, 41028 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:02:37,402 : INFO : EPOCH 1 - PROGRESS: at 3.11% examples, 41041 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:02:38,482 : INFO : EPOCH 1 - PROGRESS: at 3.16% examples, 41089 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-20 16:02:39,555 : INFO : EPOCH 1 - PROGRESS: at 3.21% examples, 41037 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:40,634 : INFO : EPOCH 1 - PROGRESS: at 3.26% examples, 41147 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:41,783 : INFO : EPOCH 1 - PROGRESS: at 3.31% examples, 41129 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:42,829 : INFO : EPOCH 1 - PROGRESS: at 3.36% examples, 41182 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:43,942 : INFO : EPOCH 1 - PROGRESS: at 3.39% examples, 40905 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:45,125 : INFO : EPOCH 1 - PROGRESS: at 3.42% examples, 40694 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:02:46,269 : INFO : EPOCH 1 - PROGRESS: at 3.45% examples, 40515 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:47,333 : INFO : EPOCH 1 - PROGRESS: at 3.49% examples, 40377 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:48,620 : INFO : EPOCH 1 - PROGRESS: at 3.52% examples, 40150 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:02:50,044 : INFO : EPOCH 1 - PROGRESS: at 3.56% examples, 39945 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:51,187 : INFO : EPOCH 1 - PROGRESS: at 3.59% examples, 39793 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:02:52,295 : INFO : EPOCH 1 - PROGRESS: at 3.62% examples, 39555 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:02:53,564 : INFO : EPOCH 1 - PROGRESS: at 3.65% examples, 39348 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:02:54,851 : INFO : EPOCH 1 - PROGRESS: at 3.68% examples, 39038 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:02:56,153 : INFO : EPOCH 1 - PROGRESS: at 3.71% examples, 38823 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:02:57,159 : INFO : EPOCH 1 - PROGRESS: at 3.73% examples, 38666 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:58,269 : INFO : EPOCH 1 - PROGRESS: at 3.76% examples, 38465 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:02:59,879 : INFO : EPOCH 1 - PROGRESS: at 3.79% examples, 38156 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:03:01,117 : INFO : EPOCH 1 - PROGRESS: at 3.82% examples, 37991 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:03:02,172 : INFO : EPOCH 1 - PROGRESS: at 3.85% examples, 37831 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:03:03,365 : INFO : EPOCH 1 - PROGRESS: at 3.88% examples, 37703 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:04,372 : INFO : EPOCH 1 - PROGRESS: at 3.91% examples, 37568 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:05,436 : INFO : EPOCH 1 - PROGRESS: at 3.93% examples, 37413 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:07,064 : INFO : EPOCH 1 - PROGRESS: at 3.97% examples, 37137 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:08,559 : INFO : EPOCH 1 - PROGRESS: at 3.99% examples, 36844 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:09,652 : INFO : EPOCH 1 - PROGRESS: at 4.01% examples, 36609 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:03:11,030 : INFO : EPOCH 1 - PROGRESS: at 4.01% examples, 36198 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:03:12,170 : INFO : EPOCH 1 - PROGRESS: at 4.04% examples, 36031 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:13,641 : INFO : EPOCH 1 - PROGRESS: at 4.06% examples, 35754 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:14,911 : INFO : EPOCH 1 - PROGRESS: at 4.09% examples, 35554 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:16,786 : INFO : EPOCH 1 - PROGRESS: at 4.11% examples, 35171 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:18,572 : INFO : EPOCH 1 - PROGRESS: at 4.13% examples, 34758 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:03:19,945 : INFO : EPOCH 1 - PROGRESS: at 4.14% examples, 34406 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:03:21,915 : INFO : EPOCH 1 - PROGRESS: at 4.16% examples, 33950 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:23,299 : INFO : EPOCH 1 - PROGRESS: at 4.16% examples, 33615 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:25,097 : INFO : EPOCH 1 - PROGRESS: at 4.18% examples, 33239 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:03:26,268 : INFO : EPOCH 1 - PROGRESS: at 4.19% examples, 32981 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:27,435 : INFO : EPOCH 1 - PROGRESS: at 4.20% examples, 32796 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:03:28,743 : INFO : EPOCH 1 - PROGRESS: at 4.23% examples, 32643 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:03:29,957 : INFO : EPOCH 1 - PROGRESS: at 4.25% examples, 32513 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:31,306 : INFO : EPOCH 1 - PROGRESS: at 4.26% examples, 32231 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:03:32,654 : INFO : EPOCH 1 - PROGRESS: at 4.28% examples, 32018 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:34,515 : INFO : EPOCH 1 - PROGRESS: at 4.29% examples, 31616 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:35,720 : INFO : EPOCH 1 - PROGRESS: at 4.30% examples, 31391 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:37,651 : INFO : EPOCH 1 - PROGRESS: at 4.30% examples, 30993 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:41,154 : INFO : EPOCH 1 - PROGRESS: at 4.31% examples, 30250 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:03:44,862 : INFO : EPOCH 1 - PROGRESS: at 4.33% examples, 29561 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:48,358 : INFO : EPOCH 1 - PROGRESS: at 4.34% examples, 28894 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:50,593 : INFO : EPOCH 1 - PROGRESS: at 4.35% examples, 28566 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:51,933 : INFO : EPOCH 1 - PROGRESS: at 4.36% examples, 28360 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:52,998 : INFO : EPOCH 1 - PROGRESS: at 4.37% examples, 28214 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:54,035 : INFO : EPOCH 1 - PROGRESS: at 4.38% examples, 28071 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:55,822 : INFO : EPOCH 1 - PROGRESS: at 4.39% examples, 27792 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:03:57,646 : INFO : EPOCH 1 - PROGRESS: at 4.39% examples, 27515 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:04:00,614 : INFO : EPOCH 1 - PROGRESS: at 4.40% examples, 27040 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:04:04,770 : INFO : EPOCH 1 - PROGRESS: at 4.41% examples, 26388 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:04:06,086 : INFO : EPOCH 1 - PROGRESS: at 4.42% examples, 26223 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:04:07,955 : INFO : EPOCH 1 - PROGRESS: at 4.43% examples, 25968 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:04:11,353 : INFO : EPOCH 1 - PROGRESS: at 4.44% examples, 25483 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:04:12,424 : INFO : EPOCH 1 - PROGRESS: at 4.44% examples, 25364 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:04:15,894 : INFO : EPOCH 1 - PROGRESS: at 4.45% examples, 24894 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:04:19,315 : INFO : EPOCH 1 - PROGRESS: at 4.46% examples, 24451 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:04:21,666 : INFO : EPOCH 1 - PROGRESS: at 4.48% examples, 24213 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:04:24,997 : INFO : EPOCH 1 - PROGRESS: at 4.49% examples, 23807 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:04:30,019 : INFO : EPOCH 1 - PROGRESS: at 4.50% examples, 23241 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:04:33,905 : INFO : EPOCH 1 - PROGRESS: at 4.51% examples, 22802 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:04:37,338 : INFO : EPOCH 1 - PROGRESS: at 4.53% examples, 22476 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:04:41,269 : INFO : EPOCH 1 - PROGRESS: at 4.54% examples, 22063 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:04:45,524 : INFO : EPOCH 1 - PROGRESS: at 4.55% examples, 21674 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:04:48,747 : INFO : EPOCH 1 - PROGRESS: at 4.56% examples, 21367 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:04:51,819 : INFO : EPOCH 1 - PROGRESS: at 4.58% examples, 21126 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:04:56,768 : INFO : EPOCH 1 - PROGRESS: at 4.58% examples, 20670 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:04:59,368 : INFO : EPOCH 1 - PROGRESS: at 4.60% examples, 20490 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:05:02,910 : INFO : EPOCH 1 - PROGRESS: at 4.61% examples, 20191 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-20 16:05:03,914 : INFO : EPOCH 1 - PROGRESS: at 4.62% examples, 20134 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:05:07,612 : INFO : EPOCH 1 - PROGRESS: at 4.63% examples, 19835 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:05:11,975 : INFO : EPOCH 1 - PROGRESS: at 4.63% examples, 19486 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:05:13,191 : INFO : EPOCH 1 - PROGRESS: at 4.64% examples, 19415 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:05:16,152 : INFO : EPOCH 1 - PROGRESS: at 4.65% examples, 19198 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:05:22,458 : INFO : EPOCH 1 - PROGRESS: at 4.66% examples, 18720 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:05:23,613 : INFO : EPOCH 1 - PROGRESS: at 4.67% examples, 18663 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:05:26,309 : INFO : EPOCH 1 - PROGRESS: at 4.68% examples, 18486 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:05:30,289 : INFO : EPOCH 1 - PROGRESS: at 4.68% examples, 18216 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:05:32,201 : INFO : EPOCH 1 - PROGRESS: at 4.69% examples, 18106 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:05:37,252 : INFO : EPOCH 1 - PROGRESS: at 4.70% examples, 17772 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:05:41,415 : INFO : EPOCH 1 - PROGRESS: at 4.71% examples, 17513 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:05:42,602 : INFO : EPOCH 1 - PROGRESS: at 4.72% examples, 17461 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:05:45,638 : INFO : EPOCH 1 - PROGRESS: at 4.73% examples, 17287 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:05:51,847 : INFO : EPOCH 1 - PROGRESS: at 4.73% examples, 16911 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:05:55,745 : INFO : EPOCH 1 - PROGRESS: at 4.75% examples, 16721 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:05:59,459 : INFO : EPOCH 1 - PROGRESS: at 4.76% examples, 16521 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:06:00,549 : INFO : EPOCH 1 - PROGRESS: at 4.77% examples, 16484 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:06:05,923 : INFO : EPOCH 1 - PROGRESS: at 4.77% examples, 16195 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:06:09,444 : INFO : EPOCH 1 - PROGRESS: at 4.78% examples, 16021 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:06:10,938 : INFO : EPOCH 1 - PROGRESS: at 4.79% examples, 15964 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:06:15,342 : INFO : EPOCH 1 - PROGRESS: at 4.80% examples, 15746 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:06:19,798 : INFO : EPOCH 1 - PROGRESS: at 4.81% examples, 15535 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:06:24,479 : INFO : EPOCH 1 - PROGRESS: at 4.82% examples, 15343 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:06:30,333 : INFO : EPOCH 1 - PROGRESS: at 4.83% examples, 15073 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:06:34,904 : INFO : EPOCH 1 - PROGRESS: at 4.85% examples, 14901 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:06:38,740 : INFO : EPOCH 1 - PROGRESS: at 4.86% examples, 14742 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:06:44,803 : INFO : EPOCH 1 - PROGRESS: at 4.87% examples, 14507 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:06:49,275 : INFO : EPOCH 1 - PROGRESS: at 4.88% examples, 14329 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:06:50,470 : INFO : EPOCH 1 - PROGRESS: at 4.89% examples, 14301 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:06:55,337 : INFO : EPOCH 1 - PROGRESS: at 4.90% examples, 14113 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:06:59,343 : INFO : EPOCH 1 - PROGRESS: at 4.91% examples, 13965 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:07:01,466 : INFO : EPOCH 1 - PROGRESS: at 4.92% examples, 13901 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:07:06,302 : INFO : EPOCH 1 - PROGRESS: at 4.92% examples, 13727 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:07:11,569 : INFO : EPOCH 1 - PROGRESS: at 4.93% examples, 13542 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:07:13,183 : INFO : EPOCH 1 - PROGRESS: at 4.94% examples, 13503 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:07:17,864 : INFO : EPOCH 1 - PROGRESS: at 4.95% examples, 13346 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:07:23,465 : INFO : EPOCH 1 - PROGRESS: at 4.96% examples, 13160 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:07:25,147 : INFO : EPOCH 1 - PROGRESS: at 4.96% examples, 13121 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:07:28,798 : INFO : EPOCH 1 - PROGRESS: at 4.97% examples, 13011 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:07:35,122 : INFO : EPOCH 1 - PROGRESS: at 4.98% examples, 12810 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:07:37,302 : INFO : EPOCH 1 - PROGRESS: at 4.99% examples, 12758 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:07:40,395 : INFO : EPOCH 1 - PROGRESS: at 5.00% examples, 12673 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:07:46,857 : INFO : EPOCH 1 - PROGRESS: at 5.01% examples, 12478 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:07:48,760 : INFO : EPOCH 1 - PROGRESS: at 5.01% examples, 12436 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:07:52,177 : INFO : EPOCH 1 - PROGRESS: at 5.02% examples, 12347 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:07:58,384 : INFO : EPOCH 1 - PROGRESS: at 5.03% examples, 12171 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:08:04,762 : INFO : EPOCH 1 - PROGRESS: at 5.05% examples, 12014 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:08:10,822 : INFO : EPOCH 1 - PROGRESS: at 5.06% examples, 11853 words/s, in_qsize 4, out_qsize 1\n",
      "2018-11-20 16:08:17,114 : INFO : EPOCH 1 - PROGRESS: at 5.07% examples, 11711 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:08:25,288 : INFO : EPOCH 1 - PROGRESS: at 5.08% examples, 11503 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:08:30,494 : INFO : EPOCH 1 - PROGRESS: at 5.10% examples, 11398 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:08:38,150 : INFO : EPOCH 1 - PROGRESS: at 5.11% examples, 11214 words/s, in_qsize 5, out_qsize 1\n",
      "2018-11-20 16:08:42,288 : INFO : EPOCH 1 - PROGRESS: at 5.12% examples, 11145 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:08:51,954 : INFO : EPOCH 1 - PROGRESS: at 5.13% examples, 10922 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:08:54,490 : INFO : EPOCH 1 - PROGRESS: at 5.15% examples, 10895 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:09:04,230 : INFO : EPOCH 1 - PROGRESS: at 5.15% examples, 10681 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:09:05,236 : INFO : EPOCH 1 - PROGRESS: at 5.16% examples, 10674 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:09:18,976 : INFO : EPOCH 1 - PROGRESS: at 5.18% examples, 10398 words/s, in_qsize 5, out_qsize 1\n",
      "2018-11-20 16:09:20,528 : INFO : EPOCH 1 - PROGRESS: at 5.20% examples, 10398 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:09:31,664 : INFO : EPOCH 1 - PROGRESS: at 5.20% examples, 10175 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:09:34,369 : INFO : EPOCH 1 - PROGRESS: at 5.22% examples, 10151 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:09:46,396 : INFO : EPOCH 1 - PROGRESS: at 5.23% examples, 9922 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:09:47,519 : INFO : EPOCH 1 - PROGRESS: at 5.24% examples, 9915 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:09:49,618 : INFO : EPOCH 1 - PROGRESS: at 5.25% examples, 9891 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:09:59,854 : INFO : EPOCH 1 - PROGRESS: at 5.25% examples, 9708 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:10:01,055 : INFO : EPOCH 1 - PROGRESS: at 5.26% examples, 9701 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:10:03,826 : INFO : EPOCH 1 - PROGRESS: at 5.27% examples, 9664 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:10:14,471 : INFO : EPOCH 1 - PROGRESS: at 5.28% examples, 9485 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:10:17,567 : INFO : EPOCH 1 - PROGRESS: at 5.30% examples, 9459 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:10:27,911 : INFO : EPOCH 1 - PROGRESS: at 5.30% examples, 9292 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:10:30,999 : INFO : EPOCH 1 - PROGRESS: at 5.32% examples, 9268 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:10:42,016 : INFO : EPOCH 1 - PROGRESS: at 5.33% examples, 9099 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:10:43,315 : INFO : EPOCH 1 - PROGRESS: at 5.34% examples, 9092 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-20 16:10:47,012 : INFO : EPOCH 1 - PROGRESS: at 5.34% examples, 9047 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:10:57,090 : INFO : EPOCH 1 - PROGRESS: at 5.35% examples, 8901 words/s, in_qsize 5, out_qsize 1\n",
      "2018-11-20 16:11:01,043 : INFO : EPOCH 1 - PROGRESS: at 5.37% examples, 8867 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:11:13,274 : INFO : EPOCH 1 - PROGRESS: at 5.38% examples, 8697 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:11:14,562 : INFO : EPOCH 1 - PROGRESS: at 5.39% examples, 8692 words/s, in_qsize 4, out_qsize 1\n",
      "2018-11-20 16:11:28,219 : INFO : EPOCH 1 - PROGRESS: at 5.40% examples, 8522 words/s, in_qsize 5, out_qsize 1\n",
      "2018-11-20 16:11:29,347 : INFO : EPOCH 1 - PROGRESS: at 5.41% examples, 8519 words/s, in_qsize 4, out_qsize 1\n",
      "2018-11-20 16:11:41,387 : INFO : EPOCH 1 - PROGRESS: at 5.43% examples, 8378 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:11:43,957 : INFO : EPOCH 1 - PROGRESS: at 5.44% examples, 8356 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:11:55,697 : INFO : EPOCH 1 - PROGRESS: at 5.45% examples, 8226 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:11:58,871 : INFO : EPOCH 1 - PROGRESS: at 5.46% examples, 8199 words/s, in_qsize 4, out_qsize 1\n",
      "2018-11-20 16:12:10,506 : INFO : EPOCH 1 - PROGRESS: at 5.48% examples, 8077 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:12:12,349 : INFO : EPOCH 1 - PROGRESS: at 5.49% examples, 8065 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:12:13,619 : INFO : EPOCH 1 - PROGRESS: at 5.49% examples, 8061 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:12:24,371 : INFO : EPOCH 1 - PROGRESS: at 5.50% examples, 7941 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:12:27,978 : INFO : EPOCH 1 - PROGRESS: at 5.51% examples, 7910 words/s, in_qsize 5, out_qsize 1\n",
      "2018-11-20 16:12:38,656 : INFO : EPOCH 1 - PROGRESS: at 5.53% examples, 7809 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:12:41,700 : INFO : EPOCH 1 - PROGRESS: at 5.53% examples, 7785 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:12:43,273 : INFO : EPOCH 1 - PROGRESS: at 5.54% examples, 7780 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:12:52,363 : INFO : EPOCH 1 - PROGRESS: at 5.55% examples, 7688 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:12:56,531 : INFO : EPOCH 1 - PROGRESS: at 5.56% examples, 7654 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:12:58,579 : INFO : EPOCH 1 - PROGRESS: at 5.57% examples, 7643 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:13:06,985 : INFO : EPOCH 1 - PROGRESS: at 5.58% examples, 7563 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:13:11,250 : INFO : EPOCH 1 - PROGRESS: at 5.58% examples, 7528 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:13:13,253 : INFO : EPOCH 1 - PROGRESS: at 5.59% examples, 7518 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:13:22,125 : INFO : EPOCH 1 - PROGRESS: at 5.60% examples, 7437 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:13:26,797 : INFO : EPOCH 1 - PROGRESS: at 5.61% examples, 7400 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:13:28,045 : INFO : EPOCH 1 - PROGRESS: at 5.62% examples, 7398 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:13:36,981 : INFO : EPOCH 1 - PROGRESS: at 5.63% examples, 7319 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:13:40,277 : INFO : EPOCH 1 - PROGRESS: at 5.63% examples, 7297 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:13:42,620 : INFO : EPOCH 1 - PROGRESS: at 5.64% examples, 7284 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:13:52,319 : INFO : EPOCH 1 - PROGRESS: at 5.65% examples, 7201 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:13:54,990 : INFO : EPOCH 1 - PROGRESS: at 5.66% examples, 7185 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:13:56,015 : INFO : EPOCH 1 - PROGRESS: at 5.67% examples, 7186 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:14:09,925 : INFO : EPOCH 1 - PROGRESS: at 5.68% examples, 7065 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:14:11,920 : INFO : EPOCH 1 - PROGRESS: at 5.68% examples, 7058 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:14:25,270 : INFO : EPOCH 1 - PROGRESS: at 5.70% examples, 6957 words/s, in_qsize 4, out_qsize 1\n",
      "2018-11-20 16:14:26,971 : INFO : EPOCH 1 - PROGRESS: at 5.72% examples, 6961 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:14:40,863 : INFO : EPOCH 1 - PROGRESS: at 5.72% examples, 6850 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:14:42,272 : INFO : EPOCH 1 - PROGRESS: at 5.73% examples, 6848 words/s, in_qsize 4, out_qsize 1\n",
      "2018-11-20 16:14:55,383 : INFO : EPOCH 1 - PROGRESS: at 5.75% examples, 6756 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:14:57,802 : INFO : EPOCH 1 - PROGRESS: at 5.77% examples, 6756 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:15:10,660 : INFO : EPOCH 1 - PROGRESS: at 5.77% examples, 6660 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:15:11,709 : INFO : EPOCH 1 - PROGRESS: at 5.78% examples, 6662 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:15:14,726 : INFO : EPOCH 1 - PROGRESS: at 5.79% examples, 6647 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:15:27,455 : INFO : EPOCH 1 - PROGRESS: at 5.80% examples, 6556 words/s, in_qsize 4, out_qsize 1\n",
      "2018-11-20 16:15:29,437 : INFO : EPOCH 1 - PROGRESS: at 5.82% examples, 6559 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:15:43,503 : INFO : EPOCH 1 - PROGRESS: at 5.82% examples, 6460 words/s, in_qsize 5, out_qsize 1\n",
      "2018-11-20 16:15:45,635 : INFO : EPOCH 1 - PROGRESS: at 5.84% examples, 6463 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:15:59,493 : INFO : EPOCH 1 - PROGRESS: at 5.85% examples, 6369 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:16:00,831 : INFO : EPOCH 1 - PROGRESS: at 5.86% examples, 6369 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:16:02,373 : INFO : EPOCH 1 - PROGRESS: at 5.87% examples, 6366 words/s, in_qsize 4, out_qsize 0\n",
      "2018-11-20 16:16:19,663 : INFO : EPOCH 1 - PROGRESS: at 5.87% examples, 6252 words/s, in_qsize 5, out_qsize 1\n",
      "2018-11-20 16:16:20,698 : INFO : EPOCH 1 - PROGRESS: at 5.88% examples, 6254 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:16:22,115 : INFO : EPOCH 1 - PROGRESS: at 5.89% examples, 6253 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:16:37,527 : INFO : EPOCH 1 - PROGRESS: at 5.90% examples, 6157 words/s, in_qsize 4, out_qsize 1\n",
      "2018-11-20 16:16:54,982 : INFO : EPOCH 1 - PROGRESS: at 5.92% examples, 6066 words/s, in_qsize 5, out_qsize 1\n",
      "2018-11-20 16:16:56,058 : INFO : EPOCH 1 - PROGRESS: at 5.93% examples, 6068 words/s, in_qsize 4, out_qsize 1\n",
      "2018-11-20 16:17:11,519 : INFO : EPOCH 1 - PROGRESS: at 5.95% examples, 5986 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:17:27,414 : INFO : EPOCH 1 - PROGRESS: at 5.97% examples, 5911 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:17:29,641 : INFO : EPOCH 1 - PROGRESS: at 5.99% examples, 5914 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:17:46,085 : INFO : EPOCH 1 - PROGRESS: at 6.00% examples, 5823 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:17:47,199 : INFO : EPOCH 1 - PROGRESS: at 6.01% examples, 5824 words/s, in_qsize 4, out_qsize 1\n",
      "2018-11-20 16:17:48,534 : INFO : EPOCH 1 - PROGRESS: at 6.01% examples, 5825 words/s, in_qsize 4, out_qsize 0\n",
      "2018-11-20 16:18:03,996 : INFO : EPOCH 1 - PROGRESS: at 6.02% examples, 5742 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:18:05,645 : INFO : EPOCH 1 - PROGRESS: at 6.03% examples, 5741 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:18:07,069 : INFO : EPOCH 1 - PROGRESS: at 6.04% examples, 5741 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:18:20,812 : INFO : EPOCH 1 - PROGRESS: at 6.05% examples, 5671 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:18:22,362 : INFO : EPOCH 1 - PROGRESS: at 6.06% examples, 5670 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:18:24,371 : INFO : EPOCH 1 - PROGRESS: at 6.06% examples, 5667 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:18:38,011 : INFO : EPOCH 1 - PROGRESS: at 6.07% examples, 5600 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:18:39,281 : INFO : EPOCH 1 - PROGRESS: at 6.08% examples, 5601 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:18:41,647 : INFO : EPOCH 1 - PROGRESS: at 6.09% examples, 5596 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:18:55,173 : INFO : EPOCH 1 - PROGRESS: at 6.10% examples, 5532 words/s, in_qsize 5, out_qsize 1\n",
      "2018-11-20 16:18:57,741 : INFO : EPOCH 1 - PROGRESS: at 6.11% examples, 5533 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-20 16:19:12,801 : INFO : EPOCH 1 - PROGRESS: at 6.12% examples, 5463 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:19:15,398 : INFO : EPOCH 1 - PROGRESS: at 6.14% examples, 5465 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:19:33,038 : INFO : EPOCH 1 - PROGRESS: at 6.15% examples, 5384 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:19:49,992 : INFO : EPOCH 1 - PROGRESS: at 6.17% examples, 5323 words/s, in_qsize 4, out_qsize 1\n",
      "2018-11-20 16:19:52,634 : INFO : EPOCH 1 - PROGRESS: at 6.19% examples, 5324 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:20:06,113 : INFO : EPOCH 1 - PROGRESS: at 6.20% examples, 5267 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:20:08,503 : INFO : EPOCH 1 - PROGRESS: at 6.20% examples, 5262 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:20:13,334 : INFO : EPOCH 1 - PROGRESS: at 6.21% examples, 5247 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:20:28,097 : INFO : EPOCH 1 - PROGRESS: at 6.22% examples, 5186 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:20:29,445 : INFO : EPOCH 1 - PROGRESS: at 6.23% examples, 5187 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:20:34,680 : INFO : EPOCH 1 - PROGRESS: at 6.24% examples, 5171 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:20:48,318 : INFO : EPOCH 1 - PROGRESS: at 6.25% examples, 5116 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:20:49,512 : INFO : EPOCH 1 - PROGRESS: at 6.25% examples, 5118 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:20:53,800 : INFO : EPOCH 1 - PROGRESS: at 6.26% examples, 5106 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:21:05,762 : INFO : EPOCH 1 - PROGRESS: at 6.27% examples, 5060 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:21:09,904 : INFO : EPOCH 1 - PROGRESS: at 6.28% examples, 5050 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:21:14,910 : INFO : EPOCH 1 - PROGRESS: at 6.29% examples, 5036 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:21:25,852 : INFO : EPOCH 1 - PROGRESS: at 6.29% examples, 4996 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:21:28,952 : INFO : EPOCH 1 - PROGRESS: at 6.30% examples, 4990 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:21:32,692 : INFO : EPOCH 1 - PROGRESS: at 6.31% examples, 4982 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-20 16:21:43,250 : INFO : EPOCH 1 - PROGRESS: at 6.32% examples, 4945 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:21:48,356 : INFO : EPOCH 1 - PROGRESS: at 6.33% examples, 4931 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:21:52,222 : INFO : EPOCH 1 - PROGRESS: at 6.34% examples, 4922 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:22:04,172 : INFO : EPOCH 1 - PROGRESS: at 6.34% examples, 4881 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-20 16:22:07,325 : INFO : EPOCH 1 - PROGRESS: at 6.35% examples, 4875 words/s, in_qsize 5, out_qsize 0\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from gensim.models import word2vec\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "sentences = word2vec.Text8Corpus('Util/jawiki_wakati.txt')\n",
    "model = word2vec.Word2Vec(sentences, size=100, min_count=1, window=15)\n",
    "model.save(\"Util/\" + datetime.now().strftime(\"%Y%m%d%H%M%S\") + \"wiki.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ある', 0.7372819185256958)\n",
      "('当てはまる', 0.714497447013855)\n",
      "('あてはまる', 0.6894434094429016)\n",
      "('成り立つ', 0.6864159107208252)\n",
      "('有る', 0.6478556394577026)\n",
      "('等しい', 0.6273118853569031)\n",
      "('みなせる', 0.626924991607666)\n",
      "('あたる', 0.6089791655540466)\n",
      "('大きい', 0.5976715087890625)\n",
      "('定まる', 0.5887224078178406)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "model = word2vec.Word2Vec.load(\"Util/word2vec.gensim.model\")\n",
    "results = model.wv.most_similar(positive=['である'])\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success これらは\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def aeded():\n",
    "    basis = \"これらは\"\n",
    "    analyzer = CaboChaAnalyzer()\n",
    "    basis_tree = analyzer.parse(re.sub(\"、\", \"\",basis))\n",
    "    if basis_tree.chunk_size < 2 or re.search(r'www|html|http|jpg|png|jpeg', basis) or re.search(r'www|html|http|jpg|png|jpeg', basis):\n",
    "        print(\"success\",basis)\n",
    "    for chunk in basis_tree:\n",
    "        for token in chunk:\n",
    "            if token.pos == \"名詞\" and token.pos1  == \"代名詞\":\n",
    "                return True\n",
    "            elif token.pos == \"連体詞\" and re.match(r'こ|そ|あ|ど', token.surface):\n",
    "                return True\n",
    "    chunk = basis_tree[basis_tree.chunk_size - 1] if basis_tree.chunk_size > 0 else basis_tree[0]\n",
    "    # if all([chunk[chunk.token_size - 1].pos != str(basis_list[causal.causalId]), str(basis_list[causal.causalId]) != None]):\n",
    "    #     causals.remove(causal)\n",
    "    return False\n",
    "\n",
    "print(aeded())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
